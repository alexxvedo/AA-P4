{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Cargar los datos\n",
    "train_data = pd.read_csv('train_processed.csv')\n",
    "test_data = pd.read_csv('test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del conjunto de datos de entrenamiento:\n",
      "Número de filas: 20000\n",
      "Número de columnas: 20\n",
      "\n",
      "Primeras filas del conjunto de datos:\n",
      "      id  superficie_interior_m2  superficie_exterior_m2  numero_habitacions  \\\n",
      "0  25521                   44.96                    0.00                   1   \n",
      "1   4843                   93.55                   87.26                   2   \n",
      "2  27734                  273.64                  187.29                   1   \n",
      "3  22142                  171.82                   54.89                   4   \n",
      "4  14748                     NaN                 2153.49                   1   \n",
      "\n",
      "   numero_banos  ano_construccion  lonxitude  latitude  \\\n",
      "0             2              1947      -8.17     43.20   \n",
      "1             2              1977      -7.23     43.60   \n",
      "2             1              1996      -8.40     42.25   \n",
      "3             2              1996      -6.81     43.15   \n",
      "4             1              1990      -8.76     42.92   \n",
      "\n",
      "   temperatura_media_mes_construccion tipo_edificacion calidade_materiais  \\\n",
      "0                               24.75      Apartamento              Media   \n",
      "1                               14.06      Apartamento               Alta   \n",
      "2                               12.27   Chalet adosado              Media   \n",
      "3                               11.61   Chalet adosado               Alta   \n",
      "4                               10.04             Casa              Baixa   \n",
      "\n",
      "  cor_favorita_propietario  distancia_centro_km  distancia_escola_km  \\\n",
      "0                     Azul                23.68                 2.75   \n",
      "1                    Verde                  NaN                16.67   \n",
      "2                   Branco                29.44                18.96   \n",
      "3                 Vermello                53.31                 1.96   \n",
      "4                    Verde                70.20                 4.72   \n",
      "\n",
      "   indice_criminalidade acceso_transporte_publico orientacion  \\\n",
      "0                  0.35                        Bo       Norte   \n",
      "1                  0.44                        Bo        Este   \n",
      "2                  0.47                   Regular        Este   \n",
      "3                  0.35                        Bo        Este   \n",
      "4                  0.09                        Bo       Oeste   \n",
      "\n",
      "  eficiencia_enerxetica  numero_arboles_xardin  prezo_euros  \n",
      "0                     C                      0        51938  \n",
      "1                     C                      0        76891  \n",
      "2                     C                     10       261441  \n",
      "3                     G                      3       247821  \n",
      "4                     G                     12       400645  \n",
      "\n",
      "Valores nulos en el conjunto de entrenamiento:\n",
      "id                                       0\n",
      "superficie_interior_m2                1007\n",
      "superficie_exterior_m2                1027\n",
      "numero_habitacions                       0\n",
      "numero_banos                             0\n",
      "ano_construccion                         0\n",
      "lonxitude                                0\n",
      "latitude                                 0\n",
      "temperatura_media_mes_construccion       0\n",
      "tipo_edificacion                         0\n",
      "calidade_materiais                       0\n",
      "cor_favorita_propietario                 0\n",
      "distancia_centro_km                   1011\n",
      "distancia_escola_km                   1021\n",
      "indice_criminalidade                   988\n",
      "acceso_transporte_publico                0\n",
      "orientacion                              0\n",
      "eficiencia_enerxetica                    0\n",
      "numero_arboles_xardin                    0\n",
      "prezo_euros                              0\n",
      "dtype: int64\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "                 id  superficie_interior_m2  superficie_exterior_m2  \\\n",
      "count  20000.000000            18993.000000            18973.000000   \n",
      "mean   15007.472150              140.063982              493.428165   \n",
      "std     8676.254271               78.978305              829.010391   \n",
      "min        1.000000               30.000000                0.000000   \n",
      "25%     7441.750000               81.210000                0.000000   \n",
      "50%    15066.000000              125.680000               42.030000   \n",
      "75%    22513.500000              191.580000              610.500000   \n",
      "max    29999.000000             1014.960000             3043.770000   \n",
      "\n",
      "       numero_habitacions  numero_banos  ano_construccion     lonxitude  \\\n",
      "count         20000.00000  20000.000000      20000.000000  20000.000000   \n",
      "mean              3.49715      1.997650       1981.878400     -8.005199   \n",
      "std               1.71042      0.815829         24.689814      0.749610   \n",
      "min               1.00000      1.000000       1940.000000     -9.300000   \n",
      "25%               2.00000      1.000000       1961.000000     -8.650000   \n",
      "50%               4.00000      2.000000       1982.000000     -8.000000   \n",
      "75%               5.00000      3.000000       2003.000000     -7.360000   \n",
      "max               6.00000      3.000000       2024.000000     -6.700000   \n",
      "\n",
      "           latitude  temperatura_media_mes_construccion  distancia_centro_km  \\\n",
      "count  20000.000000                         20000.00000         18989.000000   \n",
      "mean      42.800605                            17.55279            25.758541   \n",
      "std        0.576779                             7.21723            23.108787   \n",
      "min       41.800000                             5.00000             0.100000   \n",
      "25%       42.300000                            11.29000             8.310000   \n",
      "50%       42.810000                            17.59000            16.980000   \n",
      "75%       43.300000                            23.90000            41.100000   \n",
      "max       43.800000                            30.00000           199.370000   \n",
      "\n",
      "       distancia_escola_km  indice_criminalidade  numero_arboles_xardin  \\\n",
      "count         18979.000000          19012.000000           20000.000000   \n",
      "mean             10.350650              0.330250               4.820900   \n",
      "std               7.269707              0.202404               6.315973   \n",
      "min               0.050000             -0.300000               0.000000   \n",
      "25%               4.540000              0.180000               0.000000   \n",
      "50%              10.000000              0.330000               0.000000   \n",
      "75%              15.395000              0.470000              10.000000   \n",
      "max             108.430000              1.060000              19.000000   \n",
      "\n",
      "         prezo_euros  \n",
      "count   20000.000000  \n",
      "mean   223402.814500  \n",
      "std    166395.695409  \n",
      "min     50000.000000  \n",
      "25%     93345.750000  \n",
      "50%    159407.500000  \n",
      "75%    329635.000000  \n",
      "max    955855.000000  \n",
      "\n",
      "Estadísticas de la variable objetivo 'prezo_euros':\n",
      "count     20000.000000\n",
      "mean     223402.814500\n",
      "std      166395.695409\n",
      "min       50000.000000\n",
      "25%       93345.750000\n",
      "50%      159407.500000\n",
      "75%      329635.000000\n",
      "max      955855.000000\n",
      "Name: prezo_euros, dtype: float64\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'log_prezo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log_prezo'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_1693779/4078047683.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# También visualizamos el logaritmo del precio (que suele ser más normal)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'log_prezo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkde\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Distribución del logaritmo de precios de viviendas'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Log(Precio)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log_prezo'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. Análisis exploratorio de datos\n",
    "print(\"Información del conjunto de datos de entrenamiento:\")\n",
    "print(f\"Número de filas: {train_data.shape[0]}\")\n",
    "print(f\"Número de columnas: {train_data.shape[1]}\")\n",
    "print(\"\\nPrimeras filas del conjunto de datos:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Verificar valores nulos\n",
    "print(\"\\nValores nulos en el conjunto de entrenamiento:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "# Estadísticas descriptivas de las características numéricas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(train_data.describe())\n",
    "\n",
    "# Variables objetivo\n",
    "print(\"\\nEstadísticas de la variable objetivo 'prezo_euros':\")\n",
    "print(train_data['prezo_euros'].describe())\n",
    "\n",
    "# Visualizar la distribución del precio\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_data['prezo_euros'], kde=True)\n",
    "plt.title('Distribución de precios de viviendas')\n",
    "plt.xlabel('Precio (euros)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.savefig('distribucion_precios.png')\n",
    "plt.close()\n",
    "\n",
    "# También visualizamos el logaritmo del precio (que suele ser más normal)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(train_data['log_prezo'], kde=True)\n",
    "plt.title('Distribución del logaritmo de precios de viviendas')\n",
    "plt.xlabel('Log(Precio)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.savefig('distribucion_log_precios.png')\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de características utilizadas: 69\n",
      "Columnas categóricas: Index(['tipo_edificacion', 'calidade_materiais', 'cor_favorita_propietario',\n",
      "       'acceso_transporte_publico', 'orientacion', 'eficiencia_enerxetica'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 3. Preparación de datos para modelado\n",
    "# Identificar características y variable objetivo\n",
    "# Excluimos 'id', 'prezo_euros', 'log_prezo' y columnas duplicadas al final del dataset\n",
    "target_column = 'prezo_euros'\n",
    "log_target_column = 'log_prezo'\n",
    "\n",
    "# Eliminar columnas duplicadas y el ID\n",
    "all_columns = train_data.columns.tolist()\n",
    "features = [col for col in all_columns if col not in ['id', 'prezo_euros', 'log_prezo', 'is_outlier']]\n",
    "\n",
    "# Eliminamos columnas duplicadas que aparecen dos veces al final del dataset\n",
    "unique_features = []\n",
    "for feature in features:\n",
    "    if feature not in unique_features:\n",
    "        unique_features.append(feature)\n",
    "    else:\n",
    "        print(f\"Columna duplicada encontrada: {feature}\")\n",
    "\n",
    "features = unique_features\n",
    "print(f\"\\nNúmero de características utilizadas: {len(features)}\")\n",
    "\n",
    "# Separar features y target\n",
    "X = train_data[features]\n",
    "y = train_data[target_column]  # Predecimos el precio real\n",
    "\n",
    "# Identificar las columnas categóricas\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "print(\"Columnas categóricas:\", categorical_columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    X[col] = label_encoder.fit_transform(X[col])\n",
    "\n",
    "y_log = train_data[log_target_column]  # También guardamos el log para probarlo\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "_, _, y_log_train, y_log_val = train_test_split(X, y_log, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Definir función para evaluar modelos\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"Métricas para {model_name}:\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Random Forest...\n",
      "Métricas para Random Forest:\n",
      "MSE: 2256589805.98\n",
      "RMSE: 47503.58\n",
      "MAE: 33734.34\n",
      "R²: 0.9153\n",
      "--------------------------------------------------\n",
      "\n",
      "Entrenando Gradient Boosting...\n",
      "Métricas para Gradient Boosting:\n",
      "MSE: 2072149947.68\n",
      "RMSE: 45520.87\n",
      "MAE: 32043.91\n",
      "R²: 0.9222\n",
      "--------------------------------------------------\n",
      "\n",
      "Entrenando XGBoost...\n",
      "Métricas para XGBoost:\n",
      "MSE: 2208504632.49\n",
      "RMSE: 46994.73\n",
      "MAE: 33745.69\n",
      "R²: 0.9171\n",
      "--------------------------------------------------\n",
      "\n",
      "Entrenando MLP (Red Neuronal)...\n",
      "Métricas para MLP (Red Neuronal):\n",
      "MSE: 2596796553.78\n",
      "RMSE: 50958.77\n",
      "MAE: 35124.06\n",
      "R²: 0.9025\n",
      "--------------------------------------------------\n",
      "\n",
      "Entrenando Ridge Regression...\n",
      "Métricas para Ridge Regression:\n",
      "MSE: 2939553103.03\n",
      "RMSE: 54217.65\n",
      "MAE: 38907.78\n",
      "R²: 0.8897\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 5. Entrenar y evaluar modelos base\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# Modelo 1: Random Forest\n",
    "print(\"\\nEntrenando Random Forest...\")\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100, n_jobs=-1)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_val)\n",
    "results['Random Forest'] = evaluate_model(y_val, rf_pred, \"Random Forest\")\n",
    "models['Random Forest'] = rf_model\n",
    "\n",
    "# Modelo 2: Gradient Boosting\n",
    "print(\"\\nEntrenando Gradient Boosting...\")\n",
    "gb_model = GradientBoostingRegressor(random_state=42, n_estimators=100)\n",
    "gb_model.fit(X_train, y_train)\n",
    "gb_pred = gb_model.predict(X_val)\n",
    "results['Gradient Boosting'] = evaluate_model(y_val, gb_pred, \"Gradient Boosting\")\n",
    "models['Gradient Boosting'] = gb_model\n",
    "\n",
    "# Modelo 3: XGBoost\n",
    "print(\"\\nEntrenando XGBoost...\")\n",
    "xgb_model = XGBRegressor(random_state=42, n_estimators=100, n_jobs=-1)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_val)\n",
    "results['XGBoost'] = evaluate_model(y_val, xgb_pred, \"XGBoost\")\n",
    "models['XGBoost'] = xgb_model\n",
    "\n",
    "# Modelo 4: MLP (Red Neuronal)\n",
    "print(\"\\nEntrenando MLP (Red Neuronal)...\")\n",
    "mlp_model = MLPRegressor(random_state=42, max_iter=500, hidden_layer_sizes=(100, 50), early_stopping=True)\n",
    "mlp_model.fit(X_train, y_train)\n",
    "mlp_pred = mlp_model.predict(X_val)\n",
    "results['MLP'] = evaluate_model(y_val, mlp_pred, \"MLP (Red Neuronal)\")\n",
    "models['MLP'] = mlp_model\n",
    "\n",
    "# Modelo 5: Ridge Regression\n",
    "print(\"\\nEntrenando Ridge Regression...\")\n",
    "ridge_model = Ridge(alpha=1.0, random_state=42)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "ridge_pred = ridge_model.predict(X_val)\n",
    "results['Ridge'] = evaluate_model(y_val, ridge_pred, \"Ridge Regression\")\n",
    "models['Ridge'] = ridge_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Visualizar comparación de resultados\n",
    "models_df = pd.DataFrame(results).T\n",
    "models_df = models_df.sort_values('rmse')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=models_df.index, y=models_df['rmse'])\n",
    "plt.title('RMSE por Modelo')\n",
    "plt.ylabel('RMSE')\n",
    "plt.xlabel('Modelo')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacion_modelos_rmse.png')\n",
    "plt.close()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=models_df.index, y=models_df['r2'])\n",
    "plt.title('R² por Modelo')\n",
    "plt.ylabel('R²')\n",
    "plt.xlabel('Modelo')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('comparacion_modelos_r2.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Los mejores modelos son: ['Gradient Boosting', 'XGBoost', 'Random Forest']\n",
      "\n",
      "Optimizando hiperparámetros para Gradient Boosting...\n",
      "Métricas para Gradient Boosting (Optimizado):\n",
      "MSE: 1935395436.34\n",
      "RMSE: 43993.13\n",
      "MAE: 31000.61\n",
      "R²: 0.9274\n",
      "--------------------------------------------------\n",
      "Mejores hiperparámetros para Gradient Boosting:\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "Optimizando hiperparámetros para XGBoost...\n",
      "Métricas para XGBoost (Optimizado):\n",
      "MSE: 1938279178.51\n",
      "RMSE: 44025.89\n",
      "MAE: 31070.48\n",
      "R²: 0.9272\n",
      "--------------------------------------------------\n",
      "Mejores hiperparámetros para XGBoost:\n",
      "{'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8}\n",
      "\n",
      "Optimizando hiperparámetros para Random Forest...\n",
      "Métricas para Random Forest (Optimizado):\n",
      "MSE: 2237490466.66\n",
      "RMSE: 47302.12\n",
      "MAE: 33506.99\n",
      "R²: 0.9160\n",
      "--------------------------------------------------\n",
      "Mejores hiperparámetros para Random Forest:\n",
      "{'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# 7. Optimización de hiperparámetros para los mejores modelos\n",
    "# Seleccionamos los tres mejores modelos para optimizar\n",
    "best_models = list(models_df.iloc[:3].index)\n",
    "print(f\"\\nLos mejores modelos son: {best_models}\")\n",
    "\n",
    "# Definimos los hiperparámetros a optimizar\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'MLP': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (100, 50), (100, 100)],\n",
    "        'alpha': [0.0001, 0.001, 0.01],\n",
    "        'learning_rate_init': [0.001, 0.01]\n",
    "    },\n",
    "    'Ridge': {\n",
    "        'alpha': [0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Optimización de hiperparámetros para los mejores modelos\n",
    "optimized_models = {}\n",
    "\n",
    "for model_name in best_models:\n",
    "    if model_name in param_grids:\n",
    "        print(f\"\\nOptimizando hiperparámetros para {model_name}...\")\n",
    "        \n",
    "        # Seleccionamos el modelo base correspondiente\n",
    "        if model_name == 'Random Forest':\n",
    "            base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "        elif model_name == 'XGBoost':\n",
    "            base_model = XGBRegressor(random_state=42, n_jobs=-1)\n",
    "        elif model_name == 'Gradient Boosting':\n",
    "            base_model = GradientBoostingRegressor(random_state=42)\n",
    "        elif model_name == 'MLP':\n",
    "            base_model = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "        elif model_name == 'Ridge':\n",
    "            base_model = Ridge(random_state=42)\n",
    "            \n",
    "        # Configuramos la búsqueda en grid con validación cruzada\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=base_model,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=5,\n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        # Ajustamos la búsqueda en grid\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Guardamos el mejor modelo\n",
    "        best_model = grid_search.best_estimator_\n",
    "        optimized_models[model_name] = best_model\n",
    "        \n",
    "        # Evaluamos el modelo optimizado\n",
    "        best_pred = best_model.predict(X_val)\n",
    "        results[f'{model_name} (Optimizado)'] = evaluate_model(y_val, best_pred, f\"{model_name} (Optimizado)\")\n",
    "        \n",
    "        print(f\"Mejores hiperparámetros para {model_name}:\")\n",
    "        print(grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo de Stacking...\n",
      "Métricas para Stacking:\n",
      "MSE: 1924468867.23\n",
      "RMSE: 43868.77\n",
      "MAE: 30910.17\n",
      "R²: 0.9278\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 8. Implementación de Stacking\n",
    "# Definimos los modelos base y el meta-modelo\n",
    "base_models = [\n",
    "    (name, model) for name, model in optimized_models.items()\n",
    "]\n",
    "\n",
    "# Utilizamos Ridge como meta-modelo\n",
    "meta_model = Ridge(random_state=42)\n",
    "\n",
    "# Creamos el modelo de stacking\n",
    "stacking_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nEntrenando modelo de Stacking...\")\n",
    "stacking_model.fit(X_train, y_train)\n",
    "stacking_pred = stacking_model.predict(X_val)\n",
    "results['Stacking'] = evaluate_model(y_val, stacking_pred, \"Stacking\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando modelo final con todos los datos...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['edad_vivienda', 'superficie_por_habitacion', 'superficie_total', 'ratio_interior_exterior', 'densidad_banos', 'densidad_habitaciones', 'dist_coruna', 'dist_vigo', 'dist_santiago', 'calidad_edad', 'banos_por_habitacion', 'orientacion_valor', 'eficiencia_valor', 'calidade_valor', 'transporte_valor', 'tipo_Apartamento', 'tipo_Casa', 'tipo_Chalet adosado', 'color_Amarelo', 'color_Azul', 'color_Branco', 'color_Negro', 'color_Verde', 'color_Vermello', 'tipo_Apartamento.1', 'tipo_Casa.1', 'tipo_Chalet adosado.1', 'color_Amarelo.1', 'color_Azul.1', 'color_Branco.1', 'color_Negro.1', 'color_Verde.1', 'color_Vermello.1', 'tipo_Apartamento.1.1', 'tipo_Casa.1.1', 'tipo_Chalet adosado.1.1', 'color_Amarelo.1.1', 'color_Azul.1.1', 'color_Branco.1.1', 'color_Negro.1.1', 'color_Verde.1.1', 'color_Vermello.1.1', 'tipo_Apartamento.1.1.1', 'tipo_Casa.1.1.1', 'tipo_Chalet adosado.1.1.1', 'color_Amarelo.1.1.1', 'color_Azul.1.1.1', 'color_Branco.1.1.1', 'color_Negro.1.1.1', 'color_Verde.1.1.1', 'color_Vermello.1.1.1'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_1693779/2387759160.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Preparamos el conjunto de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcategorical_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3462\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3463\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3464\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3466\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['edad_vivienda', 'superficie_por_habitacion', 'superficie_total', 'ratio_interior_exterior', 'densidad_banos', 'densidad_habitaciones', 'dist_coruna', 'dist_vigo', 'dist_santiago', 'calidad_edad', 'banos_por_habitacion', 'orientacion_valor', 'eficiencia_valor', 'calidade_valor', 'transporte_valor', 'tipo_Apartamento', 'tipo_Casa', 'tipo_Chalet adosado', 'color_Amarelo', 'color_Azul', 'color_Branco', 'color_Negro', 'color_Verde', 'color_Vermello', 'tipo_Apartamento.1', 'tipo_Casa.1', 'tipo_Chalet adosado.1', 'color_Amarelo.1', 'color_Azul.1', 'color_Branco.1', 'color_Negro.1', 'color_Verde.1', 'color_Vermello.1', 'tipo_Apartamento.1.1', 'tipo_Casa.1.1', 'tipo_Chalet adosado.1.1', 'color_Amarelo.1.1', 'color_Azul.1.1', 'color_Branco.1.1', 'color_Negro.1.1', 'color_Verde.1.1', 'color_Vermello.1.1', 'tipo_Apartamento.1.1.1', 'tipo_Casa.1.1.1', 'tipo_Chalet adosado.1.1.1', 'color_Amarelo.1.1.1', 'color_Azul.1.1.1', 'color_Branco.1.1.1', 'color_Negro.1.1.1', 'color_Verde.1.1.1', 'color_Vermello.1.1.1'] not in index\""
     ]
    }
   ],
   "source": [
    "# 9. Entrenamiento final con todos los datos y generación de predicciones\n",
    "print(\"\\nEntrenando modelo final con todos los datos...\")\n",
    "final_model = stacking_model\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# Preparamos el conjunto de test\n",
    "X_test = test_data[features]\n",
    "\n",
    "categorical_columns = X_test.select_dtypes(include=['object']).columns\n",
    "print(\"Columnas categóricas:\", categorical_columns)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    X_test[col] = label_encoder.fit_transform(X_test[col])\n",
    "\n",
    "# Realizamos la predicción en el conjunto de test\n",
    "test_predictions = final_model.predict(X_test)\n",
    "\n",
    "# Creamos el archivo de envío\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'prezo_euros': test_predictions\n",
    "})\n",
    "\n",
    "# Guardamos el archivo de envío\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nArchivo de envío 'submission.csv' generado correctamente.\")\n",
    "\n",
    "# 10. Visualizar importancia de características para algunos modelos\n",
    "if 'Random Forest' in optimized_models:\n",
    "    rf_model = optimized_models['Random Forest']\n",
    "    \n",
    "    # Importancia de características para Random Forest\n",
    "    feature_importance_rf = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': rf_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_rf.head(15))\n",
    "    plt.title('Top 15 características más importantes (Random Forest)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_rf.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nCaracterísticas más importantes (Random Forest):\")\n",
    "    print(feature_importance_rf.head(10))\n",
    "\n",
    "if 'XGBoost' in optimized_models:\n",
    "    xgb_model = optimized_models['XGBoost']\n",
    "    \n",
    "    # Importancia de características para XGBoost\n",
    "    feature_importance_xgb = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': xgb_model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_xgb.head(15))\n",
    "    plt.title('Top 15 características más importantes (XGBoost)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance_xgb.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"\\nCaracterísticas más importantes (XGBoost):\")\n",
    "    print(feature_importance_xgb.head(10))\n",
    "\n",
    "print(\"\\n¡Proceso completo! El modelo está listo para enviar a Kaggle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
