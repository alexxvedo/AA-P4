{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.8s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=32, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 50], optimizer__weight_decay=0.001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=64, lr=0.0001, module__activation=<class 'torch.nn.modules.activation.ReLU'>, module__hidden_units=[100, 100, 50], optimizer__weight_decay=0.0001; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n",
      "[CV] END batch_size=16, lr=0.01, module__activation=<class 'torch.nn.modules.activation.Tanh'>, module__hidden_units=[100, 50], optimizer__weight_decay=0; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 100.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/regressor.py\", line 91, in fit\n",
      "    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/net.py\", line 1302, in fit\n",
      "    self.partial_fit(X, y, **fit_params)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/net.py\", line 1261, in partial_fit\n",
      "    self.fit_loop(X, y, **fit_params)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/net.py\", line 1155, in fit_loop\n",
      "    self.check_data(X, y)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/regressor.py\", line 76, in check_data\n",
      "    raise ValueError(msg)\n",
      "ValueError: The target data shouldn't be 1-dimensional but instead have 2 dimensions, with the second dimension having the same size as the number of regression targets (usually 1). Please reshape your target data to be 2-dimensional (e.g. y = y.reshape(-1, 1).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The target data shouldn't be 1-dimensional but instead have 2 dimensions, with the second dimension having the same size as the number of regression targets (usually 1). Please reshape your target data to be 2-dimensional (e.g. y = y.reshape(-1, 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_1457127/1874446140.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# 6. Run hyperparameter search on training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best params:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/regressor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# this is actually a pylint bug:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# https://github.com/PyCQA/pylint/issues/1085\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNeuralNetRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, classes, **fit_params)\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_train_begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/net.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(self, X, y, epochs, **fit_params)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \"\"\"\n\u001b[0;32m-> 1155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_training_readiness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/skorch/regressor.py\u001b[0m in \u001b[0;36mcheck_data\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0;34m\"reshape your target data to be 2-dimensional \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \"(e.g. y = y.reshape(-1, 1).\")\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# pylint: disable=signature-differs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The target data shouldn't be 1-dimensional but instead have 2 dimensions, with the second dimension having the same size as the number of regression targets (usually 1). Please reshape your target data to be 2-dimensional (e.g. y = y.reshape(-1, 1)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import PrintLog\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Detect device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 1. Load already preprocessed datasets\n",
    "df_train = pd.read_csv('train_preprocesado.csv')\n",
    "df_val = pd.read_csv('val_preprocesado.csv')\n",
    "df_test = pd.read_csv('test_preprocesado.csv')\n",
    "\n",
    "# 2. Separate features and target\n",
    "y_train = df_train['prezo_euros'].values.astype(np.float32)\n",
    "y_val = df_val['prezo_euros'].values.astype(np.float32)\n",
    "X_train = df_train.drop(columns=['prezo_euros', 'id']).values.astype(np.float32)\n",
    "X_val = df_val.drop(columns=['prezo_euros', 'id']).values.astype(np.float32)\n",
    "X_test = df_test.drop(columns=['id']).values.astype(np.float32)\n",
    "\n",
    "# 3. Define PyTorch module for MLP\n",
    "def create_module(input_dim=10, hidden_units=[100, 50], activation=nn.ReLU):\n",
    "    layers = []\n",
    "    in_dim = input_dim\n",
    "    for h in hidden_units:\n",
    "        layers.append(nn.Linear(in_dim, h))\n",
    "        layers.append(activation())\n",
    "        in_dim = h\n",
    "    layers.append(nn.Linear(in_dim, 1))\n",
    "    layers.append(nn.Flatten(start_dim=0))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# 4. Wrap with skorch NeuralNetRegressor (verbose=1 already prints train/valid loss per epoch)\n",
    "input_dim = X_train.shape[1]\n",
    "net = NeuralNetRegressor(\n",
    "    module=create_module,\n",
    "    module__input_dim=input_dim,\n",
    "    max_epochs=50,\n",
    "    lr=0.001,\n",
    "    batch_size=32,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    criterion=nn.MSELoss,\n",
    "    device=device,\n",
    "    verbose=1,  # shows train and valid loss each epoch\n",
    ")\n",
    "\n",
    "# 5. Hyperparameter distribution for RandomizedSearchCV Hyperparameter distribution for RandomizedSearchCV\n",
    "dist_params = {\n",
    "    'module__hidden_units': [[50], [100], [100, 50], [100, 100, 50]],\n",
    "    'module__activation': [nn.ReLU, nn.Tanh],\n",
    "    'lr': [1e-4, 1e-3, 1e-2],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'optimizer__weight_decay': [0, 1e-4, 1e-3]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    net,\n",
    "    param_distributions=dist_params,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    verbose=2,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "# 6. Run hyperparameter search on training set\n",
    "search.fit(X_train, y_train)\n",
    "print(\"Best params:\", search.best_params_)\n",
    "\n",
    "# 7. Evaluate on validation set\n",
    "y_val_pred = search.predict(X_val)\n",
    "val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "print(f\"Validation RMSE: {val_rmse:.2f}\")\n",
    "\n",
    "# 8. Retrain on train+validation\n",
    "a = np.concatenate([X_train, X_val], axis=0)\n",
    "b = np.concatenate([y_train, y_val], axis=0)\n",
    "best_net = search.best_estimator_\n",
    "best_net.set_params(max_epochs=50)\n",
    "best_net.fit(a, b)\n",
    "\n",
    "# 9. Predict on test and save predictions\n",
    "test_preds = best_net.predict(X_test)\n",
    "out = df_test[['id']].copy()\n",
    "out['prezo_euros'] = test_preds\n",
    "out.to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "# 10. Export the trained model\n",
    "joblib.dump(best_net, 'mlp_price_model.pkl')\n",
    "print(\"Model and predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
