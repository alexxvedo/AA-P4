{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 0. Extendida: Feature Engineer + Winsorizer + Preprocessor\n",
    "# ----------------------------\n",
    "class ExtendedFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    _orientation_map = {\n",
    "        \"Norte\": 0, \"Nordeste\": 45, \"Este\": 90, \"Sudeste\": 135,\n",
    "        \"Sur\": 180, \"Sudoeste\": 225, \"Oeste\": 270, \"Noroeste\": 315,\n",
    "    }\n",
    "    def __init__(self, current_year=2025, geo_clusters=10):\n",
    "        self.current_year = current_year\n",
    "        self.geo_clusters = geo_clusters\n",
    "        self.km_model_ = None\n",
    "        self.agg_stats_ = {}\n",
    "    def fit(self, X, y=None):\n",
    "        if {\"latitud\",\"longitud\"}.issubset(X.columns):\n",
    "            coords = X[[\"latitud\",\"longitud\"]].fillna(0)\n",
    "            self.km_model_ = KMeans(n_clusters=self.geo_clusters, random_state=42)\n",
    "            self.km_model_.fit(coords)\n",
    "        if y is not None and 'tipo_edificacion' in X.columns:\n",
    "            grp = pd.DataFrame({'precio':y,'type':X['tipo_edificacion']})\n",
    "            agg = grp.groupby('type').precio.agg(['mean','std'])\n",
    "            self.agg_stats_ = agg.to_dict()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        df = X.copy()\n",
    "        # Edad\n",
    "        df['antiguedad']  = self.current_year - df['ano_construccion']\n",
    "        df['antiguedad2'] = df['antiguedad']**2\n",
    "        df['decada']      = (df['ano_construccion']//10)*10\n",
    "        # Superficies\n",
    "        df['superficie_total']      = df['superficie_interior_m2'].fillna(0) + df['superficie_exterior_m2'].fillna(0)\n",
    "        df['log_superficie_total']  = np.log1p(df['superficie_total'])\n",
    "        df['habitacion_area']       = df['superficie_interior_m2']/df['numero_habitacions'].replace(0,np.nan)\n",
    "        df['banos_area']            = df['superficie_interior_m2']/df['numero_banos'].replace(0,np.nan)\n",
    "        # Distancias\n",
    "        for col in ['distancia_centro_km','distancia_escola_km']:\n",
    "            if col in df:\n",
    "                df[f'log_{col}'] = np.log1p(df[col])\n",
    "                df[f'inv_{col}'] = 1/(df[col]+0.1)\n",
    "        # Temperatura\n",
    "        if 'temperatura_media_mes_construccion' in df:\n",
    "            t = df['temperatura_media_mes_construccion']\n",
    "            df['temp_norm'] = (t - t.mean())/t.std()\n",
    "            df['temp_sq']   = t**2\n",
    "        # Índice criminalidad\n",
    "        if 'indice_criminalidade' in df:\n",
    "            df['crime_q'] = pd.qcut(df['indice_criminalidade'],5,labels=False,duplicates='drop')\n",
    "        # Orientación\n",
    "        deg = df.get('orientacion',pd.Series()).map(self._orientation_map).fillna(0)\n",
    "        rad = np.deg2rad(deg)\n",
    "        df['orient_sin'] = np.sin(rad)\n",
    "        df['orient_cos'] = np.cos(rad)\n",
    "        # Clusters geográficos\n",
    "        if self.km_model_:\n",
    "            coords = df[['latitud','longitud']].fillna(0)\n",
    "            df['geo_cluster'] = self.km_model_.predict(coords)\n",
    "        else:\n",
    "            df['geo_cluster'] = 0\n",
    "        # Stats por tipo de edificación\n",
    "        if 'tipo_edificacion' in df and self.agg_stats_:\n",
    "            df['type_price_mean'] = df['tipo_edificacion'].map(self.agg_stats_['mean'])\n",
    "            df['type_price_std']  = df['tipo_edificacion'].map(self.agg_stats_['std'])\n",
    "        else:\n",
    "            df['type_price_mean'] = 0\n",
    "            df['type_price_std']  = 0\n",
    "        # One-hot color favorito\n",
    "        if 'cor_favorita_propietario' in df:\n",
    "            cols = pd.get_dummies(df['cor_favorita_propietario'],prefix='color')\n",
    "            df = pd.concat([df,cols],axis=1)\n",
    "        # Eliminamos originales\n",
    "        drops = [\n",
    "            'ano_construccion','superficie_interior_m2','superficie_exterior_m2',\n",
    "            'numero_habitacions','numero_banos','temperatura_media_mes_construccion',\n",
    "            'distancia_centro_km','distancia_escola_km','indice_criminalidade',\n",
    "            'orientacion','tipo_edificacion','cor_favorita_propietario'\n",
    "        ]\n",
    "        df.drop(columns=[c for c in drops if c in df], inplace=True)\n",
    "        return df\n",
    "\n",
    "class WinsorizerSelective(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower=0.005, upper=0.995, active=True):\n",
    "        self.lower=lower; self.upper=upper; self.active=active; self.bounds_={}\n",
    "    def fit(self, X, y=None):\n",
    "        if not self.active: return self\n",
    "        df = pd.DataFrame(X)\n",
    "        for c in df:\n",
    "            lo,hi = df[c].quantile(self.lower), df[c].quantile(self.upper)\n",
    "            self.bounds_[c] = (lo,hi)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if not self.active: return X\n",
    "        df = pd.DataFrame(X).copy()\n",
    "        for c,(lo,hi) in self.bounds_.items():\n",
    "            df[c] = df[c].clip(lo,hi)\n",
    "        return df.values\n",
    "\n",
    "def build_preprocessor(df_sample, is_train=True):\n",
    "    target = 'prezo_euros'\n",
    "    # numéricas\n",
    "    num_cols = df_sample.select_dtypes(include='number').columns.tolist()\n",
    "    if target in num_cols: num_cols.remove(target)\n",
    "    # placeholders generadas\n",
    "    engineered = [\n",
    "        'antiguedad','antiguedad2','decada','superficie_total','log_superficie_total',\n",
    "        'habitacion_area','banos_area','log_distancia_centro_km','inv_distancia_centro_km',\n",
    "        'log_distancia_escola_km','inv_distancia_escola_km','temp_norm','temp_sq','crime_q',\n",
    "        'orient_sin','orient_cos','geo_cluster','type_price_mean','type_price_std'\n",
    "    ]\n",
    "    num_cols += [f for f in engineered if f in df_sample.columns]\n",
    "    # categóricas\n",
    "    cat_cols = df_sample.select_dtypes(include='object').columns.tolist()\n",
    "    ordinal_maps = {\n",
    "        'calidade_materiais': ['Baixa','Media','Alta'],\n",
    "        'acceso_transporte_publico': ['Malo','Regular','Bo','Moi bo'],\n",
    "        'eficiencia_enerxetica': ['G','F','E','D','C','B','A'],\n",
    "    }\n",
    "    ord_feats = [c for c in ordinal_maps if c in cat_cols]\n",
    "    ord_cats  = [ordinal_maps[c] for c in ord_feats]\n",
    "    ohe_feats = [c for c in cat_cols if c not in ord_feats]\n",
    "\n",
    "    num_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='median')),\n",
    "        ('winsor', WinsorizerSelective(active=is_train)),\n",
    "        ('scale', RobustScaler())\n",
    "    ])\n",
    "    ord_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encode', OrdinalEncoder(categories=ord_cats))\n",
    "    ])\n",
    "    ohe_pipe= Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "    preproc = ColumnTransformer([\n",
    "        ('num', num_pipe, num_cols),\n",
    "        ('ord', ord_pipe, ord_feats),\n",
    "        ('ohe', ohe_pipe, ohe_feats)\n",
    "    ], remainder='drop', n_jobs=-1)\n",
    "\n",
    "    full = Pipeline([\n",
    "        ('feat', ExtendedFeatureEngineer()),\n",
    "        ('prep', preproc)\n",
    "    ])\n",
    "    return full, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1. Configuración y semillas\n",
    "# ----------------------------\n",
    "DATA_PATH    = 'train.csv'\n",
    "TEST_PATH    = 'test.csv'\n",
    "MODEL_DIR    = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "\n",
    "DEVICE        = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE    = 256\n",
    "MAX_EPOCHS    = 100\n",
    "PATIENCE      = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "TEST_SIZE     = 0.1\n",
    "SUBMIT_FILE   = os.path.join(MODEL_DIR,'submission_pytorch.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'superficie_interior_m2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mcol_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'superficie_interior_m2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_888045/2852853910.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_all\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0my_all\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mtransformer_to_input_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A given column is not a column of the dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 2. Carga y preprocesado\n",
    "# ----------------------------\n",
    "df        = pd.read_csv(DATA_PATH)\n",
    "df_test   = pd.read_csv(TEST_PATH)\n",
    "\n",
    "pipe, tgt = build_preprocessor(df, is_train=True)\n",
    "X_all     = pipe.fit_transform(df, df[tgt])\n",
    "y_all     = df[tgt].values\n",
    "\n",
    "# split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all, y_all, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# dataset & loader\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self,X,y=None):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float() if y is not None else None\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i):\n",
    "        return (self.X[i], self.y[i]) if self.y is not None else self.X[i]\n",
    "\n",
    "train_dl = DataLoader(HousePriceDataset(X_train,y_train),\n",
    "                      batch_size=BATCH_SIZE,shuffle=True,pin_memory=True,num_workers=2)\n",
    "val_dl   = DataLoader(HousePriceDataset(X_val,y_val),\n",
    "                      batch_size=BATCH_SIZE,shuffle=False,pin_memory=True,num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_888045/539670413.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegressionNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0moptim\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 3. Modelo\n",
    "# ----------------------------\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim,256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128,64),  nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x).squeeze(1)\n",
    "\n",
    "model = RegressionNN(X_train.shape[1]).to(DEVICE)\n",
    "\n",
    "optim   = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Training + EarlyStopping\n",
    "# ----------------------------\n",
    "best_rmse = np.inf\n",
    "wait      = 0\n",
    "\n",
    "for epoch in range(1,MAX_EPOCHS+1):\n",
    "    model.train()\n",
    "    for xb,yb in train_dl:\n",
    "        xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        loss = criterion(model(xb), yb)\n",
    "        optim.zero_grad(); loss.backward(); optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_dl:\n",
    "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            preds = model(xb)\n",
    "            losses.append(((preds-yb)**2).mean().item())\n",
    "    rmse = np.sqrt(np.mean(losses))\n",
    "    print(f\"Epoch {epoch:03d} \u0014 Val RMSE: {rmse:.2f}\")\n",
    "    if rmse + 1e-4 < best_rmse:\n",
    "        best_rmse = rmse; wait = 0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR,'best.pt'))\n",
    "    else:\n",
    "        wait+=1\n",
    "        if wait>=PATIENCE:\n",
    "            print(\"EarlyStopping!\") \n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR,'best.pt')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 5. Inference y submission\n",
    "# ----------------------------\n",
    "# Desactiva winsor en test\n",
    "pipe.set_params(prep__num__winsor__active=False)\n",
    "\n",
    "X_test = pipe.transform(df_test)\n",
    "test_dl = DataLoader(HousePriceDataset(X_test),batch_size=BATCH_SIZE,\n",
    "                     shuffle=False,pin_memory=True,num_workers=2)\n",
    "\n",
    "preds=[]\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb in test_dl:\n",
    "        xb = xb.to(DEVICE)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "preds = np.concatenate(preds,axis=0)\n",
    "\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'prezo_euros': preds})\n",
    "submission.to_csv(SUBMIT_FILE,index=False)\n",
    "print(f\"Submission guardada en {SUBMIT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1. Extended Feature Engineer (usa el nombre exacto de columnas de tu CSV)\n",
    "# -----------------------------------------------------------------------------\n",
    "class ExtendedFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    _orientation_map = {\n",
    "      \"Norte\": 0, \"Nordeste\": 45, \"Este\": 90, \"Sudeste\": 135,\n",
    "      \"Sur\": 180, \"Sudoeste\": 225, \"Oeste\": 270, \"Noroeste\": 315,\n",
    "    }\n",
    "    def __init__(self, current_year=2025, geo_clusters=10):\n",
    "        self.current_year = current_year\n",
    "        self.geo_clusters = geo_clusters\n",
    "        self.km_model_ = None\n",
    "        self.agg_stats_ = {}\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Ajusta KMeans con 'latitude' y 'lonxitude'\n",
    "        if {\"latitude\",\"lonxitude\"}.issubset(X.columns):\n",
    "            coords = X[[\"latitude\",\"lonxitude\"]].fillna(0)\n",
    "            self.km_model_ = KMeans(n_clusters=self.geo_clusters, random_state=42)\n",
    "            self.km_model_.fit(coords)\n",
    "        # Estadísticas por tipo_edificacion\n",
    "        if y is not None and \"tipo_edificacion\" in X.columns:\n",
    "            grp = pd.DataFrame({\"precio\": y, \"type\": X[\"tipo_edificacion\"]})\n",
    "            agg = grp.groupby(\"type\").precio.agg([\"mean\",\"std\"])\n",
    "            self.agg_stats_ = agg.to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        df = X.copy()\n",
    "        # Edad\n",
    "        df[\"antiguedad\"]   = self.current_year - df[\"ano_construccion\"]\n",
    "        df[\"antiguedad2\"]  = df[\"antiguedad\"]**2\n",
    "        df[\"decada\"]       = (df[\"ano_construccion\"]//10)*10\n",
    "        # Superficies\n",
    "        df[\"superficie_total\"]     = df[\"superficie_interior_m2\"].fillna(0) + df[\"superficie_exterior_m2\"].fillna(0)\n",
    "        df[\"log_superficie_total\"] = np.log1p(df[\"superficie_total\"])\n",
    "        df[\"habitacion_area\"]      = df[\"superficie_interior_m2\"]/df[\"numero_habitacions\"].replace(0,np.nan)\n",
    "        df[\"banos_area\"]           = df[\"superficie_interior_m2\"]/df[\"numero_banos\"].replace(0,np.nan)\n",
    "        # Distancias\n",
    "        for c in [\"distancia_centro_km\",\"distancia_escola_km\"]:\n",
    "            if c in df:\n",
    "                df[f\"log_{c}\"] = np.log1p(df[c])\n",
    "                df[f\"inv_{c}\"] = 1/(df[c]+0.1)\n",
    "        # Temperatura\n",
    "        if \"temperatura_media_mes_construccion\" in df:\n",
    "            t = df[\"temperatura_media_mes_construccion\"]\n",
    "            df[\"temp_norm\"] = (t - t.mean())/t.std()\n",
    "            df[\"temp_sq\"]   = t**2\n",
    "        # Índice criminalidad\n",
    "        if \"indice_criminalidade\" in df:\n",
    "            df[\"crime_q\"] = pd.qcut(df[\"indice_criminalidade\"],5,labels=False,duplicates=\"drop\")\n",
    "        # Orientación\n",
    "        deg = df.get(\"orientacion\", pd.Series()).map(self._orientation_map).fillna(0)\n",
    "        rad = np.deg2rad(deg)\n",
    "        df[\"orient_sin\"] = np.sin(rad)\n",
    "        df[\"orient_cos\"] = np.cos(rad)\n",
    "        # Geo-clusters\n",
    "        if self.km_model_ is not None:\n",
    "            coords = df[[\"latitude\",\"lonxitude\"]].fillna(0)\n",
    "            df[\"geo_cluster\"] = self.km_model_.predict(coords)\n",
    "        else:\n",
    "            df[\"geo_cluster\"] = 0\n",
    "        # Stats por tipo_edificacion\n",
    "        if \"tipo_edificacion\" in df and self.agg_stats_:\n",
    "            df[\"type_price_mean\"] = df[\"tipo_edificacion\"].map(self.agg_stats_[\"mean\"])\n",
    "            df[\"type_price_std\"]  = df[\"tipo_edificacion\"].map(self.agg_stats_[\"std\"])\n",
    "        else:\n",
    "            df[\"type_price_mean\"] = 0\n",
    "            df[\"type_price_std\"]  = 0\n",
    "        # One-hot color favorito\n",
    "        if \"cor_favorita_propietario\" in df:\n",
    "            cols = pd.get_dummies(df[\"cor_favorita_propietario\"], prefix=\"color\")\n",
    "            df = pd.concat([df, cols], axis=1)\n",
    "        # Eliminar las originales\n",
    "        drops = [\n",
    "          \"ano_construccion\",\"superficie_interior_m2\",\"superficie_exterior_m2\",\n",
    "          \"numero_habitacions\",\"numero_banos\",\"temperatura_media_mes_construccion\",\n",
    "          \"distancia_centro_km\",\"distancia_escola_km\",\"indice_criminalidade\",\n",
    "          \"orientacion\",\"tipo_edificacion\",\"cor_favorita_propietario\",\"fecha\"\n",
    "        ]\n",
    "        for c in drops:\n",
    "            if c in df: df.drop(columns=c, inplace=True)\n",
    "        return df\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2. Winsorizer Selectivo\n",
    "# -----------------------------------------------------------------------------\n",
    "class WinsorizerSelective(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower=0.005, upper=0.995, active=True):\n",
    "        self.lower, self.upper, self.active = lower, upper, active\n",
    "        self.bounds_ = {}\n",
    "    def fit(self, X, y=None):\n",
    "        if not self.active: return self\n",
    "        df = pd.DataFrame(X)\n",
    "        for c in df.columns:\n",
    "            lo = df[c].quantile(self.lower)\n",
    "            hi = df[c].quantile(self.upper)\n",
    "            self.bounds_[c] = (lo,hi)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if not self.active: return X\n",
    "        df = pd.DataFrame(X).copy()\n",
    "        for c,(lo,hi) in self.bounds_.items():\n",
    "            df[c] = df[c].clip(lo,hi)\n",
    "        return df.values\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 \u0014 Val RMSE: 277646.80\n",
      "Epoch 002 \u0014 Val RMSE: 237224.98\n",
      "Epoch 003 \u0014 Val RMSE: 143107.71\n",
      "Epoch 004 \u0014 Val RMSE: 80829.19\n",
      "Epoch 005 \u0014 Val RMSE: 72275.65\n",
      "Epoch 006 \u0014 Val RMSE: 67498.47\n",
      "Epoch 007 \u0014 Val RMSE: 63859.09\n",
      "Epoch 008 \u0014 Val RMSE: 61025.03\n",
      "Epoch 009 \u0014 Val RMSE: 58807.05\n",
      "Epoch 010 \u0014 Val RMSE: 56705.42\n",
      "Epoch 011 \u0014 Val RMSE: 55020.72\n",
      "Epoch 012 \u0014 Val RMSE: 53601.27\n",
      "Epoch 013 \u0014 Val RMSE: 52245.53\n",
      "Epoch 014 \u0014 Val RMSE: 50839.45\n",
      "Epoch 015 \u0014 Val RMSE: 49565.80\n",
      "Epoch 016 \u0014 Val RMSE: 48435.39\n",
      "Epoch 017 \u0014 Val RMSE: 46615.49\n",
      "Epoch 018 \u0014 Val RMSE: 45111.30\n",
      "Epoch 019 \u0014 Val RMSE: 43437.27\n",
      "Epoch 020 \u0014 Val RMSE: 41655.45\n",
      "Epoch 021 \u0014 Val RMSE: 39612.38\n",
      "Epoch 022 \u0014 Val RMSE: 37504.06\n",
      "Epoch 023 \u0014 Val RMSE: 35097.13\n",
      "Epoch 024 \u0014 Val RMSE: 32482.15\n",
      "Epoch 025 \u0014 Val RMSE: 29492.38\n",
      "Epoch 026 \u0014 Val RMSE: 26490.58\n",
      "Epoch 027 \u0014 Val RMSE: 23415.04\n",
      "Epoch 028 \u0014 Val RMSE: 20167.78\n",
      "Epoch 029 \u0014 Val RMSE: 17104.09\n",
      "Epoch 030 \u0014 Val RMSE: 14050.47\n",
      "Epoch 031 \u0014 Val RMSE: 11982.98\n",
      "Epoch 032 \u0014 Val RMSE: 10072.03\n",
      "Epoch 033 \u0014 Val RMSE: 9087.21\n",
      "Epoch 034 \u0014 Val RMSE: 8437.27\n",
      "Epoch 035 \u0014 Val RMSE: 7905.39\n",
      "Epoch 036 \u0014 Val RMSE: 7754.41\n",
      "Epoch 037 \u0014 Val RMSE: 8177.48\n",
      "Epoch 038 \u0014 Val RMSE: 6982.79\n",
      "Epoch 039 \u0014 Val RMSE: 7170.31\n",
      "Epoch 040 \u0014 Val RMSE: 6650.30\n",
      "Epoch 041 \u0014 Val RMSE: 6483.33\n",
      "Epoch 042 \u0014 Val RMSE: 6954.91\n",
      "Epoch 043 \u0014 Val RMSE: 7352.60\n",
      "Epoch 044 \u0014 Val RMSE: 7157.40\n",
      "Epoch 045 \u0014 Val RMSE: 6977.64\n",
      "Epoch 046 \u0014 Val RMSE: 6712.50\n",
      "Epoch 047 \u0014 Val RMSE: 6515.97\n",
      "Epoch 048 \u0014 Val RMSE: 6465.43\n",
      "Epoch 049 \u0014 Val RMSE: 6459.06\n",
      "Epoch 050 \u0014 Val RMSE: 6696.23\n",
      "Epoch 051 \u0014 Val RMSE: 6246.89\n",
      "Epoch 052 \u0014 Val RMSE: 6599.45\n",
      "Epoch 053 \u0014 Val RMSE: 7179.91\n",
      "Epoch 054 \u0014 Val RMSE: 6357.90\n",
      "Epoch 055 \u0014 Val RMSE: 6847.88\n",
      "Epoch 056 \u0014 Val RMSE: 6392.12\n",
      "Epoch 057 \u0014 Val RMSE: 6646.94\n",
      "Epoch 058 \u0014 Val RMSE: 6560.46\n",
      "Epoch 059 \u0014 Val RMSE: 7325.90\n",
      "Epoch 060 \u0014 Val RMSE: 6697.39\n",
      "Epoch 061 \u0014 Val RMSE: 6725.87\n",
      "EarlyStopping!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['prezo_euros'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1422\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1423\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1424\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_888045/1890592042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_transformers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"winsor\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test_fe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m test_dl = DataLoader(HPDataset(X_test), batch_size=BATCH_SIZE,\n\u001b[1;32m    135\u001b[0m                         shuffle=False, num_workers=2, pin_memory=True)\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0m_transform_one\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mfitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mcolumn_as_strings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_dataframe_and_transform_dataframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 )\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             )\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1948\u001b[0m         \u001b[0;31m# reach the first `yield` statement. This starts the aynchronous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0;31m# dispatch of the tasks to the workers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1950\u001b[0;31m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1586\u001b[0m         \u001b[0mdetach_generator_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1588\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1589\u001b[0m             \u001b[0;31m# first yield returns None, for internal use only. This ensures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m             \u001b[0;31m# that we enter the try/except block and start dispatching the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_start\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m                     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 )\n\u001b[0;32m--> 615\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             )\n\u001b[1;32m    617\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;31m# check whether we should index with loc or iloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkey_dtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"int\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multi_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple_same_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0;31m# We should never have retval.ndim < self.ndim, as that should\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0;31m#  be handled by the _getitem_lowerdim call above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['prezo_euros'] not in index\""
     ]
    }
   ],
   "source": [
    "# -- Configuración --\n",
    "DATA_PATH  = \"train.csv\"\n",
    "TEST_PATH  = \"test.csv\"\n",
    "MODEL_DIR  = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "SEED       = 42\n",
    "np.random.seed(SEED); random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
    "DEVICE    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE  = 256\n",
    "TEST_SIZE   = 0.1\n",
    "MAX_EPOCHS  = 100\n",
    "PATIENCE    = 10\n",
    "LR          = 1e-3\n",
    "SUBMIT_FILE = os.path.join(MODEL_DIR,\"submission_pytorch.csv\")\n",
    "\n",
    "# -- 1) Leo datos --\n",
    "df       = pd.read_csv(DATA_PATH)\n",
    "df_test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# -- 2) Feature Engineering --\n",
    "feat_eng = ExtendedFeatureEngineer(current_year=2025, geo_clusters=10)\n",
    "feat_eng.fit(df, df[\"prezo_euros\"].values)\n",
    "df_fe       = feat_eng.transform(df)\n",
    "df_test_fe  = feat_eng.transform(df_test)\n",
    "\n",
    "# -- 3) ColumnTransformer sobre df_fe --\n",
    "# Detecto numéricas y ordinales\n",
    "num_cols = df_fe.select_dtypes(include=np.number).columns.tolist()\n",
    "# (no hay target en df_fe, así no hay que removerlo)\n",
    "ord_feats = [f for f in [\"calidade_materiais\",\n",
    "                            \"acceso_transporte_publico\",\n",
    "                            \"eficiencia_enerxetica\"]\n",
    "                if f in df_fe.columns]\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"winsor\", WinsorizerSelective(active=True)),\n",
    "    (\"scale\", RobustScaler())\n",
    "])\n",
    "ord_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encode\", OrdinalEncoder(categories=[\n",
    "        [\"Baixa\",\"Media\",\"Alta\"],\n",
    "        [\"Malo\",\"Regular\",\"Bo\",\"Moi bo\"],\n",
    "        [\"G\",\"F\",\"E\",\"D\",\"C\",\"B\",\"A\"]\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"ord\", ord_pipe, ord_feats),\n",
    "], remainder=\"drop\", n_jobs=-1)\n",
    "\n",
    "X_all = preproc.fit_transform(df_fe)\n",
    "y_all = df[\"prezo_euros\"].values\n",
    "\n",
    "# -- 4) Split train/val --\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_all, y_all, test_size=TEST_SIZE,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "# -- 5) DataLoaders --\n",
    "class HPDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float() if y is not None else None\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self,i):\n",
    "        return (self.X[i], self.y[i]) if self.y is not None else self.X[i]\n",
    "\n",
    "tr_dl  = DataLoader(HPDataset(X_tr,y_tr), batch_size=BATCH_SIZE,\n",
    "                    shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_dl = DataLoader(HPDataset(X_val,y_val), batch_size=BATCH_SIZE,\n",
    "                    shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# -- 6) Modelo PyTorch (mismo que antes) --\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, d): \n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d,256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128,64),  nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x).squeeze(1)\n",
    "\n",
    "model   = RegressionNN(X_tr.shape[1]).to(DEVICE)\n",
    "optim    = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn  = nn.MSELoss()\n",
    "\n",
    "# -- 7) Entrenamiento + EarlyStopping --\n",
    "best_rmse = np.inf\n",
    "wait      = 0\n",
    "\n",
    "for ep in range(1, MAX_EPOCHS+1):\n",
    "    model.train()\n",
    "    for xb,yb in tr_dl:\n",
    "        xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        loss = loss_fn(model(xb), yb)\n",
    "        optim.zero_grad(); loss.backward(); optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    vals = []\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_dl:\n",
    "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            p = model(xb)\n",
    "            vals.append(((p-yb)**2).mean().item())\n",
    "    rmse = np.sqrt(np.mean(vals))\n",
    "    print(f\"Epoch {ep:03d} \u0014 Val RMSE: {rmse:.2f}\")\n",
    "\n",
    "    if rmse + 1e-4 < best_rmse:\n",
    "        best_rmse = rmse; wait = 0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR,\"best.pt\"))\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(\"EarlyStopping!\") \n",
    "            break\n",
    "\n",
    "# cargo el mejor\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR,\"best.pt\")))\n",
    "\n",
    "# -- 8) Inference en test --\n",
    "# Desactivo winsor\n",
    "preproc.named_transformers_[\"num\"].named_steps[\"winsor\"].active = False\n",
    "\n",
    "X_test = preproc.transform(df_test_fe)\n",
    "test_dl = DataLoader(HPDataset(X_test), batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb in test_dl:\n",
    "        xb = xb.to(DEVICE)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "# -- 9) Submission --\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    \"prezo_euros\": preds\n",
    "})\n",
    "submission.to_csv(SUBMIT_FILE, index=False)\n",
    "print(\"Submission guardada en\", SUBMIT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/ipykernel_launcher.py:74: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 \u0014 Val RMSE: 276841.25\n",
      "Epoch 002 \u0014 Val RMSE: 225659.90\n",
      "Epoch 003 \u0014 Val RMSE: 125480.16\n",
      "Epoch 004 \u0014 Val RMSE: 86156.02\n",
      "Epoch 005 \u0014 Val RMSE: 79636.00\n",
      "Epoch 006 \u0014 Val RMSE: 75523.72\n",
      "Epoch 007 \u0014 Val RMSE: 72652.40\n",
      "Epoch 008 \u0014 Val RMSE: 70622.13\n",
      "Epoch 009 \u0014 Val RMSE: 69402.00\n",
      "Epoch 010 \u0014 Val RMSE: 68188.64\n",
      "Epoch 011 \u0014 Val RMSE: 67500.02\n",
      "Epoch 012 \u0014 Val RMSE: 67000.54\n",
      "Epoch 013 \u0014 Val RMSE: 66664.15\n",
      "Epoch 014 \u0014 Val RMSE: 66401.92\n",
      "Epoch 015 \u0014 Val RMSE: 66403.15\n",
      "Epoch 016 \u0014 Val RMSE: 66085.30\n",
      "Epoch 017 \u0014 Val RMSE: 65960.38\n",
      "Epoch 018 \u0014 Val RMSE: 65953.91\n",
      "Epoch 019 \u0014 Val RMSE: 65850.73\n",
      "Epoch 020 \u0014 Val RMSE: 65808.87\n",
      "Epoch 021 \u0014 Val RMSE: 65987.14\n",
      "Epoch 022 \u0014 Val RMSE: 65612.94\n",
      "Epoch 023 \u0014 Val RMSE: 65677.18\n",
      "Epoch 024 \u0014 Val RMSE: 65779.35\n",
      "Epoch 025 \u0014 Val RMSE: 65500.46\n",
      "Epoch 026 \u0014 Val RMSE: 65525.02\n",
      "Epoch 027 \u0014 Val RMSE: 65492.09\n",
      "Epoch 028 \u0014 Val RMSE: 65435.15\n",
      "Epoch 029 \u0014 Val RMSE: 65484.67\n",
      "Epoch 030 \u0014 Val RMSE: 65493.20\n",
      "Epoch 031 \u0014 Val RMSE: 65634.56\n",
      "Epoch 032 \u0014 Val RMSE: 65437.89\n",
      "Epoch 033 \u0014 Val RMSE: 65379.95\n",
      "Epoch 034 \u0014 Val RMSE: 65398.39\n",
      "Epoch 035 \u0014 Val RMSE: 65525.56\n",
      "Epoch 036 \u0014 Val RMSE: 65487.83\n",
      "Epoch 037 \u0014 Val RMSE: 65377.52\n",
      "Epoch 038 \u0014 Val RMSE: 65347.92\n",
      "Epoch 039 \u0014 Val RMSE: 65331.51\n",
      "Epoch 040 \u0014 Val RMSE: 65420.64\n",
      "Epoch 041 \u0014 Val RMSE: 65381.38\n",
      "Epoch 042 \u0014 Val RMSE: 65445.86\n",
      "Epoch 043 \u0014 Val RMSE: 65228.53\n",
      "Epoch 044 \u0014 Val RMSE: 65348.99\n",
      "Epoch 045 \u0014 Val RMSE: 65309.14\n",
      "Epoch 046 \u0014 Val RMSE: 65414.72\n",
      "Epoch 047 \u0014 Val RMSE: 65299.53\n",
      "Epoch 048 \u0014 Val RMSE: 65331.34\n",
      "Epoch 049 \u0014 Val RMSE: 65216.68\n",
      "Epoch 050 \u0014 Val RMSE: 65213.30\n",
      "Epoch 051 \u0014 Val RMSE: 65153.47\n",
      "Epoch 052 \u0014 Val RMSE: 65291.02\n",
      "Epoch 053 \u0014 Val RMSE: 65233.74\n",
      "Epoch 054 \u0014 Val RMSE: 65115.12\n",
      "Epoch 055 \u0014 Val RMSE: 65108.43\n",
      "Epoch 056 \u0014 Val RMSE: 65476.21\n",
      "Epoch 057 \u0014 Val RMSE: 65194.09\n",
      "Epoch 058 \u0014 Val RMSE: 65168.66\n",
      "Epoch 059 \u0014 Val RMSE: 65196.60\n",
      "Epoch 060 \u0014 Val RMSE: 65472.08\n",
      "Epoch 061 \u0014 Val RMSE: 65046.78\n",
      "Epoch 062 \u0014 Val RMSE: 65082.06\n",
      "Epoch 063 \u0014 Val RMSE: 65033.80\n",
      "Epoch 064 \u0014 Val RMSE: 65028.93\n",
      "Epoch 065 \u0014 Val RMSE: 65014.68\n",
      "Epoch 066 \u0014 Val RMSE: 64917.02\n",
      "Epoch 067 \u0014 Val RMSE: 64896.36\n",
      "Epoch 068 \u0014 Val RMSE: 64971.03\n",
      "Epoch 069 \u0014 Val RMSE: 64844.75\n",
      "Epoch 070 \u0014 Val RMSE: 65068.81\n",
      "Epoch 071 \u0014 Val RMSE: 64910.94\n",
      "Epoch 072 \u0014 Val RMSE: 64822.69\n",
      "Epoch 073 \u0014 Val RMSE: 64810.20\n",
      "Epoch 074 \u0014 Val RMSE: 64921.91\n",
      "Epoch 075 \u0014 Val RMSE: 64869.52\n",
      "Epoch 076 \u0014 Val RMSE: 64702.41\n",
      "Epoch 077 \u0014 Val RMSE: 65133.15\n",
      "Epoch 078 \u0014 Val RMSE: 64645.54\n",
      "Epoch 079 \u0014 Val RMSE: 64686.14\n",
      "Epoch 080 \u0014 Val RMSE: 64626.39\n",
      "Epoch 081 \u0014 Val RMSE: 64629.79\n",
      "Epoch 082 \u0014 Val RMSE: 64674.94\n",
      "Epoch 083 \u0014 Val RMSE: 64611.43\n",
      "Epoch 084 \u0014 Val RMSE: 64650.73\n",
      "Epoch 085 \u0014 Val RMSE: 64457.56\n",
      "Epoch 086 \u0014 Val RMSE: 64595.58\n",
      "Epoch 087 \u0014 Val RMSE: 64537.92\n",
      "Epoch 088 \u0014 Val RMSE: 64420.37\n",
      "Epoch 089 \u0014 Val RMSE: 64390.38\n",
      "Epoch 090 \u0014 Val RMSE: 64469.28\n",
      "Epoch 091 \u0014 Val RMSE: 64483.36\n",
      "Epoch 092 \u0014 Val RMSE: 64327.62\n",
      "Epoch 093 \u0014 Val RMSE: 64387.25\n",
      "Epoch 094 \u0014 Val RMSE: 64456.38\n",
      "Epoch 095 \u0014 Val RMSE: 64239.98\n",
      "Epoch 096 \u0014 Val RMSE: 64475.52\n",
      "Epoch 097 \u0014 Val RMSE: 64300.25\n",
      "Epoch 098 \u0014 Val RMSE: 64204.79\n",
      "Epoch 099 \u0014 Val RMSE: 64271.64\n",
      "Epoch 100 \u0014 Val RMSE: 64119.22\n",
      "Submission guardada en models/submission_pytorch.csv\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH  = \"train.csv\"\n",
    "TEST_PATH  = \"test.csv\"\n",
    "MODEL_DIR  = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "SEED       = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 256\n",
    "TEST_SIZE  = 0.1\n",
    "MAX_EPOCHS = 100\n",
    "PATIENCE   = 10\n",
    "LR         = 1e-3\n",
    "SUBMIT_FILE= os.path.join(MODEL_DIR,\"submission_pytorch.csv\")\n",
    "\n",
    "### 1) Leer datos ###\n",
    "df       = pd.read_csv(DATA_PATH)\n",
    "df_test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Separamos id y target\n",
    "y = df[\"prezo_euros\"].values\n",
    "X = df.drop(columns=[\"id\",\"prezo_euros\"])\n",
    "\n",
    "### 2) Feature Engineering ###\n",
    "feat_eng = ExtendedFeatureEngineer(current_year=2025, geo_clusters=10)\n",
    "feat_eng.fit(X, y)\n",
    "df_fe      = feat_eng.transform(X)\n",
    "df_test_fe = feat_eng.transform(df_test.drop(columns=[\"id\"]))\n",
    "\n",
    "### 3) Construir ColumnTransformer sobre df_fe ###\n",
    "# Columnas numéricas dinámicas\n",
    "num_cols = df_fe.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Columnas ordinales específicas\n",
    "ord_feats = [c for c in [\n",
    "    \"calidade_materiais\",\n",
    "    \"acceso_transporte_publico\",\n",
    "    \"eficiencia_enerxetica\"\n",
    "] if c in df_fe.columns]\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"winsor\", WinsorizerSelective(active=True)),\n",
    "    (\"scale\", RobustScaler())\n",
    "])\n",
    "ord_pipe = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encode\", OrdinalEncoder(categories=[\n",
    "        [\"Baixa\",\"Media\",\"Alta\"],\n",
    "        [\"Malo\",\"Regular\",\"Bo\",\"Moi bo\"],\n",
    "        [\"G\",\"F\",\"E\",\"D\",\"C\",\"B\",\"A\"]\n",
    "    ]))\n",
    "])\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"ord\", ord_pipe, ord_feats)\n",
    "], remainder=\"drop\", n_jobs=-1)\n",
    "\n",
    "# Preprocesado final\n",
    "X_all = preproc.fit_transform(df_fe, y)\n",
    "y_all = y\n",
    "\n",
    "### 4) Split train/val ###\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_all, y_all,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "### 5) DataLoaders ###\n",
    "class HPDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float() if y is not None else None\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i):\n",
    "        return (self.X[i], self.y[i]) if self.y is not None else self.X[i]\n",
    "\n",
    "train_dl = DataLoader(HPDataset(X_tr, y_tr),\n",
    "                        batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        num_workers=2, pin_memory=True)\n",
    "val_dl   = DataLoader(HPDataset(X_val, y_val),\n",
    "                        batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=2, pin_memory=True)\n",
    "\n",
    "### 6) Modelo PyTorch ###\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, 256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256,128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128,64),  nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "    def forward(self, x): return self.net(x).squeeze(1)\n",
    "\n",
    "model   = RegressionNN(X_tr.shape[1]).to(DEVICE)\n",
    "optim    = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn  = nn.MSELoss()\n",
    "\n",
    "### 7) Entrenamiento + EarlyStopping ###\n",
    "best_rmse, wait = np.inf, 0\n",
    "for ep in range(1, MAX_EPOCHS+1):\n",
    "    model.train()\n",
    "    for xb,yb in train_dl:\n",
    "        xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        loss = loss_fn(model(xb), yb)\n",
    "        optim.zero_grad(); loss.backward(); optim.step()\n",
    "\n",
    "    model.eval()\n",
    "    vals = []\n",
    "    with torch.no_grad():\n",
    "        for xb,yb in val_dl:\n",
    "            xb,yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            p     = model(xb)\n",
    "            vals.append(((p-yb)**2).mean().item())\n",
    "    rmse = np.sqrt(np.mean(vals))\n",
    "    print(f\"Epoch {ep:03d} \u0014 Val RMSE: {rmse:.2f}\")\n",
    "\n",
    "    if rmse + 1e-4 < best_rmse:\n",
    "        best_rmse, wait = rmse, 0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR,\"best.pt\"))\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(\"EarlyStopping!\") \n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR,\"best.pt\")))\n",
    "\n",
    "### 8) Inference en test ###\n",
    "# Desactivo winsor para no recortar en test\n",
    "preproc.named_transformers_[\"num\"].named_steps[\"winsor\"].active = False\n",
    "\n",
    "X_test = preproc.transform(df_test_fe)\n",
    "test_dl = DataLoader(HPDataset(X_test),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=2,\n",
    "                        pin_memory=True)\n",
    "\n",
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb in test_dl:\n",
    "        xb = xb.to(DEVICE)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "### 9) Submission ###\n",
    "submission = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"],\n",
    "    \"prezo_euros\": preds\n",
    "})\n",
    "submission.to_csv(SUBMIT_FILE, index=False)\n",
    "print(\"Submission guardada en\", SUBMIT_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
