{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:39:24,136 - __main__ - INFO - Iniciando pipeline de entrenamiento XGBoost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>superficie_interior_m2</th>\n",
       "      <th>superficie_exterior_m2</th>\n",
       "      <th>numero_habitacions</th>\n",
       "      <th>numero_banos</th>\n",
       "      <th>ano_construccion</th>\n",
       "      <th>lonxitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>temperatura_media_mes_construccion</th>\n",
       "      <th>tipo_edificacion</th>\n",
       "      <th>...</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>tipo_Apartamento.1</th>\n",
       "      <th>tipo_Casa.1</th>\n",
       "      <th>tipo_Chalet adosado.1</th>\n",
       "      <th>color_Amarelo.1</th>\n",
       "      <th>color_Azul.1</th>\n",
       "      <th>color_Branco.1</th>\n",
       "      <th>color_Negro.1</th>\n",
       "      <th>color_Verde.1</th>\n",
       "      <th>color_Vermello.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25521</td>\n",
       "      <td>-1.214878</td>\n",
       "      <td>-0.600905</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1947</td>\n",
       "      <td>-8.17</td>\n",
       "      <td>43.20</td>\n",
       "      <td>24.75</td>\n",
       "      <td>Apartamento</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4843</td>\n",
       "      <td>-0.590517</td>\n",
       "      <td>-0.493874</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1977</td>\n",
       "      <td>-7.23</td>\n",
       "      <td>43.60</td>\n",
       "      <td>14.06</td>\n",
       "      <td>Apartamento</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27734</td>\n",
       "      <td>1.723563</td>\n",
       "      <td>-0.371180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>42.25</td>\n",
       "      <td>12.27</td>\n",
       "      <td>Chalet adosado</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22142</td>\n",
       "      <td>0.415219</td>\n",
       "      <td>-0.533578</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1996</td>\n",
       "      <td>-6.81</td>\n",
       "      <td>43.15</td>\n",
       "      <td>11.61</td>\n",
       "      <td>Chalet adosado</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14748</td>\n",
       "      <td>1.203970</td>\n",
       "      <td>2.040511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>-8.76</td>\n",
       "      <td>42.92</td>\n",
       "      <td>10.04</td>\n",
       "      <td>Casa</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  superficie_interior_m2  superficie_exterior_m2  numero_habitacions  \\\n",
       "0  25521               -1.214878               -0.600905                   1   \n",
       "1   4843               -0.590517               -0.493874                   2   \n",
       "2  27734                1.723563               -0.371180                   1   \n",
       "3  22142                0.415219               -0.533578                   4   \n",
       "4  14748                1.203970                2.040511                   1   \n",
       "\n",
       "   numero_banos  ano_construccion  lonxitude  latitude  \\\n",
       "0             2              1947      -8.17     43.20   \n",
       "1             2              1977      -7.23     43.60   \n",
       "2             1              1996      -8.40     42.25   \n",
       "3             2              1996      -6.81     43.15   \n",
       "4             1              1990      -8.76     42.92   \n",
       "\n",
       "   temperatura_media_mes_construccion tipo_edificacion  ... is_outlier  \\\n",
       "0                               24.75      Apartamento  ...      False   \n",
       "1                               14.06      Apartamento  ...      False   \n",
       "2                               12.27   Chalet adosado  ...      False   \n",
       "3                               11.61   Chalet adosado  ...      False   \n",
       "4                               10.04             Casa  ...      False   \n",
       "\n",
       "  tipo_Apartamento.1  tipo_Casa.1  tipo_Chalet adosado.1  color_Amarelo.1  \\\n",
       "0                  1            0                      0                0   \n",
       "1                  1            0                      0                0   \n",
       "2                  0            0                      1                0   \n",
       "3                  0            0                      1                0   \n",
       "4                  0            1                      0                0   \n",
       "\n",
       "  color_Azul.1 color_Branco.1 color_Negro.1  color_Verde.1  color_Vermello.1  \n",
       "0            1              0             0              0                 0  \n",
       "1            0              0             0              1                 0  \n",
       "2            0              1             0              0                 0  \n",
       "3            0              0             0              0                 1  \n",
       "4            0              0             0              1                 0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:39:24,218 - __main__ - INFO - Datos cargados correctamente: 20000 filas, 54 columnas\n",
      "2025-05-06 17:39:24,218 - __main__ - INFO - \n",
      "Resumen estadístico:\n",
      "2025-05-06 17:39:24,218 - __main__ - INFO - Dimensiones: (20000, 54)\n",
      "2025-05-06 17:39:24,226 - __main__ - INFO - Valores faltantes por columna:\n",
      "Series([], dtype: int64)\n",
      "2025-05-06 17:39:24,228 - __main__ - INFO - Columnas numéricas: 45\n",
      "2025-05-06 17:39:24,228 - __main__ - INFO - Columnas categóricas: 6\n",
      "2025-05-06 17:39:24,234 - __main__ - INFO - Iniciando preprocesamiento de datos\n",
      "2025-05-06 17:39:24,327 - __main__ - INFO - Imputador y scaler guardados en models\n",
      "2025-05-06 17:39:24,344 - __main__ - INFO - Codificadores guardados en models\n",
      "2025-05-06 17:39:24,350 - __main__ - INFO - División de datos: 17000 muestras de entrenamiento, 3000 de validación\n",
      "2025-05-06 17:39:24,351 - __main__ - INFO - Iniciando búsqueda de hiperparámetros con Optuna (100 trials)\n",
      "[I 2025-05-06 17:39:24,351] A new study created in memory with name: no-name-444670f3-e997-4506-b8bf-6172961e48a9\n",
      "[I 2025-05-06 17:39:57,669] Trial 0 finished with value: 30522.80868212891 and parameters: {'learning_rate': 0.008468008575248327, 'max_depth': 12, 'min_child_weight': 37, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'lambda': 0.004207053950287938, 'alpha': 0.0017073967431528124, 'gamma': 4.330880728874676, 'grow_policy': 'lossguide', 'max_leaves': 5, 'max_bin': 505}. Best is trial 0 with value: 30522.80868212891.\n",
      "[I 2025-05-06 17:40:00,214] Trial 1 finished with value: 30325.927751367184 and parameters: {'learning_rate': 0.11536162338241392, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.5917022549267169, 'colsample_bytree': 0.6521211214797689, 'lambda': 0.12561043700013558, 'alpha': 0.05342937261279776, 'gamma': 1.4561457009902097, 'grow_policy': 'depthwise', 'max_leaves': 75, 'max_bin': 350}. Best is trial 1 with value: 30325.927751367184.\n",
      "[I 2025-05-06 17:41:54,645] Trial 2 finished with value: 30237.64639511719 and parameters: {'learning_rate': 0.013481575603601416, 'max_depth': 10, 'min_child_weight': 10, 'subsample': 0.7571172192068059, 'colsample_bytree': 0.7962072844310213, 'lambda': 0.0015339162591163618, 'alpha': 0.26926469100861794, 'gamma': 0.8526206184364576, 'grow_policy': 'lossguide', 'max_leaves': 248, 'max_bin': 463}. Best is trial 2 with value: 30237.64639511719.\n",
      "[I 2025-05-06 17:42:28,370] Trial 3 finished with value: 30531.649991308594 and parameters: {'learning_rate': 0.0056828375585122656, 'max_depth': 3, 'min_child_weight': 35, 'subsample': 0.7200762468698007, 'colsample_bytree': 0.5610191174223894, 'lambda': 0.09565499215943825, 'alpha': 0.0013726318898045872, 'gamma': 4.546602010393911, 'grow_policy': 'lossguide', 'max_leaves': 80, 'max_bin': 389}. Best is trial 2 with value: 30237.64639511719.\n",
      "[I 2025-05-06 17:42:47,555] Trial 4 finished with value: 30167.09520722656 and parameters: {'learning_rate': 0.02260828676373495, 'max_depth': 4, 'min_child_weight': 49, 'subsample': 0.8875664116805573, 'colsample_bytree': 0.9697494707820946, 'lambda': 3.7958531426706403, 'alpha': 0.24637685958997463, 'gamma': 4.609371175115584, 'grow_policy': 'lossguide', 'max_leaves': 11, 'max_bin': 339}. Best is trial 4 with value: 30167.09520722656.\n",
      "[I 2025-05-06 17:43:30,800] Trial 5 finished with value: 29991.620129296876 and parameters: {'learning_rate': 0.00917911425163946, 'max_depth': 5, 'min_child_weight': 42, 'subsample': 0.6783766633467947, 'colsample_bytree': 0.6404672548436904, 'lambda': 0.14817820606039092, 'alpha': 0.0036618192203924276, 'gamma': 4.010984903770199, 'grow_policy': 'lossguide', 'max_leaves': 198, 'max_bin': 307}. Best is trial 5 with value: 29991.620129296876.\n",
      "[I 2025-05-06 17:44:44,718] Trial 6 finished with value: 32213.449820898437 and parameters: {'learning_rate': 0.0010319982330247674, 'max_depth': 11, 'min_child_weight': 36, 'subsample': 0.8645035840204937, 'colsample_bytree': 0.8856351733429728, 'lambda': 0.0019777828512462727, 'alpha': 0.02715581955282941, 'gamma': 0.5793452976256486, 'grow_policy': 'depthwise', 'max_leaves': 85, 'max_bin': 272}. Best is trial 5 with value: 29991.620129296876.\n",
      "[I 2025-05-06 17:45:19,940] Trial 7 finished with value: 30025.181326367187 and parameters: {'learning_rate': 0.005893060761114622, 'max_depth': 6, 'min_child_weight': 37, 'subsample': 0.8187787356776066, 'colsample_bytree': 0.9436063712881633, 'lambda': 0.0774211647399625, 'alpha': 0.003008686821445846, 'gamma': 3.566223936114975, 'grow_policy': 'depthwise', 'max_leaves': 198, 'max_bin': 382}. Best is trial 5 with value: 29991.620129296876.\n",
      "[I 2025-05-06 17:45:33,761] Trial 8 finished with value: 29951.70249882813 and parameters: {'learning_rate': 0.019718442220616167, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5539457134966522, 'colsample_bytree': 0.5157145928433671, 'lambda': 0.35127047262708466, 'alpha': 0.018089390092767135, 'gamma': 2.542853455823514, 'grow_policy': 'depthwise', 'max_leaves': 105, 'max_bin': 450}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:46:03,488] Trial 9 finished with value: 30819.25257763672 and parameters: {'learning_rate': 0.0036877442861551015, 'max_depth': 3, 'min_child_weight': 15, 'subsample': 0.5806106436270022, 'colsample_bytree': 0.9648488261712865, 'lambda': 1.7079750342958235, 'alpha': 0.34167643418329696, 'gamma': 4.357302950938589, 'grow_policy': 'depthwise', 'max_leaves': 229, 'max_bin': 394}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:46:08,620] Trial 10 finished with value: 30823.23664667969 and parameters: {'learning_rate': 0.08419971167624792, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.5089809378074097, 'colsample_bytree': 0.5072552314167731, 'lambda': 0.8529494377627208, 'alpha': 6.903717055434683, 'gamma': 2.694232938321996, 'grow_policy': 'depthwise', 'max_leaves': 141, 'max_bin': 445}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:46:26,287] Trial 11 finished with value: 30110.673426171874 and parameters: {'learning_rate': 0.033846175254018875, 'max_depth': 7, 'min_child_weight': 24, 'subsample': 0.6642242348394745, 'colsample_bytree': 0.6802639230418349, 'lambda': 0.4088812669376903, 'alpha': 0.007542481944789031, 'gamma': 2.527794140583878, 'grow_policy': 'lossguide', 'max_leaves': 161, 'max_bin': 262}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:46:41,102] Trial 12 finished with value: 30378.56871152344 and parameters: {'learning_rate': 0.05059805262424324, 'max_depth': 8, 'min_child_weight': 49, 'subsample': 0.9828472877209868, 'colsample_bytree': 0.677346428615168, 'lambda': 0.01598519049727414, 'alpha': 0.011701191748027962, 'gamma': 3.3362280523931753, 'grow_policy': 'lossguide', 'max_leaves': 199, 'max_bin': 310}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:46:43,055] Trial 13 finished with value: 31368.940635351562 and parameters: {'learning_rate': 0.23131829516555288, 'max_depth': 6, 'min_child_weight': 26, 'subsample': 0.635696404804212, 'colsample_bytree': 0.5036317587811662, 'lambda': 8.031094986587314, 'alpha': 0.006945727049204129, 'gamma': 1.671680435920643, 'grow_policy': 'depthwise', 'max_leaves': 115, 'max_bin': 440}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:48:19,886] Trial 14 finished with value: 30058.759900390625 and parameters: {'learning_rate': 0.002143731578083862, 'max_depth': 9, 'min_child_weight': 26, 'subsample': 0.5017522294643687, 'colsample_bytree': 0.5936551134412327, 'lambda': 0.025473383418482144, 'alpha': 0.030114130729586602, 'gamma': 3.4685962495481, 'grow_policy': 'depthwise', 'max_leaves': 177, 'max_bin': 492}. Best is trial 8 with value: 29951.70249882813.\n",
      "[I 2025-05-06 17:48:51,450] Trial 15 finished with value: 29726.791765039066 and parameters: {'learning_rate': 0.014561965098307202, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.663992660734231, 'colsample_bytree': 0.7580143193422603, 'lambda': 0.42518821371924465, 'alpha': 5.928440456998787, 'gamma': 1.7919514239527086, 'grow_policy': 'lossguide', 'max_leaves': 112, 'max_bin': 416}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:49:05,835] Trial 16 finished with value: 29730.528277148434 and parameters: {'learning_rate': 0.019749690370975046, 'max_depth': 7, 'min_child_weight': 2, 'subsample': 0.5818346578628171, 'colsample_bytree': 0.786844733752796, 'lambda': 0.48411425337539016, 'alpha': 9.848932254968787, 'gamma': 1.8033959850277823, 'grow_policy': 'depthwise', 'max_leaves': 49, 'max_bin': 420}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:49:17,870] Trial 17 finished with value: 29876.506561328126 and parameters: {'learning_rate': 0.04217937364553562, 'max_depth': 5, 'min_child_weight': 7, 'subsample': 0.6232393643060067, 'colsample_bytree': 0.770837914243513, 'lambda': 1.3113324528089367, 'alpha': 5.645515751221936, 'gamma': 1.505152466626335, 'grow_policy': 'lossguide', 'max_leaves': 37, 'max_bin': 417}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:50:03,547] Trial 18 finished with value: 29947.98335214844 and parameters: {'learning_rate': 0.015214884170955895, 'max_depth': 9, 'min_child_weight': 18, 'subsample': 0.7201778857522847, 'colsample_bytree': 0.8400779529046856, 'lambda': 0.4001999940575961, 'alpha': 1.6940660589848116, 'gamma': 1.9882531576527924, 'grow_policy': 'lossguide', 'max_leaves': 53, 'max_bin': 413}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:50:07,483] Trial 19 finished with value: 30243.442364843748 and parameters: {'learning_rate': 0.08324045541133376, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.5653055199473161, 'colsample_bytree': 0.7149872794581776, 'lambda': 0.02672420947072981, 'alpha': 1.6094475602319005, 'gamma': 0.08679201752884325, 'grow_policy': 'depthwise', 'max_leaves': 40, 'max_bin': 475}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:50:44,085] Trial 20 finished with value: 30643.35256582031 and parameters: {'learning_rate': 0.00252036476258264, 'max_depth': 4, 'min_child_weight': 17, 'subsample': 0.685840191091291, 'colsample_bytree': 0.8248328747926553, 'lambda': 2.405730721833829, 'alpha': 2.082125798291699, 'gamma': 1.0145594644272422, 'grow_policy': 'depthwise', 'max_leaves': 125, 'max_bin': 355}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:50:56,213] Trial 21 finished with value: 29829.928938671877 and parameters: {'learning_rate': 0.03729224237705339, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6220809916657736, 'colsample_bytree': 0.7591797267442771, 'lambda': 1.0000023325135172, 'alpha': 9.946126450457445, 'gamma': 1.9868195493945986, 'grow_policy': 'lossguide', 'max_leaves': 36, 'max_bin': 420}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:51:09,338] Trial 22 finished with value: 29889.065138476562 and parameters: {'learning_rate': 0.030419306138452954, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.637948277961116, 'colsample_bytree': 0.7377865612230857, 'lambda': 0.6595819571062189, 'alpha': 3.537362005314268, 'gamma': 1.956718759569798, 'grow_policy': 'lossguide', 'max_leaves': 57, 'max_bin': 427}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:51:19,069] Trial 23 finished with value: 30014.252173632813 and parameters: {'learning_rate': 0.06033281886507357, 'max_depth': 6, 'min_child_weight': 5, 'subsample': 0.6053702645405754, 'colsample_bytree': 0.877222803034642, 'lambda': 5.199332602575501, 'alpha': 9.202602325459797, 'gamma': 2.126098037731915, 'grow_policy': 'lossguide', 'max_leaves': 25, 'max_bin': 405}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:52:14,328] Trial 24 finished with value: 29833.776649609375 and parameters: {'learning_rate': 0.011553760498885218, 'max_depth': 7, 'min_child_weight': 11, 'subsample': 0.5406830653609522, 'colsample_bytree': 0.7620982972275638, 'lambda': 0.22628555534489206, 'alpha': 0.7285055717495915, 'gamma': 3.046510009679418, 'grow_policy': 'lossguide', 'max_leaves': 94, 'max_bin': 379}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:52:32,602] Trial 25 finished with value: 29841.29085449219 and parameters: {'learning_rate': 0.02546129314016683, 'max_depth': 5, 'min_child_weight': 14, 'subsample': 0.7201295933971152, 'colsample_bytree': 0.7270334992083364, 'lambda': 0.9532312560157212, 'alpha': 4.0339184858411175, 'gamma': 1.1739372607022405, 'grow_policy': 'lossguide', 'max_leaves': 62, 'max_bin': 432}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:52:35,999] Trial 26 finished with value: 30646.42275566406 and parameters: {'learning_rate': 0.1680566941727306, 'max_depth': 4, 'min_child_weight': 22, 'subsample': 0.6600491457137759, 'colsample_bytree': 0.8061822874555999, 'lambda': 2.718490366435987, 'alpha': 0.7967209297105302, 'gamma': 2.222189024827081, 'grow_policy': 'lossguide', 'max_leaves': 141, 'max_bin': 468}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:53:03,945] Trial 27 finished with value: 29810.325763671874 and parameters: {'learning_rate': 0.019936133568739092, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.7674143168602259, 'colsample_bytree': 0.8698698674322948, 'lambda': 0.05741348258404135, 'alpha': 8.875764367256703, 'gamma': 2.921114025068194, 'grow_policy': 'lossguide', 'max_leaves': 26, 'max_bin': 372}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:53:40,640] Trial 28 finished with value: 29770.021051171876 and parameters: {'learning_rate': 0.007217246927515492, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.7684567977522573, 'colsample_bytree': 0.907096614951835, 'lambda': 0.04987092096338724, 'alpha': 3.069460349479968, 'gamma': 3.0616072623160235, 'grow_policy': 'depthwise', 'max_leaves': 20, 'max_bin': 366}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:53:41,342] Trial 29 finished with value: 137406.367259375 and parameters: {'learning_rate': 0.0064179325393732495, 'max_depth': 11, 'min_child_weight': 12, 'subsample': 0.8133117646209015, 'colsample_bytree': 0.9208192536789207, 'lambda': 0.006236039920397246, 'alpha': 2.769684332881291, 'gamma': 3.918176007091774, 'grow_policy': 'depthwise', 'max_leaves': 1, 'max_bin': 500}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:54:18,061] Trial 30 finished with value: 30425.362329687498 and parameters: {'learning_rate': 0.0037740228360549867, 'max_depth': 9, 'min_child_weight': 29, 'subsample': 0.8696131630949446, 'colsample_bytree': 0.9226515028781562, 'lambda': 0.045335810403674445, 'alpha': 1.0359952160126646, 'gamma': 2.962891265772261, 'grow_policy': 'depthwise', 'max_leaves': 13, 'max_bin': 328}. Best is trial 15 with value: 29726.791765039066.\n",
      "[I 2025-05-06 17:54:46,792] Trial 31 finished with value: 29708.551159960938 and parameters: {'learning_rate': 0.008563397226240926, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.7735831217204824, 'colsample_bytree': 0.8567299808807762, 'lambda': 0.055318342469879225, 'alpha': 3.7951613060707063, 'gamma': 3.11169162738614, 'grow_policy': 'depthwise', 'max_leaves': 21, 'max_bin': 372}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 17:55:16,543] Trial 32 finished with value: 29792.012654492184 and parameters: {'learning_rate': 0.008922585992436867, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.8005253303938332, 'colsample_bytree': 0.8556148624161874, 'lambda': 0.009660610605774002, 'alpha': 3.9661940269619613, 'gamma': 2.345775160917182, 'grow_policy': 'depthwise', 'max_leaves': 64, 'max_bin': 364}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 17:55:46,808] Trial 33 finished with value: 29829.34902490234 and parameters: {'learning_rate': 0.012159613304936099, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.7675346491686746, 'colsample_bytree': 0.8981923810551214, 'lambda': 0.1909846342333812, 'alpha': 0.4959051615858574, 'gamma': 1.6802410766075029, 'grow_policy': 'depthwise', 'max_leaves': 21, 'max_bin': 400}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 17:57:21,944] Trial 34 finished with value: 30348.896447460935 and parameters: {'learning_rate': 0.004750992587960189, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7084341996542152, 'colsample_bytree': 0.7962495901794323, 'lambda': 0.03712903744600612, 'alpha': 0.12973384141874225, 'gamma': 3.2248166861131757, 'grow_policy': 'depthwise', 'max_leaves': 0, 'max_bin': 344}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 17:57:56,059] Trial 35 finished with value: 29807.43321914063 and parameters: {'learning_rate': 0.007409009016528592, 'max_depth': 8, 'min_child_weight': 8, 'subsample': 0.8417082065705896, 'colsample_bytree': 0.8216143118585228, 'lambda': 0.0997340197515361, 'alpha': 1.2407141649325706, 'gamma': 3.685386449408509, 'grow_policy': 'depthwise', 'max_leaves': 47, 'max_bin': 323}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 17:58:16,174] Trial 36 finished with value: 30041.58415957031 and parameters: {'learning_rate': 0.015667693443630806, 'max_depth': 12, 'min_child_weight': 10, 'subsample': 0.9152458162544559, 'colsample_bytree': 0.9842376063977007, 'lambda': 0.3016257179860487, 'alpha': 4.451797389156497, 'gamma': 4.86284565940834, 'grow_policy': 'depthwise', 'max_leaves': 81, 'max_bin': 359}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 17:58:45,896] Trial 37 finished with value: 29811.273161328125 and parameters: {'learning_rate': 0.010257240233495685, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7472236161623518, 'colsample_bytree': 0.7872518960762216, 'lambda': 0.12330477771439438, 'alpha': 0.12129195084724288, 'gamma': 1.2983892327402626, 'grow_policy': 'depthwise', 'max_leaves': 92, 'max_bin': 388}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:00:06,260] Trial 38 finished with value: 30043.037989843746 and parameters: {'learning_rate': 0.0022088637949735147, 'max_depth': 9, 'min_child_weight': 31, 'subsample': 0.7439172636147793, 'colsample_bytree': 0.8481775836466877, 'lambda': 0.5814288570998314, 'alpha': 2.592873610897582, 'gamma': 0.8329079620896436, 'grow_policy': 'depthwise', 'max_leaves': 71, 'max_bin': 370}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:00:57,645] Trial 39 finished with value: 32828.43223417969 and parameters: {'learning_rate': 0.0013055318150707407, 'max_depth': 11, 'min_child_weight': 13, 'subsample': 0.7842904876373281, 'colsample_bytree': 0.9034403289516038, 'lambda': 0.0030448637788760735, 'alpha': 5.68917130964408, 'gamma': 2.678513668249872, 'grow_policy': 'depthwise', 'max_leaves': 19, 'max_bin': 334}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:01:43,607] Trial 40 finished with value: 29772.194352734376 and parameters: {'learning_rate': 0.004990752549707158, 'max_depth': 7, 'min_child_weight': 8, 'subsample': 0.6867425724507935, 'colsample_bytree': 0.9989036901425076, 'lambda': 0.016440090217165845, 'alpha': 0.06835050183921348, 'gamma': 3.9751890748932484, 'grow_policy': 'depthwise', 'max_leaves': 34, 'max_bin': 283}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:02:39,487] Trial 41 finished with value: 29738.16017402344 and parameters: {'learning_rate': 0.004346068855874028, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.6973543189668895, 'colsample_bytree': 0.9998429294777827, 'lambda': 0.012168857516199746, 'alpha': 0.06437984804347807, 'gamma': 4.002188591040543, 'grow_policy': 'depthwise', 'max_leaves': 35, 'max_bin': 286}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:03:41,202] Trial 42 finished with value: 29818.960481640628 and parameters: {'learning_rate': 0.0033088155179301607, 'max_depth': 8, 'min_child_weight': 4, 'subsample': 0.8367767132239857, 'colsample_bytree': 0.9480450770644245, 'lambda': 0.06507656836316275, 'alpha': 0.24832669462260326, 'gamma': 4.352473175076099, 'grow_policy': 'depthwise', 'max_leaves': 45, 'max_bin': 293}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:04:22,437] Trial 43 finished with value: 29953.8210046875 and parameters: {'learning_rate': 0.00800411099741744, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.6992370395510149, 'colsample_bytree': 0.947587353057868, 'lambda': 0.1861192251454639, 'alpha': 0.04744489143585395, 'gamma': 3.789964168019219, 'grow_policy': 'depthwise', 'max_leaves': 9, 'max_bin': 456}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:04:34,355] Trial 44 finished with value: 29812.120289648436 and parameters: {'learning_rate': 0.023868426750668754, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.7392687350901437, 'colsample_bytree': 0.6986146787490974, 'lambda': 0.010270572609118732, 'alpha': 5.841613332169389, 'gamma': 2.810577029251479, 'grow_policy': 'depthwise', 'max_leaves': 27, 'max_bin': 404}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:04:54,630] Trial 45 finished with value: 29870.88764277344 and parameters: {'learning_rate': 0.013718452631681083, 'max_depth': 10, 'min_child_weight': 7, 'subsample': 0.7885714334706818, 'colsample_bytree': 0.9197379985941248, 'lambda': 0.0010400700591837056, 'alpha': 2.528585329378512, 'gamma': 3.201142555254059, 'grow_policy': 'depthwise', 'max_leaves': 72, 'max_bin': 314}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:05:37,512] Trial 46 finished with value: 30011.867728515626 and parameters: {'learning_rate': 0.006037753178867375, 'max_depth': 8, 'min_child_weight': 45, 'subsample': 0.6543254846388857, 'colsample_bytree': 0.7805704511465267, 'lambda': 0.00431021159132146, 'alpha': 0.5289811852808097, 'gamma': 2.366541917989773, 'grow_policy': 'depthwise', 'max_leaves': 108, 'max_bin': 435}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:06:11,100] Trial 47 finished with value: 30715.478287109378 and parameters: {'learning_rate': 0.0041235175512831694, 'max_depth': 3, 'min_child_weight': 17, 'subsample': 0.5972479780292419, 'colsample_bytree': 0.8200438548701152, 'lambda': 0.029596845430803355, 'alpha': 0.14990452805359325, 'gamma': 4.701100062900215, 'grow_policy': 'depthwise', 'max_leaves': 246, 'max_bin': 349}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:06:25,398] Trial 48 finished with value: 30018.401354101563 and parameters: {'learning_rate': 0.017600968220641316, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.5287028547587449, 'colsample_bytree': 0.6331805602784701, 'lambda': 0.01683099220063363, 'alpha': 0.03242058450861336, 'gamma': 4.1998932490572205, 'grow_policy': 'depthwise', 'max_leaves': 159, 'max_bin': 259}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:07:34,971] Trial 49 finished with value: 29715.402208203122 and parameters: {'learning_rate': 0.0030035429551007733, 'max_depth': 7, 'min_child_weight': 3, 'subsample': 0.5751310874954975, 'colsample_bytree': 0.9629286963814135, 'lambda': 0.10013426856944585, 'alpha': 0.06366592320873718, 'gamma': 3.516129392531644, 'grow_policy': 'depthwise', 'max_leaves': 51, 'max_bin': 389}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:08:40,794] Trial 50 finished with value: 30544.93553496094 and parameters: {'learning_rate': 0.001605660194125121, 'max_depth': 6, 'min_child_weight': 20, 'subsample': 0.5658132521074046, 'colsample_bytree': 0.9718988768761956, 'lambda': 0.12883537578765697, 'alpha': 0.07384559701360927, 'gamma': 3.498801296642017, 'grow_policy': 'depthwise', 'max_leaves': 51, 'max_bin': 394}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:09:24,477] Trial 51 finished with value: 29783.582364550784 and parameters: {'learning_rate': 0.0069625713050472686, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.5745037928251955, 'colsample_bytree': 0.9987258745873118, 'lambda': 0.08110216661072597, 'alpha': 0.051122476251506246, 'gamma': 3.3824965105851073, 'grow_policy': 'depthwise', 'max_leaves': 13, 'max_bin': 382}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:10:33,794] Trial 52 finished with value: 29795.228672460937 and parameters: {'learning_rate': 0.0029215232320169197, 'max_depth': 6, 'min_child_weight': 3, 'subsample': 0.5262986595047825, 'colsample_bytree': 0.9553465513142464, 'lambda': 0.24906585320353863, 'alpha': 0.015445036017945779, 'gamma': 4.153190417140732, 'grow_policy': 'depthwise', 'max_leaves': 33, 'max_bin': 412}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:11:09,196] Trial 53 finished with value: 29711.361689062498 and parameters: {'learning_rate': 0.00885246453556989, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.6067320266720466, 'colsample_bytree': 0.9354245789400908, 'lambda': 0.5609297598852518, 'alpha': 0.08719815467976785, 'gamma': 3.611868203883148, 'grow_policy': 'depthwise', 'max_leaves': 63, 'max_bin': 423}. Best is trial 31 with value: 29708.551159960938.\n",
      "[I 2025-05-06 18:11:58,252] Trial 54 finished with value: 29706.911756835936 and parameters: {'learning_rate': 0.004977835452567715, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6117872362400538, 'colsample_bytree': 0.9772030720108622, 'lambda': 0.5542259794155255, 'alpha': 0.19132441816022186, 'gamma': 3.6685657355105947, 'grow_policy': 'depthwise', 'max_leaves': 88, 'max_bin': 424}. Best is trial 54 with value: 29706.911756835936.\n",
      "[I 2025-05-06 18:12:40,009] Trial 55 finished with value: 29710.186063085937 and parameters: {'learning_rate': 0.00964884116060136, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.6138453563721263, 'colsample_bytree': 0.7436344838944223, 'lambda': 0.5274775178551474, 'alpha': 0.20653544212070465, 'gamma': 3.6197198018464336, 'grow_policy': 'lossguide', 'max_leaves': 95, 'max_bin': 423}. Best is trial 54 with value: 29706.911756835936.\n",
      "[W 2025-05-06 18:13:00,907] Trial 56 failed with parameters: {'learning_rate': 0.009626616625074134, 'max_depth': 5, 'min_child_weight': 6, 'subsample': 0.6109354715020417, 'colsample_bytree': 0.9323642476794194, 'lambda': 1.614887272098404, 'alpha': 0.15904329077092275, 'gamma': 3.720686896386529, 'grow_policy': 'lossguide', 'max_leaves': 95, 'max_bin': 448} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_64025/2515943617.py\", line 396, in <lambda>\n",
      "    lambda trial: objective(trial, X_processed, y, CONFIG['cv_folds']),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_64025/2515943617.py\", line 332, in objective\n",
      "    model = xgb.train(\n",
      "            ^^^^^^^^^^\n",
      "  File \"/usr/lib/python3/dist-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3/dist-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/usr/lib/python3/dist-packages/xgboost/core.py\", line 2051, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-06 18:13:00,908] Trial 56 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 496\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 496\u001b[0m         \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    498\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError en el pipeline: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 395\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIniciando búsqueda de hiperparámetros con Optuna (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_trials\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trials)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    390\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    391\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    392\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcv_folds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_trials\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores hiperparámetros encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, value \u001b[38;5;129;01min\u001b[39;00m study\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[8], line 396\u001b[0m, in \u001b[0;36mmain.<locals>.<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    388\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIniciando búsqueda de hiperparámetros con Optuna (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_trials\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m trials)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    390\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    391\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    392\u001b[0m     sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    393\u001b[0m )\n\u001b[1;32m    395\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_processed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcv_folds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    397\u001b[0m     n_trials\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_trials\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    398\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    399\u001b[0m )\n\u001b[1;32m    401\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores hiperparámetros encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, value \u001b[38;5;129;01min\u001b[39;00m study\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[8], line 332\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, X, y, cv_folds)\u001b[0m\n\u001b[1;32m    329\u001b[0m dval \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_fold_val, label\u001b[38;5;241m=\u001b[39my_fold_val)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# Entrenar modelo\u001b[39;00m\n\u001b[0;32m--> 332\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_boost_rounds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mearly_stopping_rounds\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Evaluar usando MAE\u001b[39;00m\n\u001b[1;32m    342\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(dval)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/xgboost/core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/xgboost/core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2050\u001b[0m     _check_call(\n\u001b[0;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2054\u001b[0m     )\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "XGBoost Modeling Pipeline (MAE Optimized)\n",
    "----------------------------------------\n",
    "Script optimizado para entrenamiento de un modelo XGBoost con validación cruzada,\n",
    "búsqueda de hiperparámetros usando Optuna, y generación de predicciones para test.\n",
    "Este script está específicamente optimizado para minimizar el Error Absoluto Medio (MAE).\n",
    "\n",
    "Características:\n",
    "- Optimización enfocada en MAE en lugar de RMSE\n",
    "- Preprocesamiento robusto con manejo inteligente de valores faltantes\n",
    "- Validación cruzada con múltiples métricas de evaluación\n",
    "- Optimización bayesiana de hiperparámetros con Optuna\n",
    "- Análisis de importancia de características\n",
    "- Serialización de todos los componentes del pipeline\n",
    "- Logging detallado\n",
    "\"\"\"\n",
    "\n",
    "!pip install optuna\n",
    "\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"xgboost_training.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ignorar warnings específicos\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "CONFIG = {\n",
    "    # Rutas\n",
    "    'data_path': 'train_processed.csv',\n",
    "    'test_path': 'test_processed.csv',\n",
    "    'output_dir': 'models',\n",
    "    \n",
    "    # Nombres de archivos\n",
    "    'model_file': 'xgboost_model.json',\n",
    "    'encoders_file': 'label_encoders.pkl',\n",
    "    'scaler_file': 'scaler.pkl',\n",
    "    'imputer_file': 'imputer.pkl',\n",
    "    'feature_importance_file': 'feature_importance.png',\n",
    "    'submission_file': 'submission_mae.csv',\n",
    "    'config_file': 'model_config.json',\n",
    "    \n",
    "    # Parámetros de división de datos\n",
    "    'test_size': 0.15,          # Aumentado para una validación más robusta\n",
    "    'random_state': 42,\n",
    "    \n",
    "    # Parámetros XGBoost\n",
    "    'eval_metric': 'mae',       # Cambiado a MAE como métrica principal\n",
    "    'cv_folds': 5,\n",
    "    'max_boost_rounds': 3000,   # Aumentado para permitir más iteraciones\n",
    "    'early_stopping_rounds': 50,\n",
    "    \n",
    "    # Optuna\n",
    "    'n_trials': 2,           # Número de combinaciones de hiperparámetros a probar\n",
    "    'timeout': 3600,           # Tiempo máximo en segundos (1 hora)\n",
    "    \n",
    "    # Target y columna ID\n",
    "    'target_column': 'prezo_euros',\n",
    "    'id_column': 'id',\n",
    "    \n",
    "    # Hardware\n",
    "    'use_gpu': True,          # Cambiar a True si tienes GPU disponible\n",
    "}\n",
    "\n",
    "# Crear directorio de salida\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "# Guardar configuración\n",
    "with open(os.path.join(CONFIG['output_dir'], CONFIG['config_file']), 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=4)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Funciones auxiliares\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Carga los datos desde un archivo CSV.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        df.drop('log_prezo', axis=1, inplace=True)\n",
    "        display(df.head())\n",
    "\n",
    "        logger.info(f\"Datos cargados correctamente: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al cargar datos: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def analyze_data(df: pd.DataFrame) -> Tuple[List[str], List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Analiza el dataframe y clasifica las columnas.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple con listas de columnas numéricas, categóricas y la columna objetivo\n",
    "    \"\"\"\n",
    "    # Detectar automáticamente tipos de columnas\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Remover columna objetivo y ID de las listas\n",
    "    if CONFIG['target_column'] in num_cols:\n",
    "        num_cols.remove(CONFIG['target_column'])\n",
    "    if CONFIG['id_column'] in num_cols:\n",
    "        num_cols.remove(CONFIG['id_column'])\n",
    "    if CONFIG['id_column'] in cat_cols:\n",
    "        cat_cols.remove(CONFIG['id_column'])\n",
    "        \n",
    "    logger.info(f\"Columnas numéricas: {len(num_cols)}\")\n",
    "    logger.info(f\"Columnas categóricas: {len(cat_cols)}\")\n",
    "    \n",
    "    return num_cols, cat_cols, [CONFIG['target_column']]\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, num_cols: List[str], cat_cols: List[str], \n",
    "                   is_training: bool = True) -> Tuple[pd.DataFrame, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Preprocesa los datos aplicando imputación, codificación y escalado.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame original\n",
    "        num_cols: Lista de columnas numéricas\n",
    "        cat_cols: Lista de columnas categóricas\n",
    "        is_training: Si es True, entrena los transformadores, si no, usa los guardados\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame preprocesado, diccionarios con transformadores\n",
    "    \"\"\"\n",
    "    X = df.copy()\n",
    "    \n",
    "    # Eliminar columna 'Unnamed: 0' si existe (solo en test)\n",
    "    if 'Unnamed: 0' in X.columns:\n",
    "        X.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        logger.info(\"Columna 'Unnamed: 0' eliminada del conjunto de datos\")\n",
    "    \n",
    "    # Eliminar columna 'is_outlier' si existe (solo en train) para mantener consistencia\n",
    "    if 'is_outlier' in X.columns:\n",
    "        X.drop('is_outlier', axis=1, inplace=True)\n",
    "        logger.info(\"Columna 'is_outlier' eliminada del conjunto de datos\")\n",
    "    \n",
    "    # Inicializar diccionarios para almacenar transformadores\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Procesar columnas numéricas\n",
    "    if is_training:\n",
    "        # Imputar valores faltantes con la mediana\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
    "        \n",
    "        # Escalar características numéricas\n",
    "        scaler = RobustScaler()  # Más robusto a outliers que StandardScaler\n",
    "        X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "        \n",
    "        # Guardar imputer y scaler\n",
    "        joblib.dump(num_imputer, os.path.join(CONFIG['output_dir'], CONFIG['imputer_file']))\n",
    "        joblib.dump(scaler, os.path.join(CONFIG['output_dir'], CONFIG['scaler_file']))\n",
    "        logger.info(f\"Imputador y scaler guardados en {CONFIG['output_dir']}\")\n",
    "    else:\n",
    "        # Cargar imputer y scaler\n",
    "        num_imputer = joblib.load(os.path.join(CONFIG['output_dir'], CONFIG['imputer_file']))\n",
    "        scaler = joblib.load(os.path.join(CONFIG['output_dir'], CONFIG['scaler_file']))\n",
    "        \n",
    "        # Aplicar transformaciones\n",
    "        X[num_cols] = num_imputer.transform(X[num_cols])\n",
    "        X[num_cols] = scaler.transform(X[num_cols])\n",
    "    \n",
    "    # Procesar columnas categóricas\n",
    "    if is_training:\n",
    "        for col in cat_cols:\n",
    "            # Primero rellenar valores faltantes\n",
    "            X[col] = X[col].fillna('Missing').astype(str)\n",
    "            \n",
    "            # Codificar categorías\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "            label_encoders[col] = le\n",
    "        \n",
    "        # Guardar encoders\n",
    "        joblib.dump(label_encoders, os.path.join(CONFIG['output_dir'], CONFIG['encoders_file']))\n",
    "        logger.info(f\"Codificadores guardados en {CONFIG['output_dir']}\")\n",
    "    else:\n",
    "        # Cargar encoders\n",
    "        label_encoders = joblib.load(os.path.join(CONFIG['output_dir'], CONFIG['encoders_file']))\n",
    "        \n",
    "        # Aplicar encoders a cada columna categórica\n",
    "        for col in cat_cols:\n",
    "            if col in label_encoders:\n",
    "                # Manejar valores nuevos no vistos durante el entrenamiento\n",
    "                X[col] = X[col].fillna('Missing').astype(str)\n",
    "                # Reemplazar categorías desconocidas con 'Missing'\n",
    "                X[col] = X[col].map(lambda x: x if x in label_encoders[col].classes_ else 'Missing')\n",
    "                X[col] = label_encoders[col].transform(X[col])\n",
    "    \n",
    "    return X, num_imputer, label_encoders\n",
    "\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    \"\"\"Evalúa el modelo en el conjunto de validación.\"\"\"\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    preds = model.predict(dval)\n",
    "    \n",
    "    # Calcular múltiples métricas de evaluación\n",
    "    mae = mean_absolute_error(y_val, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    r2 = r2_score(y_val, preds)\n",
    "    \n",
    "    # Calcular métricas adicionales específicas para regresión\n",
    "    # Error porcentual absoluto medio (MAPE)\n",
    "    mape = np.mean(np.abs((y_val - preds) / y_val)) * 100\n",
    "    # Error absoluto mediano (MedianAE)\n",
    "    median_ae = np.median(np.abs(y_val - preds))\n",
    "    \n",
    "    logger.info(f\"Evaluación en validación:\")\n",
    "    logger.info(f\"  MAE: {mae:.4f} (métrica principal)\")\n",
    "    logger.info(f\"  RMSE: {rmse:.4f}\")\n",
    "    logger.info(f\"  R²: {r2:.4f}\")\n",
    "    logger.info(f\"  MAPE: {mape:.2f}%\")\n",
    "    logger.info(f\"  MedianAE: {median_ae:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mape': mape,\n",
    "        'median_ae': median_ae\n",
    "    }\n",
    "\n",
    "def plot_feature_importance(model, features: List[str]):\n",
    "    \"\"\"Visualiza la importancia de características.\"\"\"\n",
    "    importance = model.get_score(importance_type='gain')\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': list(importance.keys()),\n",
    "        'Importance': list(importance.values())\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title('XGBoost - Top 20 características más importantes (gain)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar figura\n",
    "    output_path = os.path.join(CONFIG['output_dir'], CONFIG['feature_importance_file'])\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"Gráfico de importancia guardado en {output_path}\")\n",
    "\n",
    "def objective(trial, X, y, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Función objetivo para Optuna que optimiza los hiperparámetros de XGBoost.\n",
    "    \n",
    "    Args:\n",
    "        trial: Objeto de Optuna para sugerir hiperparámetros\n",
    "        X: Features de entrenamiento\n",
    "        y: Target de entrenamiento\n",
    "        cv_folds: Número de folds para validación cruzada\n",
    "        \n",
    "    Returns:\n",
    "        Métrica de error promedio (MAE) en validación cruzada\n",
    "    \"\"\"\n",
    "    # Espacio de búsqueda de hiperparámetros\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',  # Mantenemos objetivo cuadrático para el entrenamiento\n",
    "        'eval_metric': CONFIG['eval_metric'],  # MAE para evaluación\n",
    "        \n",
    "        # Hiperparámetros principales\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        \n",
    "        # Regularización\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "        \n",
    "        # Configuración adicional\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 0, 256),\n",
    "        'max_bin': trial.suggest_int('max_bin', 256, 512),\n",
    "    }\n",
    "    \n",
    "    # Si se usa GPU, añadir tree_method y predictor\n",
    "    if CONFIG['use_gpu']:\n",
    "        params.update({\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'predictor': 'gpu_predictor',\n",
    "        })\n",
    "    else:\n",
    "        params.update({\n",
    "            'tree_method': 'hist',\n",
    "        })\n",
    "    \n",
    "    # Definir folds para validación cruzada\n",
    "    # Si el target es continuo, usar KFold\n",
    "    # Si es categórico o discreto, considerar StratifiedKFold\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=CONFIG['random_state'])\n",
    "    \n",
    "    # Lista para almacenar resultados de cada fold\n",
    "    mae_scores = []\n",
    "    \n",
    "    # Realizar validación cruzada manualmente\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Convertir a DMatrix\n",
    "        dtrain = xgb.DMatrix(X_fold_train, label=y_fold_train)\n",
    "        dval = xgb.DMatrix(X_fold_val, label=y_fold_val)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=CONFIG['max_boost_rounds'],\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=CONFIG['early_stopping_rounds'],\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # Evaluar usando MAE\n",
    "        preds = model.predict(dval)\n",
    "        mae = mean_absolute_error(y_fold_val, preds)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    # Retornar la media de los scores MAE\n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Flujo principal\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    \"\"\"Función principal que ejecuta todo el pipeline de modelado.\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Iniciando pipeline de entrenamiento XGBoost\")\n",
    "    \n",
    "    # 1. Cargar datos\n",
    "    df = load_data(CONFIG['data_path'])\n",
    "    \n",
    "    # 2. Análisis exploratorio básico\n",
    "    logger.info(\"\\nResumen estadístico:\")\n",
    "    logger.info(f\"Dimensiones: {df.shape}\")\n",
    "    logger.info(f\"Valores faltantes por columna:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
    "    \n",
    "    # 3. Separar target y features\n",
    "    num_cols, cat_cols, target_cols = analyze_data(df)\n",
    "    y = df[CONFIG['target_column']].copy()\n",
    "    X = df.drop(columns=[CONFIG['target_column']]).copy()\n",
    "    \n",
    "    if CONFIG['id_column'] in X.columns:\n",
    "        X = X.drop(columns=[CONFIG['id_column']])\n",
    "    \n",
    "    # 4. Preprocesamiento\n",
    "    logger.info(\"Iniciando preprocesamiento de datos\")\n",
    "    X_processed, imputer, label_encoders = preprocess_data(X, num_cols, cat_cols)\n",
    "    \n",
    "    # 5. División train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_processed, y, \n",
    "        test_size=CONFIG['test_size'], \n",
    "        random_state=CONFIG['random_state']\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"División de datos: {X_train.shape[0]} muestras de entrenamiento, {X_val.shape[0]} de validación\")\n",
    "    \n",
    "    # 6. Optimización de hiperparámetros con Optuna\n",
    "    logger.info(f\"Iniciando búsqueda de hiperparámetros con Optuna ({CONFIG['n_trials']} trials)\")\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=CONFIG['random_state'])\n",
    "    )\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_processed, y, CONFIG['cv_folds']),\n",
    "        n_trials=CONFIG['n_trials'],\n",
    "        timeout=CONFIG['timeout']\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Mejores hiperparámetros encontrados:\")\n",
    "    for param, value in study.best_params.items():\n",
    "        logger.info(f\"  {param}: {value}\")\n",
    "    logger.info(f\"Mejor RMSE CV: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 7. Entrenamiento del modelo final con los mejores hiperparámetros\n",
    "    logger.info(\"Entrenando modelo final con los mejores hiperparámetros\")\n",
    "    \n",
    "    # Preparar DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Configurar parámetros finales\n",
    "    final_params = study.best_params.copy()\n",
    "    if CONFIG['use_gpu']:\n",
    "        final_params.update({\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'predictor': 'gpu_predictor',\n",
    "            'objective': 'reg:absoluteerror',  # Cambiado a error absoluto para optimizar directamente MAE\n",
    "            'eval_metric': CONFIG['eval_metric']\n",
    "        })\n",
    "    else:\n",
    "        final_params.update({\n",
    "            'tree_method': 'hist',\n",
    "            'objective': 'reg:absoluteerror',  # Cambiado a error absoluto para optimizar directamente MAE\n",
    "            'eval_metric': CONFIG['eval_metric']\n",
    "        })\n",
    "    \n",
    "    # Entrenar modelo final\n",
    "    final_model = xgb.train(\n",
    "        final_params,\n",
    "        dtrain,\n",
    "        num_boost_round=CONFIG['max_boost_rounds'],\n",
    "        evals=[(dtrain, 'train'), (dval, 'validation')],\n",
    "        early_stopping_rounds=CONFIG['early_stopping_rounds'],\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    # 8. Evaluar modelo final\n",
    "    metrics = evaluate_model(final_model, X_val, y_val)\n",
    "    \n",
    "    # 9. Visualizar importancia de características\n",
    "    plot_feature_importance(final_model, X.columns.tolist())\n",
    "    \n",
    "    # 10. Guardar modelo final\n",
    "    model_path = os.path.join(CONFIG['output_dir'], CONFIG['model_file'])\n",
    "    final_model.save_model(model_path)\n",
    "    logger.info(f\"Modelo final guardado en {model_path}\")\n",
    "    \n",
    "    # 11. Generar predicciones para test si existe\n",
    "    test_path = CONFIG['test_path']\n",
    "    if os.path.exists(test_path):\n",
    "        logger.info(f\"Generando predicciones para {test_path}\")\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        \n",
    "        # Guardar ID antes de preprocesar\n",
    "        test_ids = df_test[CONFIG['id_column']].copy()\n",
    "        \n",
    "        # Preprocesamiento de test con los mismos transformadores\n",
    "        if CONFIG['id_column'] in df_test.columns:\n",
    "            X_test = df_test.drop(columns=[CONFIG['id_column']])\n",
    "        else:\n",
    "            X_test = df_test.copy()\n",
    "        \n",
    "        # Aplicar el mismo preprocesamiento\n",
    "        X_test_processed, _, _ = preprocess_data(\n",
    "            X_test, num_cols, cat_cols, is_training=False\n",
    "        )\n",
    "        \n",
    "        # Predecir\n",
    "        dtest = xgb.DMatrix(X_test_processed)\n",
    "        test_preds = final_model.predict(dtest)\n",
    "        \n",
    "        # Crear submission\n",
    "        submission = pd.DataFrame({\n",
    "            CONFIG['id_column']: test_ids, \n",
    "            CONFIG['target_column']: test_preds\n",
    "        })\n",
    "        \n",
    "        # Guardar submission\n",
    "        submission_path = os.path.join(CONFIG['output_dir'], CONFIG['submission_file'])\n",
    "        submission.to_csv(submission_path, index=False)\n",
    "        logger.info(f\"Predicciones guardadas en {submission_path}\")\n",
    "    \n",
    "    # 12. Resumen final\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info(f\"Pipeline completado en {elapsed_time/60:.2f} minutos\")\n",
    "    logger.info(f\"MAE final: {metrics['mae']:.4f} (métrica principal)\")\n",
    "    logger.info(f\"RMSE final: {metrics['rmse']:.4f}\")\n",
    "    logger.info(f\"MAPE final: {metrics['mape']:.2f}%\")\n",
    "    logger.info(f\"MedianAE final: {metrics['median_ae']:.4f}\")\n",
    "    logger.info(f\"R² final: {metrics['r2']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error en el pipeline: {str(e)}\")\n",
    "        raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Practica4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
