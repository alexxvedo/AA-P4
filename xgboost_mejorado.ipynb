{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-06 18:19:35,439 - __main__ - INFO - Iniciando pipeline de entrenamiento XGBoost\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>superficie_interior_m2</th>\n",
       "      <th>superficie_exterior_m2</th>\n",
       "      <th>numero_habitacions</th>\n",
       "      <th>numero_banos</th>\n",
       "      <th>ano_construccion</th>\n",
       "      <th>lonxitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>temperatura_media_mes_construccion</th>\n",
       "      <th>tipo_edificacion</th>\n",
       "      <th>...</th>\n",
       "      <th>is_outlier</th>\n",
       "      <th>tipo_Apartamento.1</th>\n",
       "      <th>tipo_Casa.1</th>\n",
       "      <th>tipo_Chalet adosado.1</th>\n",
       "      <th>color_Amarelo.1</th>\n",
       "      <th>color_Azul.1</th>\n",
       "      <th>color_Branco.1</th>\n",
       "      <th>color_Negro.1</th>\n",
       "      <th>color_Verde.1</th>\n",
       "      <th>color_Vermello.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25521</td>\n",
       "      <td>-1.214878</td>\n",
       "      <td>-0.600905</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1947</td>\n",
       "      <td>-8.17</td>\n",
       "      <td>43.20</td>\n",
       "      <td>24.75</td>\n",
       "      <td>Apartamento</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4843</td>\n",
       "      <td>-0.590517</td>\n",
       "      <td>-0.493874</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1977</td>\n",
       "      <td>-7.23</td>\n",
       "      <td>43.60</td>\n",
       "      <td>14.06</td>\n",
       "      <td>Apartamento</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27734</td>\n",
       "      <td>1.723563</td>\n",
       "      <td>-0.371180</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1996</td>\n",
       "      <td>-8.40</td>\n",
       "      <td>42.25</td>\n",
       "      <td>12.27</td>\n",
       "      <td>Chalet adosado</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22142</td>\n",
       "      <td>0.415219</td>\n",
       "      <td>-0.533578</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1996</td>\n",
       "      <td>-6.81</td>\n",
       "      <td>43.15</td>\n",
       "      <td>11.61</td>\n",
       "      <td>Chalet adosado</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14748</td>\n",
       "      <td>1.203970</td>\n",
       "      <td>2.040511</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>-8.76</td>\n",
       "      <td>42.92</td>\n",
       "      <td>10.04</td>\n",
       "      <td>Casa</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  superficie_interior_m2  superficie_exterior_m2  numero_habitacions  \\\n",
       "0  25521               -1.214878               -0.600905                   1   \n",
       "1   4843               -0.590517               -0.493874                   2   \n",
       "2  27734                1.723563               -0.371180                   1   \n",
       "3  22142                0.415219               -0.533578                   4   \n",
       "4  14748                1.203970                2.040511                   1   \n",
       "\n",
       "   numero_banos  ano_construccion  lonxitude  latitude  \\\n",
       "0             2              1947      -8.17     43.20   \n",
       "1             2              1977      -7.23     43.60   \n",
       "2             1              1996      -8.40     42.25   \n",
       "3             2              1996      -6.81     43.15   \n",
       "4             1              1990      -8.76     42.92   \n",
       "\n",
       "   temperatura_media_mes_construccion tipo_edificacion  ... is_outlier  \\\n",
       "0                               24.75      Apartamento  ...      False   \n",
       "1                               14.06      Apartamento  ...      False   \n",
       "2                               12.27   Chalet adosado  ...      False   \n",
       "3                               11.61   Chalet adosado  ...      False   \n",
       "4                               10.04             Casa  ...      False   \n",
       "\n",
       "  tipo_Apartamento.1  tipo_Casa.1  tipo_Chalet adosado.1  color_Amarelo.1  \\\n",
       "0                  1            0                      0                0   \n",
       "1                  1            0                      0                0   \n",
       "2                  0            0                      1                0   \n",
       "3                  0            0                      1                0   \n",
       "4                  0            1                      0                0   \n",
       "\n",
       "  color_Azul.1 color_Branco.1 color_Negro.1  color_Verde.1  color_Vermello.1  \n",
       "0            1              0             0              0                 0  \n",
       "1            0              0             0              1                 0  \n",
       "2            0              1             0              0                 0  \n",
       "3            0              0             0              0                 1  \n",
       "4            0              0             0              1                 0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 18:19:35,563 - __main__ - INFO - Datos cargados correctamente: 20000 filas, 54 columnas\n",
      "2025-05-06 18:19:35,564 - __main__ - INFO - \n",
      "Resumen estadístico:\n",
      "2025-05-06 18:19:38,212 - __main__ - INFO - Dimensiones: (20000, 54)\n",
      "2025-05-06 18:19:38,227 - __main__ - INFO - Valores faltantes por columna:\n",
      "Series([], dtype: int64)\n",
      "2025-05-06 18:19:38,232 - __main__ - INFO - Columnas numéricas: 45\n",
      "2025-05-06 18:19:38,250 - __main__ - INFO - Columnas categóricas: 6\n",
      "2025-05-06 18:19:38,270 - __main__ - INFO - Iniciando preprocesamiento de datos\n",
      "2025-05-06 18:19:38,275 - __main__ - INFO - Columna 'is_outlier' eliminada del conjunto de datos\n",
      "2025-05-06 18:19:39,052 - __main__ - INFO - Imputador y scaler guardados en models\n",
      "2025-05-06 18:19:39,096 - __main__ - INFO - Codificadores guardados en models\n",
      "2025-05-06 18:19:39,102 - __main__ - INFO - División de datos: 17000 muestras de entrenamiento, 3000 de validación\n",
      "2025-05-06 18:19:39,104 - __main__ - INFO - Iniciando búsqueda de hiperparámetros con Optuna (2 trials)\n",
      "[I 2025-05-06 18:19:39,111] A new study created in memory with name: no-name-6ead62f1-c548-49f2-a48d-85d6c43c41ce\n",
      "[I 2025-05-06 18:19:41,314] Trial 0 finished with value: 97254.20028046875 and parameters: {'learning_rate': 0.008468008575248327, 'max_depth': 12, 'min_child_weight': 37, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'lambda': 0.004207053950287938, 'alpha': 0.0017073967431528124, 'gamma': 4.330880728874676, 'grow_policy': 'lossguide', 'max_leaves': 5, 'max_bin': 505}. Best is trial 0 with value: 97254.20028046875.\n",
      "[I 2025-05-06 18:19:44,328] Trial 1 finished with value: 30851.895193945315 and parameters: {'learning_rate': 0.11536162338241392, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.5917022549267169, 'colsample_bytree': 0.6521211214797689, 'lambda': 0.12561043700013558, 'alpha': 0.05342937261279776, 'gamma': 1.4561457009902097, 'grow_policy': 'depthwise', 'max_leaves': 75, 'max_bin': 350}. Best is trial 1 with value: 30851.895193945315.\n",
      "2025-05-06 18:19:44,329 - __main__ - INFO - Mejores hiperparámetros encontrados:\n",
      "2025-05-06 18:19:44,330 - __main__ - INFO -   learning_rate: 0.11536162338241392\n",
      "2025-05-06 18:19:44,331 - __main__ - INFO -   max_depth: 5\n",
      "2025-05-06 18:19:44,332 - __main__ - INFO -   min_child_weight: 10\n",
      "2025-05-06 18:19:44,333 - __main__ - INFO -   subsample: 0.5917022549267169\n",
      "2025-05-06 18:19:44,333 - __main__ - INFO -   colsample_bytree: 0.6521211214797689\n",
      "2025-05-06 18:19:44,333 - __main__ - INFO -   lambda: 0.12561043700013558\n",
      "2025-05-06 18:19:44,334 - __main__ - INFO -   alpha: 0.05342937261279776\n",
      "2025-05-06 18:19:44,336 - __main__ - INFO -   gamma: 1.4561457009902097\n",
      "2025-05-06 18:19:44,336 - __main__ - INFO -   grow_policy: depthwise\n",
      "2025-05-06 18:19:44,337 - __main__ - INFO -   max_leaves: 75\n",
      "2025-05-06 18:19:44,337 - __main__ - INFO -   max_bin: 350\n",
      "2025-05-06 18:19:44,339 - __main__ - INFO - Mejor RMSE CV: 30851.8952\n",
      "2025-05-06 18:19:44,339 - __main__ - INFO - Entrenando modelo final con los mejores hiperparámetros\n",
      "2025-05-06 18:19:44,362 - __main__ - ERROR - Error en el pipeline: [18:19:44] ../src/objective/objective.cc:26: Unknown objective function: `reg:absoluteerror`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x299dad) [0x7fd4f3438dad]\n",
      "  [bt] (1) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x29a409) [0x7fd4f3439409]\n",
      "  [bt] (2) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x2230f2) [0x7fd4f33c20f2]\n",
      "  [bt] (3) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x22af7d) [0x7fd4f33c9f7d]\n",
      "  [bt] (4) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterBoostedRounds+0x31) [0x7fd4f325c261]\n",
      "  [bt] (5) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6bdd) [0x7fd543bd6bdd]\n",
      "  [bt] (6) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6149) [0x7fd543bd6149]\n",
      "  [bt] (7) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2f6) [0x7fd5424b7176]\n",
      "  [bt] (8) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xa341) [0x7fd5424b0341]\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.vTBr3YY5/ipykernel_3168077/3492372518.py\", line 506, in <module>\n",
      "    main()\n",
      "  File \"/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.vTBr3YY5/ipykernel_3168077/3492372518.py\", line 446, in main\n",
      "    verbose_eval=100\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/core.py\", line 575, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/training.py\", line 176, in train\n",
      "    bst = cb_container.before_training(bst)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/callback.py\", line 147, in before_training\n",
      "    model = c.before_training(model=model)\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/callback.py\", line 349, in before_training\n",
      "    self.starting_round = model.num_boosted_rounds()\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/core.py\", line 2319, in num_boosted_rounds\n",
      "    _check_call(_LIB.XGBoosterBoostedRounds(self.handle, ctypes.byref(rounds)))\n",
      "  File \"/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/core.py\", line 246, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [18:19:44] ../src/objective/objective.cc:26: Unknown objective function: `reg:absoluteerror`\n",
      "Objective candidate: survival:aft\n",
      "Objective candidate: binary:hinge\n",
      "Objective candidate: multi:softmax\n",
      "Objective candidate: multi:softprob\n",
      "Objective candidate: rank:pairwise\n",
      "Objective candidate: rank:ndcg\n",
      "Objective candidate: rank:map\n",
      "Objective candidate: reg:squarederror\n",
      "Objective candidate: reg:squaredlogerror\n",
      "Objective candidate: reg:logistic\n",
      "Objective candidate: binary:logistic\n",
      "Objective candidate: binary:logitraw\n",
      "Objective candidate: reg:linear\n",
      "Objective candidate: reg:pseudohubererror\n",
      "Objective candidate: count:poisson\n",
      "Objective candidate: survival:cox\n",
      "Objective candidate: reg:gamma\n",
      "Objective candidate: reg:tweedie\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x299dad) [0x7fd4f3438dad]\n",
      "  [bt] (1) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x29a409) [0x7fd4f3439409]\n",
      "  [bt] (2) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x2230f2) [0x7fd4f33c20f2]\n",
      "  [bt] (3) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x22af7d) [0x7fd4f33c9f7d]\n",
      "  [bt] (4) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterBoostedRounds+0x31) [0x7fd4f325c261]\n",
      "  [bt] (5) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6bdd) [0x7fd543bd6bdd]\n",
      "  [bt] (6) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6149) [0x7fd543bd6149]\n",
      "  [bt] (7) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2f6) [0x7fd5424b7176]\n",
      "  [bt] (8) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xa341) [0x7fd5424b0341]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[18:19:44] ../src/objective/objective.cc:26: Unknown objective function: `reg:absoluteerror`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: reg:pseudohubererror\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\n\nStack trace:\n  [bt] (0) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x299dad) [0x7fd4f3438dad]\n  [bt] (1) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x29a409) [0x7fd4f3439409]\n  [bt] (2) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x2230f2) [0x7fd4f33c20f2]\n  [bt] (3) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x22af7d) [0x7fd4f33c9f7d]\n  [bt] (4) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterBoostedRounds+0x31) [0x7fd4f325c261]\n  [bt] (5) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6bdd) [0x7fd543bd6bdd]\n  [bt] (6) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6149) [0x7fd543bd6149]\n  [bt] (7) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2f6) [0x7fd5424b7176]\n  [bt] (8) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xa341) [0x7fd5424b0341]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.vTBr3YY5/ipykernel_3168077/3492372518.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error en el pipeline: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.vTBr3YY5/ipykernel_3168077/3492372518.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    444\u001b[0m         \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'early_stopping_rounds'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    174\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mbefore_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;34m'''Function called before training.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'before_training should return the model'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_cv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/callback.py\u001b[0m in \u001b[0;36mbefore_training\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbefore_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarting_round\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_boosted_rounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mnum_boosted_rounds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2317\u001b[0m         \u001b[0mrounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2319\u001b[0;31m         \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterBoostedRounds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2320\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \"\"\"\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [18:19:44] ../src/objective/objective.cc:26: Unknown objective function: `reg:absoluteerror`\nObjective candidate: survival:aft\nObjective candidate: binary:hinge\nObjective candidate: multi:softmax\nObjective candidate: multi:softprob\nObjective candidate: rank:pairwise\nObjective candidate: rank:ndcg\nObjective candidate: rank:map\nObjective candidate: reg:squarederror\nObjective candidate: reg:squaredlogerror\nObjective candidate: reg:logistic\nObjective candidate: binary:logistic\nObjective candidate: binary:logitraw\nObjective candidate: reg:linear\nObjective candidate: reg:pseudohubererror\nObjective candidate: count:poisson\nObjective candidate: survival:cox\nObjective candidate: reg:gamma\nObjective candidate: reg:tweedie\n\nStack trace:\n  [bt] (0) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x299dad) [0x7fd4f3438dad]\n  [bt] (1) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x29a409) [0x7fd4f3439409]\n  [bt] (2) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x2230f2) [0x7fd4f33c20f2]\n  [bt] (3) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(+0x22af7d) [0x7fd4f33c9f7d]\n  [bt] (4) /mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/xgboost/lib/libxgboost.so(XGBoosterBoostedRounds+0x31) [0x7fd4f325c261]\n  [bt] (5) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6bdd) [0x7fd543bd6bdd]\n  [bt] (6) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib64/libffi.so.7(+0x6149) [0x7fd543bd6149]\n  [bt] (7) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(_ctypes_callproc+0x2f6) [0x7fd5424b7176]\n  [bt] (8) /mnt/netapp1/Optcesga_FT2_RHEL7/2020/gentoo/22072020/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so(+0xa341) [0x7fd5424b0341]\n\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "XGBoost Modeling Pipeline (MAE Optimized)\n",
    "----------------------------------------\n",
    "Script optimizado para entrenamiento de un modelo XGBoost con validación cruzada,\n",
    "búsqueda de hiperparámetros usando Optuna, y generación de predicciones para test.\n",
    "Este script está específicamente optimizado para minimizar el Error Absoluto Medio (MAE).\n",
    "\n",
    "Características:\n",
    "- Optimización enfocada en MAE en lugar de RMSE\n",
    "- Preprocesamiento robusto con manejo inteligente de valores faltantes\n",
    "- Validación cruzada con múltiples métricas de evaluación\n",
    "- Optimización bayesiana de hiperparámetros con Optuna\n",
    "- Análisis de importancia de características\n",
    "- Serialización de todos los componentes del pipeline\n",
    "- Logging detallado\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import warnings\n",
    "import json\n",
    "from typing import Dict, List, Tuple, Union, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"xgboost_training.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Ignorar warnings específicos\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Configuración\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "CONFIG = {\n",
    "    # Rutas\n",
    "    'data_path': 'train_processed.csv',\n",
    "    'test_path': 'test_processed.csv',\n",
    "    'output_dir': 'models',\n",
    "    \n",
    "    # Nombres de archivos\n",
    "    'model_file': 'xgboost_model.json',\n",
    "    'encoders_file': 'label_encoders.pkl',\n",
    "    'scaler_file': 'scaler.pkl',\n",
    "    'imputer_file': 'imputer.pkl',\n",
    "    'feature_importance_file': 'feature_importance.png',\n",
    "    'submission_file': 'submission_mae.csv',\n",
    "    'config_file': 'model_config.json',\n",
    "    \n",
    "    # Parámetros de división de datos\n",
    "    'test_size': 0.15,          # Aumentado para una validación más robusta\n",
    "    'random_state': 42,\n",
    "    \n",
    "    # Parámetros XGBoost\n",
    "    'eval_metric': 'mae',       # Cambiado a MAE como métrica principal\n",
    "    'cv_folds': 5,\n",
    "    'max_boost_rounds': 100,   # Aumentado para permitir más iteraciones\n",
    "    'early_stopping_rounds': 50,\n",
    "    \n",
    "    # Optuna\n",
    "    'n_trials': 2,           # Número de combinaciones de hiperparámetros a probar\n",
    "    'timeout': 3600,           # Tiempo máximo en segundos (1 hora)\n",
    "    \n",
    "    # Target y columna ID\n",
    "    'target_column': 'prezo_euros',\n",
    "    'id_column': 'id',\n",
    "    \n",
    "    # Hardware\n",
    "    'use_gpu': True,          # Cambiar a True si tienes GPU disponible\n",
    "}\n",
    "\n",
    "# Crear directorio de salida\n",
    "os.makedirs(CONFIG['output_dir'], exist_ok=True)\n",
    "\n",
    "# Guardar configuración\n",
    "with open(os.path.join(CONFIG['output_dir'], CONFIG['config_file']), 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=4)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Funciones auxiliares\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Carga los datos desde un archivo CSV.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        df.drop('log_prezo', axis=1, inplace=True)\n",
    "        display(df.head())\n",
    "\n",
    "        logger.info(f\"Datos cargados correctamente: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error al cargar datos: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def analyze_data(df: pd.DataFrame) -> Tuple[List[str], List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Analiza el dataframe y clasifica las columnas.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple con listas de columnas numéricas, categóricas y la columna objetivo\n",
    "    \"\"\"\n",
    "    # Detectar automáticamente tipos de columnas\n",
    "    num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    \n",
    "    # Remover columna objetivo y ID de las listas\n",
    "    if CONFIG['target_column'] in num_cols:\n",
    "        num_cols.remove(CONFIG['target_column'])\n",
    "    if CONFIG['id_column'] in num_cols:\n",
    "        num_cols.remove(CONFIG['id_column'])\n",
    "    if CONFIG['id_column'] in cat_cols:\n",
    "        cat_cols.remove(CONFIG['id_column'])\n",
    "        \n",
    "    logger.info(f\"Columnas numéricas: {len(num_cols)}\")\n",
    "    logger.info(f\"Columnas categóricas: {len(cat_cols)}\")\n",
    "    \n",
    "    return num_cols, cat_cols, [CONFIG['target_column']]\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame, num_cols: List[str], cat_cols: List[str], \n",
    "                   is_training: bool = True) -> Tuple[pd.DataFrame, Dict, Dict]:\n",
    "    \"\"\"\n",
    "    Preprocesa los datos aplicando imputación, codificación y escalado.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame original\n",
    "        num_cols: Lista de columnas numéricas\n",
    "        cat_cols: Lista de columnas categóricas\n",
    "        is_training: Si es True, entrena los transformadores, si no, usa los guardados\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame preprocesado, diccionarios con transformadores\n",
    "    \"\"\"\n",
    "    X = df.copy()\n",
    "    \n",
    "    # Eliminar columna 'Unnamed: 0' si existe (solo en test)\n",
    "    if 'Unnamed: 0' in X.columns:\n",
    "        X.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        logger.info(\"Columna 'Unnamed: 0' eliminada del conjunto de datos\")\n",
    "    \n",
    "    # Eliminar columna 'is_outlier' si existe (solo en train) para mantener consistencia\n",
    "    if 'is_outlier' in X.columns:\n",
    "        X.drop('is_outlier', axis=1, inplace=True)\n",
    "        logger.info(\"Columna 'is_outlier' eliminada del conjunto de datos\")\n",
    "\n",
    "    # Inicializar diccionarios para almacenar transformadores\n",
    "    label_encoders = {}\n",
    "    \n",
    "    # Procesar columnas numéricas\n",
    "    if is_training:\n",
    "        # Imputar valores faltantes con la mediana\n",
    "        num_imputer = SimpleImputer(strategy='median')\n",
    "        X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
    "        \n",
    "        # Escalar características numéricas\n",
    "        scaler = RobustScaler()  # Más robusto a outliers que StandardScaler\n",
    "        X[num_cols] = scaler.fit_transform(X[num_cols])\n",
    "        \n",
    "        # Guardar imputer y scaler\n",
    "        joblib.dump(num_imputer, os.path.join(CONFIG['output_dir'], CONFIG['imputer_file']))\n",
    "        joblib.dump(scaler, os.path.join(CONFIG['output_dir'], CONFIG['scaler_file']))\n",
    "        logger.info(f\"Imputador y scaler guardados en {CONFIG['output_dir']}\")\n",
    "    else:\n",
    "        # Cargar imputer y scaler\n",
    "        num_imputer = joblib.load(os.path.join(CONFIG['output_dir'], CONFIG['imputer_file']))\n",
    "        scaler = joblib.load(os.path.join(CONFIG['output_dir'], CONFIG['scaler_file']))\n",
    "        \n",
    "        # Aplicar transformaciones\n",
    "        X[num_cols] = num_imputer.transform(X[num_cols])\n",
    "        X[num_cols] = scaler.transform(X[num_cols])\n",
    "    \n",
    "    # Procesar columnas categóricas\n",
    "    if is_training:\n",
    "        for col in cat_cols:\n",
    "            # Primero rellenar valores faltantes\n",
    "            X[col] = X[col].fillna('Missing').astype(str)\n",
    "            \n",
    "            # Codificar categorías\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col])\n",
    "            label_encoders[col] = le\n",
    "        \n",
    "        # Guardar encoders\n",
    "        joblib.dump(label_encoders, os.path.join(CONFIG['output_dir'], CONFIG['encoders_file']))\n",
    "        logger.info(f\"Codificadores guardados en {CONFIG['output_dir']}\")\n",
    "    else:\n",
    "        # Cargar encoders\n",
    "        label_encoders = joblib.load(os.path.join(CONFIG['output_dir'], CONFIG['encoders_file']))\n",
    "        \n",
    "        # Aplicar encoders a cada columna categórica\n",
    "        for col in cat_cols:\n",
    "            if col in label_encoders:\n",
    "                # Manejar valores nuevos no vistos durante el entrenamiento\n",
    "                X[col] = X[col].fillna('Missing').astype(str)\n",
    "                # Reemplazar categorías desconocidas con 'Missing'\n",
    "                X[col] = X[col].map(lambda x: x if x in label_encoders[col].classes_ else 'Missing')\n",
    "                X[col] = label_encoders[col].transform(X[col])\n",
    "    \n",
    "    return X, num_imputer, label_encoders\n",
    "\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    \"\"\"Evalúa el modelo en el conjunto de validación.\"\"\"\n",
    "    dval = xgb.DMatrix(X_val)\n",
    "    preds = model.predict(dval)\n",
    "    \n",
    "    # Calcular múltiples métricas de evaluación\n",
    "    mae = mean_absolute_error(y_val, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
    "    r2 = r2_score(y_val, preds)\n",
    "    \n",
    "    # Calcular métricas adicionales específicas para regresión\n",
    "    # Error porcentual absoluto medio (MAPE)\n",
    "    mape = np.mean(np.abs((y_val - preds) / y_val)) * 100\n",
    "    # Error absoluto mediano (MedianAE)\n",
    "    median_ae = np.median(np.abs(y_val - preds))\n",
    "    \n",
    "    logger.info(f\"Evaluación en validación:\")\n",
    "    logger.info(f\"  MAE: {mae:.4f} (métrica principal)\")\n",
    "    logger.info(f\"  RMSE: {rmse:.4f}\")\n",
    "    logger.info(f\"  R²: {r2:.4f}\")\n",
    "    logger.info(f\"  MAPE: {mape:.2f}%\")\n",
    "    logger.info(f\"  MedianAE: {median_ae:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'mape': mape,\n",
    "        'median_ae': median_ae\n",
    "    }\n",
    "\n",
    "def plot_feature_importance(model, features: List[str]):\n",
    "    \"\"\"Visualiza la importancia de características.\"\"\"\n",
    "    importance = model.get_score(importance_type='gain')\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': list(importance.keys()),\n",
    "        'Importance': list(importance.values())\n",
    "    })\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(20))\n",
    "    plt.title('XGBoost - Top 20 características más importantes (gain)')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Guardar figura\n",
    "    output_path = os.path.join(CONFIG['output_dir'], CONFIG['feature_importance_file'])\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    logger.info(f\"Gráfico de importancia guardado en {output_path}\")\n",
    "\n",
    "def objective(trial, X, y, cv_folds=5):\n",
    "    \"\"\"\n",
    "    Función objetivo para Optuna que optimiza los hiperparámetros de XGBoost.\n",
    "    \n",
    "    Args:\n",
    "        trial: Objeto de Optuna para sugerir hiperparámetros\n",
    "        X: Features de entrenamiento\n",
    "        y: Target de entrenamiento\n",
    "        cv_folds: Número de folds para validación cruzada\n",
    "        \n",
    "    Returns:\n",
    "        Métrica de error promedio (MAE) en validación cruzada\n",
    "    \"\"\"\n",
    "    # Espacio de búsqueda de hiperparámetros\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',  # Mantenemos objetivo cuadrático para el entrenamiento\n",
    "        'eval_metric': CONFIG['eval_metric'],  # MAE para evaluación\n",
    "        \n",
    "        # Hiperparámetros principales\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 50),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        \n",
    "        # Regularización\n",
    "        'lambda': trial.suggest_float('lambda', 1e-3, 10.0, log=True),\n",
    "        'alpha': trial.suggest_float('alpha', 1e-3, 10.0, log=True),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0),\n",
    "        \n",
    "        # Configuración adicional\n",
    "        'grow_policy': trial.suggest_categorical('grow_policy', ['depthwise', 'lossguide']),\n",
    "        'max_leaves': trial.suggest_int('max_leaves', 0, 256),\n",
    "        'max_bin': trial.suggest_int('max_bin', 256, 512),\n",
    "    }\n",
    "    \n",
    "    # Si se usa GPU, añadir tree_method y predictor\n",
    "    if CONFIG['use_gpu']:\n",
    "        params.update({\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'predictor': 'gpu_predictor',\n",
    "        })\n",
    "    else:\n",
    "        params.update({\n",
    "            'tree_method': 'hist',\n",
    "        })\n",
    "    \n",
    "    # Definir folds para validación cruzada\n",
    "    # Si el target es continuo, usar KFold\n",
    "    # Si es categórico o discreto, considerar StratifiedKFold\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True, random_state=CONFIG['random_state'])\n",
    "    \n",
    "    # Lista para almacenar resultados de cada fold\n",
    "    mae_scores = []\n",
    "    \n",
    "    # Realizar validación cruzada manualmente\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Convertir a DMatrix\n",
    "        dtrain = xgb.DMatrix(X_fold_train, label=y_fold_train)\n",
    "        dval = xgb.DMatrix(X_fold_val, label=y_fold_val)\n",
    "        \n",
    "        # Entrenar modelo\n",
    "        model = xgb.train(\n",
    "            params,\n",
    "            dtrain,\n",
    "            num_boost_round=CONFIG['max_boost_rounds'],\n",
    "            evals=[(dval, 'val')],\n",
    "            early_stopping_rounds=CONFIG['early_stopping_rounds'],\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        # Evaluar usando MAE\n",
    "        preds = model.predict(dval)\n",
    "        mae = mean_absolute_error(y_fold_val, preds)\n",
    "        mae_scores.append(mae)\n",
    "    \n",
    "    # Retornar la media de los scores MAE\n",
    "    return np.mean(mae_scores)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Flujo principal\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def main():\n",
    "    \"\"\"Función principal que ejecuta todo el pipeline de modelado.\"\"\"\n",
    "    start_time = time.time()\n",
    "    logger.info(\"Iniciando pipeline de entrenamiento XGBoost\")\n",
    "    \n",
    "    # 1. Cargar datos\n",
    "    df = load_data(CONFIG['data_path'])\n",
    "    \n",
    "    # 2. Análisis exploratorio básico\n",
    "    logger.info(\"\\nResumen estadístico:\")\n",
    "    logger.info(f\"Dimensiones: {df.shape}\")\n",
    "    logger.info(f\"Valores faltantes por columna:\\n{df.isnull().sum()[df.isnull().sum() > 0]}\")\n",
    "    \n",
    "    # 3. Separar target y features\n",
    "    num_cols, cat_cols, target_cols = analyze_data(df)\n",
    "    y = df[CONFIG['target_column']].copy()\n",
    "    X = df.drop(columns=[CONFIG['target_column']]).copy()\n",
    "    \n",
    "    if CONFIG['id_column'] in X.columns:\n",
    "        X = X.drop(columns=[CONFIG['id_column']])\n",
    "    \n",
    "    # 4. Preprocesamiento\n",
    "    logger.info(\"Iniciando preprocesamiento de datos\")\n",
    "    X_processed, imputer, label_encoders = preprocess_data(X, num_cols, cat_cols)\n",
    "    \n",
    "    # 5. División train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_processed, y, \n",
    "        test_size=CONFIG['test_size'], \n",
    "        random_state=CONFIG['random_state']\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"División de datos: {X_train.shape[0]} muestras de entrenamiento, {X_val.shape[0]} de validación\")\n",
    "    \n",
    "    # 6. Optimización de hiperparámetros con Optuna\n",
    "    logger.info(f\"Iniciando búsqueda de hiperparámetros con Optuna ({CONFIG['n_trials']} trials)\")\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        direction='minimize',\n",
    "        sampler=optuna.samplers.TPESampler(seed=CONFIG['random_state'])\n",
    "    )\n",
    "    \n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, X_processed, y, CONFIG['cv_folds']),\n",
    "        n_trials=CONFIG['n_trials'],\n",
    "        timeout=CONFIG['timeout']\n",
    "    )\n",
    "    \n",
    "    logger.info(\"Mejores hiperparámetros encontrados:\")\n",
    "    for param, value in study.best_params.items():\n",
    "        logger.info(f\"  {param}: {value}\")\n",
    "    logger.info(f\"Mejor RMSE CV: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 7. Entrenamiento del modelo final con los mejores hiperparámetros\n",
    "    logger.info(\"Entrenando modelo final con los mejores hiperparámetros\")\n",
    "    \n",
    "    # Preparar DMatrix\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Configurar parámetros finales\n",
    "    final_params = study.best_params.copy()\n",
    "    if CONFIG['use_gpu']:\n",
    "        final_params.update({\n",
    "            'tree_method': 'gpu_hist',\n",
    "            'predictor': 'gpu_predictor',\n",
    "            'objective': 'reg:absoluteerror',  # Cambiado a error absoluto para optimizar directamente MAE\n",
    "            'eval_metric': CONFIG['eval_metric']\n",
    "        })\n",
    "    else:\n",
    "        final_params.update({\n",
    "            'tree_method': 'hist',\n",
    "            'objective': 'reg:absoluteerror',  # Cambiado a error absoluto para optimizar directamente MAE\n",
    "            'eval_metric': CONFIG['eval_metric']\n",
    "        })\n",
    "    \n",
    "    # Entrenar modelo final\n",
    "    final_model = xgb.train(\n",
    "        final_params,\n",
    "        dtrain,\n",
    "        num_boost_round=CONFIG['max_boost_rounds'],\n",
    "        evals=[(dtrain, 'train'), (dval, 'validation')],\n",
    "        early_stopping_rounds=CONFIG['early_stopping_rounds'],\n",
    "        verbose_eval=100\n",
    "    )\n",
    "    \n",
    "    # 8. Evaluar modelo final\n",
    "    metrics = evaluate_model(final_model, X_val, y_val)\n",
    "    \n",
    "    # 9. Visualizar importancia de características\n",
    "    plot_feature_importance(final_model, X.columns.tolist())\n",
    "    \n",
    "    # 10. Guardar modelo final\n",
    "    model_path = os.path.join(CONFIG['output_dir'], CONFIG['model_file'])\n",
    "    final_model.save_model(model_path)\n",
    "    logger.info(f\"Modelo final guardado en {model_path}\")\n",
    "    \n",
    "    # 11. Generar predicciones para test si existe\n",
    "    test_path = CONFIG['test_path']\n",
    "    if os.path.exists(test_path):\n",
    "        logger.info(f\"Generando predicciones para {test_path}\")\n",
    "        df_test = pd.read_csv(test_path)\n",
    "        \n",
    "        # Guardar ID antes de preprocesar\n",
    "        test_ids = df_test[CONFIG['id_column']].copy()\n",
    "        \n",
    "        # Preprocesamiento de test con los mismos transformadores\n",
    "        if CONFIG['id_column'] in df_test.columns:\n",
    "            X_test = df_test.drop(columns=[CONFIG['id_column']])\n",
    "        else:\n",
    "            X_test = df_test.copy()\n",
    "        \n",
    "        # Aplicar el mismo preprocesamiento\n",
    "        X_test_processed, _, _ = preprocess_data(\n",
    "            X_test, num_cols, cat_cols, is_training=False\n",
    "        )\n",
    "        \n",
    "        # Predecir\n",
    "        dtest = xgb.DMatrix(X_test_processed)\n",
    "        test_preds = final_model.predict(dtest)\n",
    "        \n",
    "        # Crear submission\n",
    "        submission = pd.DataFrame({\n",
    "            CONFIG['id_column']: test_ids, \n",
    "            CONFIG['target_column']: test_preds\n",
    "        })\n",
    "        \n",
    "        # Guardar submission\n",
    "        submission_path = os.path.join(CONFIG['output_dir'], CONFIG['submission_file'])\n",
    "        submission.to_csv(submission_path, index=False)\n",
    "        logger.info(f\"Predicciones guardadas en {submission_path}\")\n",
    "    \n",
    "    # 12. Resumen final\n",
    "    elapsed_time = time.time() - start_time\n",
    "    logger.info(f\"Pipeline completado en {elapsed_time/60:.2f} minutos\")\n",
    "    logger.info(f\"MAE final: {metrics['mae']:.4f} (métrica principal)\")\n",
    "    logger.info(f\"RMSE final: {metrics['rmse']:.4f}\")\n",
    "    logger.info(f\"MAPE final: {metrics['mape']:.2f}%\")\n",
    "    logger.info(f\"MedianAE final: {metrics['median_ae']:.4f}\")\n",
    "    logger.info(f\"R² final: {metrics['r2']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error en el pipeline: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
