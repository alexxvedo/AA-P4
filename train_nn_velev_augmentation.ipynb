{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, FunctionTransformer, RobustScaler, \n",
    "    PolynomialFeatures\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats.mstats import winsorize\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Configuraci贸n y semillas\n",
    "# ----------------------------\n",
    "DATA_PATH     = 'train.csv'\n",
    "TEST_PATH     = 'test.csv'\n",
    "MODEL_DIR     = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE  = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "\n",
    "DEVICE        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE    = 256\n",
    "MAX_EPOCHS    = 100\n",
    "PATIENCE      = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "TEST_SIZE     = 0.2\n",
    "SUBMIT_FILE   = os.path.join(MODEL_DIR, 'submission_pytorch.csv')\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Definici贸n de feature engineering pipeline\n",
    "# ----------------------------\n",
    "class FeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, current_year=2025):\n",
    "        self.current_year = current_year\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        # Nuevas variables\n",
    "        X['superficie_total_m2'] = X['superficie_interior_m2'].fillna(0) + X['superficie_exterior_m2'].fillna(0)\n",
    "        X['ratio_ext_int']       = X['superficie_exterior_m2'].fillna(0) / (X['superficie_interior_m2'].fillna(0) + 1)\n",
    "        X['antiguedad']          = self.current_year - X['ano_construccion']\n",
    "        X['hab_por_bano']        = X['numero_habitacions'] / (X['numero_banos'] + 1)\n",
    "        X['log_superficie_int']  = np.log1p(X['superficie_interior_m2'].fillna(0))\n",
    "        X['log_superficie_ext']  = np.log1p(X['superficie_exterior_m2'].fillna(0))\n",
    "        orient_map = {'Norte':0, 'Este':90, 'Sur':180, 'Oeste':270}\n",
    "        ang = X['orientacion'].map(orient_map).fillna(0) * np.pi/180\n",
    "        X['orient_sin']          = np.sin(ang)\n",
    "        X['orient_cos']          = np.cos(ang)\n",
    "        return X\n",
    "\n",
    "NUM_COLS = [\n",
    "    'superficie_interior_m2', 'superficie_exterior_m2', 'numero_habitacions',\n",
    "    'numero_banos', 'ano_construccion', 'temperatura_media_mes_construccion',\n",
    "    'distancia_centro_km', 'distancia_escola_km', 'indice_criminalidade',\n",
    "    'numero_arboles_xardin'\n",
    "]\n",
    "CAT_COLS = [\n",
    "    'tipo_edificacion', 'calidade_materiais', 'cor_favorita_propietario',\n",
    "    'acceso_transporte_publico', 'orientacion', 'eficiencia_enerxetica'\n",
    "]\n",
    "NEW_NUMERIC = [\n",
    "    'superficie_total_m2', 'ratio_ext_int', 'antiguedad',\n",
    "    'hab_por_bano', 'log_superficie_int', 'log_superficie_ext',\n",
    "    'orient_sin', 'orient_cos'\n",
    "]\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('winsor', FunctionTransformer(\n",
    "        lambda arr: np.apply_along_axis(\n",
    "            lambda col: winsorize(col, limits=[0.01, 0.01]), 0, arr)\n",
    "    )),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, NUM_COLS + NEW_NUMERIC),\n",
    "    ('cat', categorical_pipeline, CAT_COLS)\n",
    "])\n",
    "\n",
    "full_pipeline = Pipeline([\n",
    "    ('feature_creator', FeatureCreator(current_year=2025)),\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Carga datos y transformaci贸n\n",
    "# ----------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "y  = df['prezo_euros'].values\n",
    "X  = df.drop(columns=['prezo_euros'])\n",
    "\n",
    "# Aplicar pipeline correctamente\n",
    "X_transformed = full_pipeline.fit_transform(X, y)\n",
    "\n",
    "# Split train/val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_transformed, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Dataset y DataLoader\n",
    "# ----------------------------\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, features, targets=None):\n",
    "        self.X = torch.from_numpy(features).float()\n",
    "        self.y = torch.from_numpy(targets).float() if targets is not None else None\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.X[idx], self.y[idx]) if self.y is not None else self.X[idx]\n",
    "\n",
    "train_ds    = HousePriceDataset(X_train, y_train)\n",
    "val_ds      = HousePriceDataset(X_val,   y_val)\n",
    "train_loader= DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Definici贸n del modelo\n",
    "# ----------------------------\n",
    "class RegressionNNBig(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)\n",
    "\n",
    "model     = RegressionNN(X_train.shape[1]).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001  Val RMSE: 271709.14\n",
      "Epoch 002  Val RMSE: 161588.71\n",
      "Epoch 003  Val RMSE: 116762.70\n",
      "Epoch 004  Val RMSE: 96216.29\n",
      "Epoch 005  Val RMSE: 84401.66\n",
      "Epoch 006  Val RMSE: 80016.68\n",
      "Epoch 007  Val RMSE: 76185.49\n",
      "Epoch 008  Val RMSE: 73287.27\n",
      "Epoch 009  Val RMSE: 71245.36\n",
      "Epoch 010  Val RMSE: 69056.22\n",
      "Epoch 011  Val RMSE: 68365.83\n",
      "Epoch 012  Val RMSE: 66095.86\n",
      "Epoch 013  Val RMSE: 65893.99\n",
      "Epoch 014  Val RMSE: 62798.64\n",
      "Epoch 015  Val RMSE: 62967.87\n",
      "Epoch 016  Val RMSE: 61812.50\n",
      "Epoch 017  Val RMSE: 60022.25\n",
      "Epoch 018  Val RMSE: 59329.98\n",
      "Epoch 019  Val RMSE: 59742.94\n",
      "Epoch 020  Val RMSE: 57531.81\n",
      "Epoch 021  Val RMSE: 57219.95\n",
      "Epoch 022  Val RMSE: 58115.51\n",
      "Epoch 023  Val RMSE: 56873.47\n",
      "Epoch 024  Val RMSE: 56489.10\n",
      "Epoch 025  Val RMSE: 56016.74\n",
      "Epoch 026  Val RMSE: 56717.35\n",
      "Epoch 027  Val RMSE: 55485.42\n",
      "Epoch 028  Val RMSE: 55947.97\n",
      "Epoch 029  Val RMSE: 54469.59\n",
      "Epoch 030  Val RMSE: 54564.42\n",
      "Epoch 031  Val RMSE: 54584.24\n",
      "Epoch 032  Val RMSE: 55371.73\n",
      "Epoch 033  Val RMSE: 54373.89\n",
      "Epoch 034  Val RMSE: 54785.48\n",
      "Epoch 035  Val RMSE: 54721.10\n",
      "Epoch 036  Val RMSE: 53146.14\n",
      "Epoch 037  Val RMSE: 53364.78\n",
      "Epoch 038  Val RMSE: 52346.08\n",
      "Epoch 039  Val RMSE: 52361.70\n",
      "Epoch 040  Val RMSE: 54210.32\n",
      "Epoch 041  Val RMSE: 53238.52\n",
      "Epoch 042  Val RMSE: 52484.50\n",
      "Epoch 043  Val RMSE: 54475.57\n",
      "Epoch 044  Val RMSE: 52361.55\n",
      "Epoch 045  Val RMSE: 51431.24\n",
      "Epoch 046  Val RMSE: 53905.64\n",
      "Epoch 047  Val RMSE: 53253.23\n",
      "Epoch 048  Val RMSE: 51117.69\n",
      "Epoch 049  Val RMSE: 53011.32\n",
      "Epoch 050  Val RMSE: 52275.19\n",
      "Epoch 051  Val RMSE: 50999.34\n",
      "Epoch 052  Val RMSE: 50927.39\n",
      "Epoch 053  Val RMSE: 51666.90\n",
      "Epoch 054  Val RMSE: 50677.76\n",
      "Epoch 055  Val RMSE: 51062.34\n",
      "Epoch 056  Val RMSE: 51215.86\n",
      "Epoch 057  Val RMSE: 50497.31\n",
      "Epoch 058  Val RMSE: 50398.53\n",
      "Epoch 059  Val RMSE: 50990.84\n",
      "Epoch 060  Val RMSE: 52315.66\n",
      "Epoch 061  Val RMSE: 50728.14\n",
      "Epoch 062  Val RMSE: 51027.78\n",
      "Epoch 063  Val RMSE: 51362.19\n",
      "Epoch 064  Val RMSE: 49848.32\n",
      "Epoch 065  Val RMSE: 50645.69\n",
      "Epoch 066  Val RMSE: 49983.00\n",
      "Epoch 067  Val RMSE: 49968.54\n",
      "Epoch 068  Val RMSE: 50382.15\n",
      "Epoch 069  Val RMSE: 51687.88\n",
      "Epoch 070  Val RMSE: 50686.51\n",
      "Epoch 071  Val RMSE: 50437.09\n",
      "Epoch 072  Val RMSE: 49517.24\n",
      "Epoch 073  Val RMSE: 49867.94\n",
      "Epoch 074  Val RMSE: 49848.75\n",
      "Epoch 075  Val RMSE: 49775.86\n",
      "Epoch 076  Val RMSE: 50383.35\n",
      "Epoch 077  Val RMSE: 50732.76\n",
      "Epoch 078  Val RMSE: 49331.22\n",
      "Epoch 079  Val RMSE: 52773.71\n",
      "Epoch 080  Val RMSE: 50045.91\n",
      "Epoch 081  Val RMSE: 51217.81\n",
      "Epoch 082  Val RMSE: 49632.47\n",
      "Epoch 083  Val RMSE: 50623.49\n",
      "Epoch 084  Val RMSE: 49302.03\n",
      "Epoch 085  Val RMSE: 50188.57\n",
      "Epoch 086  Val RMSE: 49125.23\n",
      "Epoch 087  Val RMSE: 49030.08\n",
      "Epoch 088  Val RMSE: 49071.07\n",
      "Epoch 089  Val RMSE: 49145.88\n",
      "Epoch 090  Val RMSE: 50121.65\n",
      "Epoch 091  Val RMSE: 49368.84\n",
      "Epoch 092  Val RMSE: 49004.86\n",
      "Epoch 093  Val RMSE: 49308.48\n",
      "Epoch 094  Val RMSE: 49028.61\n",
      "Epoch 095  Val RMSE: 50202.56\n",
      "Epoch 096  Val RMSE: 49017.45\n",
      "Epoch 097  Val RMSE: 49695.84\n",
      "Epoch 098  Val RMSE: 49252.10\n",
      "Epoch 099  Val RMSE: 49067.81\n",
      "Epoch 100  Val RMSE: 48887.08\n",
      "Mejor RMSE en validaci贸n: 48887.08 euros\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 6. Entrenamiento con early stopping\n",
    "# ----------------------------\n",
    "best_val_rmse     = np.inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS+1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        preds  = model(xb)\n",
    "        loss   = criterion(preds, yb)\n",
    "        optimizer.zero_grad(); loss.backward(); optimizer.step()\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            val_losses.append(((model(xb)-yb)**2).mean().item())\n",
    "    val_rmse = np.sqrt(np.mean(val_losses))\n",
    "    print(f\"Epoch {epoch:03d}  Val RMSE: {val_rmse:.2f}\")\n",
    "    if val_rmse + 1e-4 < best_val_rmse:\n",
    "        best_val_rmse, epochs_no_improve = val_rmse, 0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR,'best_model.pt'))\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Deteniendo tras {epoch} epochs sin mejora.\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR,'best_model.pt')))\n",
    "print(f\"Mejor RMSE en validaci贸n: {best_val_rmse:.2f} euros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 7. Inferencia y submission\n",
    "# ----------------------------\n",
    "if os.path.exists(TEST_PATH):\n",
    "    df_test = pd.read_csv(TEST_PATH)\n",
    "    X_test_trans = full_pipeline.transform(df_test)\n",
    "    test_ds     = HousePriceDataset(X_test_trans)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "    preds=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
