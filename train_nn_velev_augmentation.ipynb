{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1. Configuración y semillas\n",
    "# ----------------------------\n",
    "DATA_PATH    = 'train.csv'\n",
    "TEST_PATH    = 'test.csv'\n",
    "MODEL_DIR    = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE   = 256\n",
    "MAX_EPOCHS   = 100\n",
    "PATIENCE     = 10\n",
    "LEARNING_RATE= 1e-3\n",
    "TEST_SIZE    = 0.1\n",
    "SUBMIT_FILE  = os.path.join(MODEL_DIR, 'submission_pytorch.csv')\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Carga y preprocessado train\n",
    "# ----------------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "y  = df['prezo_euros'].values\n",
    "X  = df.drop(columns=['prezo_euros']).copy()\n",
    "\n",
    "# 2.1 Columnas numéricas y categóricas\n",
    "num_cols = X.select_dtypes(include=['float64','int64']).columns.tolist()\n",
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# 2.2 Imputación\n",
    "for col in num_cols:\n",
    "    med = X[col].median()\n",
    "    X[col].fillna(med, inplace=True)\n",
    "for col in cat_cols:\n",
    "    X[col] = X[col].fillna('Missing').astype(str)\n",
    "\n",
    "# 2.3 One-hot encoding\n",
    "X_enc      = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "FEATURES   = X_enc.columns.tolist()\n",
    "\n",
    "# 2.4 Escalado numérico\n",
    "scaler     = StandardScaler()\n",
    "X_enc[num_cols] = scaler.fit_transform(X_enc[num_cols])\n",
    "\n",
    "# 2.5 Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_enc.values, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 3. Dataset & DataLoader\n",
    "# ----------------------------\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, features, targets=None):\n",
    "        self.X = torch.from_numpy(features).float()\n",
    "        self.y = torch.from_numpy(targets).float() if targets is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds    = HousePriceDataset(X_train, y_train)\n",
    "val_ds      = HousePriceDataset(X_val,   y_val)\n",
    "train_loader= DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_loader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 4. Definición del modelo (arquitectura aumentada)\n",
    "# ----------------------------\n",
    "class RegressionNNBig(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)\n",
    "\n",
    "# Instanciación\n",
    "model = RegressionNNBig(X_train.shape[1]).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 5. Optimizer y loss\n",
    "# ----------------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 \u0014 Val RMSE: 106086.15\n",
      "Epoch 002 \u0014 Val RMSE: 69603.23\n",
      "Epoch 003 \u0014 Val RMSE: 65893.44\n",
      "Epoch 004 \u0014 Val RMSE: 62002.23\n",
      "Epoch 005 \u0014 Val RMSE: 60281.22\n",
      "Epoch 006 \u0014 Val RMSE: 60006.60\n",
      "Epoch 007 \u0014 Val RMSE: 58323.16\n",
      "Epoch 008 \u0014 Val RMSE: 57724.31\n",
      "Epoch 009 \u0014 Val RMSE: 57214.03\n",
      "Epoch 010 \u0014 Val RMSE: 56697.99\n",
      "Epoch 011 \u0014 Val RMSE: 55698.69\n",
      "Epoch 012 \u0014 Val RMSE: 55844.26\n",
      "Epoch 013 \u0014 Val RMSE: 56447.93\n",
      "Epoch 014 \u0014 Val RMSE: 53819.20\n",
      "Epoch 015 \u0014 Val RMSE: 53284.78\n",
      "Epoch 016 \u0014 Val RMSE: 53488.03\n",
      "Epoch 017 \u0014 Val RMSE: 53206.54\n",
      "Epoch 018 \u0014 Val RMSE: 52285.48\n",
      "Epoch 019 \u0014 Val RMSE: 51799.98\n",
      "Epoch 020 \u0014 Val RMSE: 52050.05\n",
      "Epoch 021 \u0014 Val RMSE: 52598.46\n",
      "Epoch 022 \u0014 Val RMSE: 51302.59\n",
      "Epoch 023 \u0014 Val RMSE: 51032.68\n",
      "Epoch 024 \u0014 Val RMSE: 51035.25\n",
      "Epoch 025 \u0014 Val RMSE: 54397.64\n",
      "Epoch 026 \u0014 Val RMSE: 49817.60\n",
      "Epoch 027 \u0014 Val RMSE: 49836.71\n",
      "Epoch 028 \u0014 Val RMSE: 49642.41\n",
      "Epoch 029 \u0014 Val RMSE: 49628.43\n",
      "Epoch 030 \u0014 Val RMSE: 49161.15\n",
      "Epoch 031 \u0014 Val RMSE: 49024.49\n",
      "Epoch 032 \u0014 Val RMSE: 48893.61\n",
      "Epoch 033 \u0014 Val RMSE: 49962.72\n",
      "Epoch 034 \u0014 Val RMSE: 47996.95\n",
      "Epoch 035 \u0014 Val RMSE: 50660.59\n",
      "Epoch 036 \u0014 Val RMSE: 47759.20\n",
      "Epoch 037 \u0014 Val RMSE: 47101.56\n",
      "Epoch 038 \u0014 Val RMSE: 50727.08\n",
      "Epoch 039 \u0014 Val RMSE: 46950.76\n",
      "Epoch 040 \u0014 Val RMSE: 48700.61\n",
      "Epoch 041 \u0014 Val RMSE: 46665.75\n",
      "Epoch 042 \u0014 Val RMSE: 46146.41\n",
      "Epoch 043 \u0014 Val RMSE: 48845.78\n",
      "Epoch 044 \u0014 Val RMSE: 46461.94\n",
      "Epoch 045 \u0014 Val RMSE: 47281.80\n",
      "Epoch 046 \u0014 Val RMSE: 46198.91\n",
      "Epoch 047 \u0014 Val RMSE: 45410.83\n",
      "Epoch 048 \u0014 Val RMSE: 46993.78\n",
      "Epoch 049 \u0014 Val RMSE: 45392.76\n",
      "Epoch 050 \u0014 Val RMSE: 45856.09\n",
      "Epoch 051 \u0014 Val RMSE: 46322.17\n",
      "Epoch 052 \u0014 Val RMSE: 45154.15\n",
      "Epoch 053 \u0014 Val RMSE: 48622.78\n",
      "Epoch 054 \u0014 Val RMSE: 45245.25\n",
      "Epoch 055 \u0014 Val RMSE: 47209.98\n",
      "Epoch 056 \u0014 Val RMSE: 47599.11\n",
      "Epoch 057 \u0014 Val RMSE: 47004.03\n",
      "Epoch 058 \u0014 Val RMSE: 44652.15\n",
      "Epoch 059 \u0014 Val RMSE: 44728.35\n",
      "Epoch 060 \u0014 Val RMSE: 45439.59\n",
      "Epoch 061 \u0014 Val RMSE: 44745.67\n",
      "Epoch 062 \u0014 Val RMSE: 44905.02\n",
      "Epoch 063 \u0014 Val RMSE: 44607.64\n",
      "Epoch 064 \u0014 Val RMSE: 44496.58\n",
      "Epoch 065 \u0014 Val RMSE: 47510.89\n",
      "Epoch 066 \u0014 Val RMSE: 49521.16\n",
      "Epoch 067 \u0014 Val RMSE: 45785.76\n",
      "Epoch 068 \u0014 Val RMSE: 45082.70\n",
      "Epoch 069 \u0014 Val RMSE: 47393.75\n",
      "Epoch 070 \u0014 Val RMSE: 50153.30\n",
      "Epoch 071 \u0014 Val RMSE: 47349.98\n",
      "Epoch 072 \u0014 Val RMSE: 44236.76\n",
      "Epoch 073 \u0014 Val RMSE: 44333.08\n",
      "Epoch 074 \u0014 Val RMSE: 46785.11\n",
      "Epoch 075 \u0014 Val RMSE: 44505.51\n",
      "Epoch 076 \u0014 Val RMSE: 45522.14\n",
      "Epoch 077 \u0014 Val RMSE: 44094.54\n",
      "Epoch 078 \u0014 Val RMSE: 45230.89\n",
      "Epoch 079 \u0014 Val RMSE: 44247.90\n",
      "Epoch 080 \u0014 Val RMSE: 44771.61\n",
      "Epoch 081 \u0014 Val RMSE: 45747.51\n",
      "Epoch 082 \u0014 Val RMSE: 43857.08\n",
      "Epoch 083 \u0014 Val RMSE: 46799.06\n",
      "Epoch 084 \u0014 Val RMSE: 43860.69\n",
      "Epoch 085 \u0014 Val RMSE: 44161.41\n",
      "Epoch 086 \u0014 Val RMSE: 49334.67\n",
      "Epoch 087 \u0014 Val RMSE: 47216.62\n",
      "Epoch 088 \u0014 Val RMSE: 44096.84\n",
      "Epoch 089 \u0014 Val RMSE: 45111.79\n",
      "Epoch 090 \u0014 Val RMSE: 43947.73\n",
      "Epoch 091 \u0014 Val RMSE: 44297.98\n",
      "Epoch 092 \u0014 Val RMSE: 46333.86\n",
      "Deteniendo tras 92 epochs sin mejora.\n",
      "Mejor RMSE en validación: 43857.08 euros\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 6. Entrenamiento con EarlyStopping\n",
    "# ----------------------------\n",
    "best_val_rmse     = np.inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        preds  = model(xb)\n",
    "        loss   = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            preds  = model(xb)\n",
    "            val_losses.append(((preds - yb)**2).mean().item())\n",
    "    val_rmse = np.sqrt(np.mean(val_losses))\n",
    "    print(f\"Epoch {epoch:03d} \u0014 Val RMSE: {val_rmse:.2f}\")\n",
    "\n",
    "    # EarlyStopping\n",
    "    if val_rmse + 1e-4 < best_val_rmse:\n",
    "        best_val_rmse     = val_rmse\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_model.pt'))\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Deteniendo tras {epoch} epochs sin mejora.\")\n",
    "            break\n",
    "\n",
    "# Carga mejor modelo\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'best_model.pt')))\n",
    "print(f\"Mejor RMSE en validación: {best_val_rmse:.2f} euros\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission guardada en models/submission_pytorch.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 7. Generar submission final\n",
    "# ----------------------------\n",
    "if os.path.exists(TEST_PATH):\n",
    "    # Leer test.csv evitando columna Unnamed\n",
    "    df_test = pd.read_csv(TEST_PATH, index_col=0)\n",
    "    X_test  = df_test.reindex(columns=FEATURES).copy()\n",
    "\n",
    "    # Imputación y encoding idénticos al train\n",
    "    for col in num_cols:\n",
    "        X_test[col].fillna(df[col].median(), inplace=True)\n",
    "    for col in cat_cols:\n",
    "        # no es necesario porque las dummies ya están alineadas\n",
    "        pass\n",
    "\n",
    "    # Escalado\n",
    "    X_test[num_cols] = scaler.transform(X_test[num_cols])\n",
    "\n",
    "    # DataLoader test\n",
    "    test_ds    = HousePriceDataset(X_test.values)\n",
    "    test_loader= DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                            num_workers=2, pin_memory=True)\n",
    "\n",
    "    # Predicción\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb in test_loader:\n",
    "            xb = xb.to(DEVICE)\n",
    "            p  = model(xb).cpu().numpy()\n",
    "            preds.append(p)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        'id':          df_test['id'],\n",
    "        'prezo_euros': preds\n",
    "    })\n",
    "    submission.to_csv(SUBMIT_FILE, index=False)\n",
    "    print(f\"Submission guardada en {SUBMIT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
