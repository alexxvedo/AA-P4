{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos procesados previamente...\n",
      "Datos procesados cargados correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Procesamiento de Datos para Competición Kaggle - Precios de Viviendas en Galicia\n",
    "# =============================================================================\n",
    "\n",
    "# Importación de bibliotecas necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "\n",
    "# Configuración de visualización\n",
    "#plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Definir una semilla para reproducibilidad\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# =============================================================================\n",
    "# 1. CARGA DE DATOS\n",
    "# =============================================================================\n",
    "\n",
    "# Verificar si existen los archivos procesados\n",
    "if os.path.exists('train_processed.csv') and os.path.exists('test_processed.csv'):\n",
    "    print(\"Cargando datos procesados previamente...\")\n",
    "    train_data = pd.read_csv('train_processed.csv')\n",
    "    test_data = pd.read_csv('test_processed.csv')\n",
    "    print(\"Datos procesados cargados correctamente.\")\n",
    "else:\n",
    "    print(\"Procesando datos desde cero...\")\n",
    "    \n",
    "    # Cargar los conjuntos de datos originales\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv')\n",
    "    \n",
    "    print(f\"Dimensiones del conjunto de entrenamiento: {train_data.shape}\")\n",
    "    print(f\"Dimensiones del conjunto de prueba: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. FUNCIÓN AUXILIAR PARA PREPROCESAMIENTO\n",
    "# =============================================================================\n",
    "\n",
    "def preprocess_data(df, is_train=True):\n",
    "    \"\"\"\n",
    "    Función para preprocesar los datos de viviendas\n",
    "    \n",
    "    Parámetros:\n",
    "    df (pandas.DataFrame): DataFrame a procesar\n",
    "    is_train (bool): Indica si el DataFrame es el conjunto de entrenamiento\n",
    "    \n",
    "    Retorna:\n",
    "    pandas.DataFrame: DataFrame procesado\n",
    "    \"\"\"\n",
    "    # Crear una copia para no modificar el original\n",
    "    data = df.copy()\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2.1 LIMPIEZA DE DATOS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"Iniciando limpieza de datos...\")\n",
    "    \n",
    "    # Eliminar duplicados en el conjunto de entrenamiento\n",
    "    if is_train:\n",
    "        duplicates = data.duplicated()\n",
    "        if duplicates.sum() > 0:\n",
    "            print(f\"Eliminando {duplicates.sum()} filas duplicadas...\")\n",
    "            data = data.drop_duplicates().reset_index(drop=True)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2.2 MANEJO DE VALORES FALTANTES\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"Manejando valores faltantes...\")\n",
    "    \n",
    "    # Chequear valores faltantes antes del preprocesado\n",
    "    missing_before = data.isnull().sum()\n",
    "    print(\"Valores faltantes antes del preprocesado:\")\n",
    "    print(missing_before[missing_before > 0])\n",
    "    \n",
    "    # Imputar valores faltantes usando KNN para variables numéricas principales\n",
    "    numeric_features = [\n",
    "        'superficie_interior_m2', \n",
    "        'superficie_exterior_m2', \n",
    "        'distancia_centro_km', \n",
    "        'distancia_escola_km', \n",
    "        'indice_criminalidade'\n",
    "    ]\n",
    "    \n",
    "    # Seleccionar columnas auxiliares para KNN (que tengan pocos o ningún NA)\n",
    "    aux_features = [\n",
    "        'numero_habitacions', \n",
    "        'numero_banos', \n",
    "        'ano_construccion',\n",
    "        'lonxitude', \n",
    "        'latitude', \n",
    "        'temperatura_media_mes_construccion',\n",
    "        'numero_arboles_xardin'\n",
    "    ]\n",
    "    \n",
    "    # Combinar características para imputer\n",
    "    imputer_features = numeric_features + aux_features\n",
    "    \n",
    "    # Crear una copia temporal para la imputación\n",
    "    imputer_data = data[imputer_features].copy()\n",
    "    \n",
    "    # Inicializar KNN Imputer\n",
    "    imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "    \n",
    "    # Aplicar imputación\n",
    "    imputed_values = imputer.fit_transform(imputer_data)\n",
    "    \n",
    "    # Reemplazar valores en el DataFrame original solo para las columnas con NAs\n",
    "    for i, col in enumerate(numeric_features):\n",
    "        # Solo imputar si hay valores faltantes en la columna\n",
    "        if data[col].isnull().sum() > 0:\n",
    "            data[col] = imputed_values[:, i]\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2.3 INGENIERÍA DE CARACTERÍSTICAS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"Creando nuevas características...\")\n",
    "    \n",
    "    # Año actual para cálculos de edad\n",
    "    current_year = 2025\n",
    "    \n",
    "    # Crear características básicas\n",
    "    data['edad_vivienda'] = current_year - data['ano_construccion']\n",
    "    data['superficie_por_habitacion'] = data['superficie_interior_m2'] / data['numero_habitacions']\n",
    "    data['superficie_total'] = data['superficie_interior_m2'] + data['superficie_exterior_m2']\n",
    "    data['ratio_interior_exterior'] = data['superficie_interior_m2'] / (data['superficie_exterior_m2'] + 1)  # Evitar división por cero\n",
    "    data['densidad_banos'] = data['numero_banos'] / data['superficie_interior_m2']\n",
    "    data['densidad_habitaciones'] = data['numero_habitacions'] / data['superficie_interior_m2']\n",
    "    \n",
    "    # Características de localización\n",
    "    # Calculamos la distancia euclidiana desde algunos puntos de referencia en Galicia\n",
    "    # Centro aproximado de A Coruña\n",
    "    data['dist_coruna'] = np.sqrt((data['lonxitude'] - (-8.4))**2 + (data['latitude'] - 43.37)**2)\n",
    "    # Centro aproximado de Vigo\n",
    "    data['dist_vigo'] = np.sqrt((data['lonxitude'] - (-8.72))**2 + (data['latitude'] - 42.23)**2)\n",
    "    # Centro aproximado de Santiago\n",
    "    data['dist_santiago'] = np.sqrt((data['lonxitude'] - (-8.54))**2 + (data['latitude'] - 42.88)**2)\n",
    "    \n",
    "    # Características interactivas\n",
    "    data['calidad_edad'] = data['edad_vivienda'] * data.apply(\n",
    "        lambda x: {'Alta': 3, 'Media': 2, 'Baixa': 1}[x['calidade_materiais']] \n",
    "        if pd.notna(x['calidade_materiais']) else 2, axis=1)\n",
    "    \n",
    "    data['banos_por_habitacion'] = data['numero_banos'] / data['numero_habitacions']\n",
    "    \n",
    "    # Características climáticas\n",
    "    # Codificar la orientación según exposición solar (Sur es mejor)\n",
    "    orientacion_map = {\n",
    "        'Sur': 4,\n",
    "        'Este': 3,\n",
    "        'Oeste': 2,\n",
    "        'Norte': 1\n",
    "    }\n",
    "    data['orientacion_valor'] = data['orientacion'].map(orientacion_map)\n",
    "    \n",
    "    # Codificar eficiencia energética\n",
    "    eficiencia_map = {\n",
    "        'A': 7,\n",
    "        'B': 6,\n",
    "        'C': 5,\n",
    "        'D': 4,\n",
    "        'E': 3,\n",
    "        'F': 2,\n",
    "        'G': 1\n",
    "    }\n",
    "    data['eficiencia_valor'] = data['eficiencia_enerxetica'].map(eficiencia_map)\n",
    "    \n",
    "    # Codificar calidad de materiales\n",
    "    calidad_map = {\n",
    "        'Alta': 3,\n",
    "        'Media': 2,\n",
    "        'Baixa': 1\n",
    "    }\n",
    "    data['calidade_valor'] = data['calidade_materiais'].map(calidad_map)\n",
    "    \n",
    "    # Codificar acceso a transporte público\n",
    "    transporte_map = {\n",
    "        'Bo': 3,\n",
    "        'Regular': 2,\n",
    "        'Malo': 1\n",
    "    }\n",
    "    data['transporte_valor'] = data['acceso_transporte_publico'].map(transporte_map)\n",
    "    \n",
    "    # Características de tipo de vivienda\n",
    "    # One-hot encoding para tipo de edificación\n",
    "    tipo_edificacion_dummies = pd.get_dummies(data['tipo_edificacion'], prefix='tipo')\n",
    "    data = pd.concat([data, tipo_edificacion_dummies], axis=1)\n",
    "    \n",
    "    # One-hot encoding para color favorito del propietario\n",
    "    color_dummies = pd.get_dummies(data['cor_favorita_propietario'], prefix='color')\n",
    "    data = pd.concat([data, color_dummies], axis=1)\n",
    "            \n",
    "    # =============================================================================\n",
    "    # 2.4 MANEJO DE OUTLIERS (Solo para entrenamiento)\n",
    "    # =============================================================================\n",
    "    \n",
    "    if is_train:\n",
    "        print(\"Analizando outliers...\")\n",
    "        \n",
    "        # Detectar outliers en el precio\n",
    "        Q1 = data['prezo_euros'].quantile(0.25)\n",
    "        Q3 = data['prezo_euros'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = data[(data['prezo_euros'] < lower_bound) | (data['prezo_euros'] > upper_bound)]\n",
    "        \n",
    "        print(f\"Detectados {len(outliers)} outliers en el precio ({len(outliers)/len(data)*100:.2f}%)\")\n",
    "        \n",
    "        # Decidimos mantener los outliers pero los marcamos para posible uso futuro\n",
    "        data['is_outlier'] = (data['prezo_euros'] < lower_bound) | (data['prezo_euros'] > upper_bound)\n",
    "        \n",
    "        # Transformar la variable objetivo para normalización (log transform)\n",
    "        data['log_prezo'] = np.log1p(data['prezo_euros'])\n",
    "            \n",
    "    # =============================================================================\n",
    "    # 2.5 NORMALIZACIÓN Y ESCALADO\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"Escalando características numéricas...\")\n",
    "    \n",
    "    # Lista de características numéricas para escalar\n",
    "    numeric_features_to_scale = [\n",
    "        'superficie_interior_m2', \n",
    "        'superficie_exterior_m2',\n",
    "        'distancia_centro_km', \n",
    "        'distancia_escola_km',\n",
    "        'indice_criminalidade',\n",
    "        'superficie_por_habitacion',\n",
    "        'superficie_total',\n",
    "        'ratio_interior_exterior',\n",
    "        'densidad_banos',\n",
    "        'densidad_habitaciones',\n",
    "        'dist_coruna',\n",
    "        'dist_vigo',\n",
    "        'dist_santiago',\n",
    "        'calidad_edad'\n",
    "    ]\n",
    "    \n",
    "    # No escalamos variables como número de habitaciones, baños, etc. que tienen sentido como están\n",
    "    \n",
    "    if is_train:\n",
    "        # Inicializar el scaler\n",
    "        scaler = StandardScaler()\n",
    "        # Ajustar el scaler solo en los datos de entrenamiento\n",
    "        scaler.fit(data[numeric_features_to_scale])\n",
    "        # Guardar el scaler para uso futuro\n",
    "        import joblib\n",
    "        joblib.dump(scaler, 'scaler.pkl')\n",
    "    else:\n",
    "        # Cargar el scaler previamente ajustado\n",
    "        import joblib\n",
    "        try:\n",
    "            scaler = joblib.load('scaler.pkl')\n",
    "        except:\n",
    "            print(\"ADVERTENCIA: No se encontró el scaler. Los datos de prueba no se escalarán correctamente.\")\n",
    "            return data\n",
    "    \n",
    "    # Aplicar la transformación\n",
    "    data[numeric_features_to_scale] = scaler.transform(data[numeric_features_to_scale])\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 2.6 LIMPIAR COLUMNAS INNECESARIAS\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(\"Limpiando columnas innecesarias...\")\n",
    "    \n",
    "    # Eliminar columnas originales que ya han sido procesadas o no son necesarias\n",
    "    columns_to_drop = [\n",
    "        # No eliminar 'id' ya que se necesita para la presentación\n",
    "    ]\n",
    "    \n",
    "    data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Verificar valores faltantes después del preprocesado\n",
    "    missing_after = data.isnull().sum()\n",
    "    print(\"Valores faltantes después del preprocesado:\")\n",
    "    print(missing_after[missing_after > 0])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocesando conjunto de entrenamiento...\n",
      "Iniciando limpieza de datos...\n",
      "Manejando valores faltantes...\n",
      "Valores faltantes antes del preprocesado:\n",
      "Series([], dtype: int64)\n",
      "Creando nuevas características...\n",
      "Analizando outliers...\n",
      "Detectados 238 outliers en el precio (1.19%)\n",
      "Escalando características numéricas...\n",
      "Limpiando columnas innecesarias...\n",
      "Valores faltantes después del preprocesado:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Preprocesando conjunto de prueba...\n",
      "Iniciando limpieza de datos...\n",
      "Manejando valores faltantes...\n",
      "Valores faltantes antes del preprocesado:\n",
      "Series([], dtype: int64)\n",
      "Creando nuevas características...\n",
      "Escalando características numéricas...\n",
      "Limpiando columnas innecesarias...\n",
      "Valores faltantes después del preprocesado:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Guardando datos procesados...\n",
      "Datos procesados guardados en 'train_processed.csv' y 'test_processed.csv'\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 3. APLICAR PREPROCESAMIENTO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nPreprocesando conjunto de entrenamiento...\")\n",
    "train_processed = preprocess_data(train_data, is_train=True)\n",
    "\n",
    "print(\"\\nPreprocesando conjunto de prueba...\")\n",
    "test_processed = preprocess_data(test_data, is_train=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. GUARDAR DATOS PROCESADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nGuardando datos procesados...\")\n",
    "train_processed.to_csv('train_processed.csv', index=False)\n",
    "test_processed.to_csv('test_processed.csv', index=False)\n",
    "\n",
    "print(\"Datos procesados guardados en 'train_processed.csv' y 'test_processed.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mostrando información de los datos procesados:\n",
      "Dimensiones del conjunto de entrenamiento procesado: (20000, 46)\n",
      "Dimensiones del conjunto de prueba procesado: (10000, 44)\n",
      "\n",
      "Primeras filas del conjunto de entrenamiento procesado:\n",
      "      id  superficie_interior_m2  superficie_exterior_m2  numero_habitacions  \\\n",
      "0  25521               -1.214878               -0.600905                   1   \n",
      "1   4843               -0.590517               -0.493874                   2   \n",
      "2  27734                1.723563               -0.371180                   1   \n",
      "3  22142                0.415219               -0.533578                   4   \n",
      "4  14748                1.203970                2.040511                   1   \n",
      "\n",
      "   numero_banos  ano_construccion  lonxitude  latitude  \\\n",
      "0             2              1947      -8.17     43.20   \n",
      "1             2              1977      -7.23     43.60   \n",
      "2             1              1996      -8.40     42.25   \n",
      "3             2              1996      -6.81     43.15   \n",
      "4             1              1990      -8.76     42.92   \n",
      "\n",
      "   temperatura_media_mes_construccion tipo_edificacion calidade_materiais  \\\n",
      "0                               24.75      Apartamento              Media   \n",
      "1                               14.06      Apartamento               Alta   \n",
      "2                               12.27   Chalet adosado              Media   \n",
      "3                               11.61   Chalet adosado               Alta   \n",
      "4                               10.04             Casa              Baixa   \n",
      "\n",
      "  cor_favorita_propietario  distancia_centro_km  distancia_escola_km  \\\n",
      "0                     Azul            -0.086440            -1.063878   \n",
      "1                    Verde             0.324846             0.891082   \n",
      "2                   Branco             0.166323             1.212695   \n",
      "3                 Vermello             1.213800            -1.174828   \n",
      "4                    Verde             1.954976            -0.787206   \n",
      "\n",
      "   indice_criminalidade acceso_transporte_publico orientacion  \\\n",
      "0              0.102166                        Bo       Norte   \n",
      "1              0.554363                        Bo        Este   \n",
      "2              0.705095                   Regular        Este   \n",
      "3              0.102166                        Bo        Este   \n",
      "4             -1.204180                        Bo       Oeste   \n",
      "\n",
      "  eficiencia_enerxetica  numero_arboles_xardin  prezo_euros  edad_vivienda  \\\n",
      "0                     C                      0        51938             78   \n",
      "1                     C                      0        76891             48   \n",
      "2                     C                     10       261441             29   \n",
      "3                     G                      3       247821             29   \n",
      "4                     G                     12       400645             35   \n",
      "\n",
      "   superficie_por_habitacion  superficie_total  ratio_interior_exterior  \\\n",
      "0                  -0.217224         -0.688652                 0.469762   \n",
      "1                  -0.185006         -0.528582                -0.555120   \n",
      "2                   3.842041         -0.198519                -0.545937   \n",
      "3                  -0.252814         -0.474498                -0.508094   \n",
      "4                   3.124258          2.070587                -0.577338   \n",
      "\n",
      "   densidad_banos  densidad_habitaciones  dist_coruna  dist_vigo  \\\n",
      "0        1.270152              -0.412240    -1.609578  -0.126416   \n",
      "1        0.027865              -0.437332     0.257816   1.474452   \n",
      "2       -0.925127              -0.952642     0.108668  -1.525513   \n",
      "3       -0.495763              -0.382056     1.108201   1.643372   \n",
      "4       -0.891057              -0.934219    -1.011537  -0.872973   \n",
      "\n",
      "   dist_santiago  calidad_edad  banos_por_habitacion  orientacion_valor  \\\n",
      "0      -1.068397      1.049995                   2.0                  1   \n",
      "1       1.096629      0.857383                   1.0                  3   \n",
      "2      -0.732149     -0.523006                   1.0                  3   \n",
      "3       1.648021     -0.057526                   0.5                  3   \n",
      "4      -1.640151     -0.892180                   1.0                  2   \n",
      "\n",
      "   eficiencia_valor  calidade_valor  transporte_valor  tipo_Apartamento  \\\n",
      "0                 5               2                 3                 1   \n",
      "1                 5               3                 3                 1   \n",
      "2                 5               2                 2                 0   \n",
      "3                 1               3                 3                 0   \n",
      "4                 1               1                 3                 0   \n",
      "\n",
      "   tipo_Casa  tipo_Chalet adosado  color_Amarelo  color_Azul  color_Branco  \\\n",
      "0          0                    0              0           1             0   \n",
      "1          0                    0              0           0             0   \n",
      "2          0                    1              0           0             1   \n",
      "3          0                    1              0           0             0   \n",
      "4          1                    0              0           0             0   \n",
      "\n",
      "   color_Negro  color_Verde  color_Vermello  is_outlier  log_prezo  \n",
      "0            0            0               0       False  10.857825  \n",
      "1            0            1               0       False  11.250157  \n",
      "2            0            0               0       False  12.473968  \n",
      "3            0            0               1       False  12.420466  \n",
      "4            0            1               0       False  12.900834  \n",
      "\n",
      "Columnas disponibles en el conjunto de entrenamiento procesado:\n",
      "['id', 'superficie_interior_m2', 'superficie_exterior_m2', 'numero_habitacions', 'numero_banos', 'ano_construccion', 'lonxitude', 'latitude', 'temperatura_media_mes_construccion', 'tipo_edificacion', 'calidade_materiais', 'cor_favorita_propietario', 'distancia_centro_km', 'distancia_escola_km', 'indice_criminalidade', 'acceso_transporte_publico', 'orientacion', 'eficiencia_enerxetica', 'numero_arboles_xardin', 'prezo_euros', 'edad_vivienda', 'superficie_por_habitacion', 'superficie_total', 'ratio_interior_exterior', 'densidad_banos', 'densidad_habitaciones', 'dist_coruna', 'dist_vigo', 'dist_santiago', 'calidad_edad', 'banos_por_habitacion', 'orientacion_valor', 'eficiencia_valor', 'calidade_valor', 'transporte_valor', 'tipo_Apartamento', 'tipo_Casa', 'tipo_Chalet adosado', 'color_Amarelo', 'color_Azul', 'color_Branco', 'color_Negro', 'color_Verde', 'color_Vermello', 'is_outlier', 'log_prezo']\n",
      "\n",
      "Estadísticas de las nuevas características:\n",
      "       superficie_por_habitacion  edad_vivienda  superficie_total  \\\n",
      "count               2.000000e+04   20000.000000      2.000000e+04   \n",
      "mean                5.009326e-17      43.121600     -8.455459e-17   \n",
      "std                 1.000025e+00      24.689814      1.000025e+00   \n",
      "min                -9.265476e-01       1.000000     -7.062795e-01   \n",
      "25%                -6.239548e-01      22.000000     -6.272168e-01   \n",
      "50%                -3.298963e-01      43.000000     -5.256537e-01   \n",
      "75%                 2.206011e-01      64.000000      2.349143e-01   \n",
      "max                 1.473787e+01      85.000000      3.583117e+00   \n",
      "\n",
      "       ratio_interior_exterior   dist_coruna     dist_vigo  dist_santiago  \n",
      "count             2.000000e+04  2.000000e+04  2.000000e+04   2.000000e+04  \n",
      "mean              3.126388e-17  5.400125e-17 -6.803447e-17   9.698908e-17  \n",
      "std               1.000025e+00  1.000025e+00  1.000025e+00   1.000025e+00  \n",
      "min              -5.795889e-01 -2.178226e+00 -2.072547e+00  -2.100021e+00  \n",
      "25%              -5.729702e-01 -7.960319e-01 -8.294170e-01  -7.447159e-01  \n",
      "50%              -5.233888e-01  2.253414e-02  4.002034e-02  -1.267923e-01  \n",
      "75%               1.205090e-01  8.044973e-01  7.617579e-01   7.369214e-01  \n",
      "max               6.313447e+00  2.554805e+00  2.401458e+00   2.460851e+00  \n",
      "\n",
      "Preprocesamiento completado exitosamente.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 5. VISUALIZACIÓN DE RESULTADOS DEL PREPROCESAMIENTO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\nMostrando información de los datos procesados:\")\n",
    "print(f\"Dimensiones del conjunto de entrenamiento procesado: {train_data.shape}\")\n",
    "print(f\"Dimensiones del conjunto de prueba procesado: {test_data.shape}\")\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(\"\\nPrimeras filas del conjunto de entrenamiento procesado:\")\n",
    "print(train_data.head())\n",
    "\n",
    "# Mostrar las columnas disponibles\n",
    "print(\"\\nColumnas disponibles en el conjunto de entrenamiento procesado:\")\n",
    "print(train_data.columns.tolist())\n",
    "\n",
    "# Verificar nuevas características creadas\n",
    "new_features = ['superficie_por_habitacion', 'edad_vivienda', 'superficie_total', \n",
    "                'ratio_interior_exterior', 'dist_coruna', 'dist_vigo', 'dist_santiago']\n",
    "print(\"\\nEstadísticas de las nuevas características:\")\n",
    "print(train_data[new_features].describe())\n",
    "\n",
    "print(\"\\nPreprocesamiento completado exitosamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
