{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import ElasticNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1. ConfiguraciÃ³n y semillas\n",
    "# ----------------------------\n",
    "DATA_PATH    = 'train.csv'\n",
    "TEST_PATH    = 'test.csv'\n",
    "MODEL_DIR    = 'models'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "\n",
    "DEVICE       = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE   = 256\n",
    "MAX_EPOCHS   = 100\n",
    "PATIENCE     = 10\n",
    "LEARNING_RATE= 1e-3\n",
    "TEST_SIZE    = 0.1\n",
    "SUBMIT_FILE  = os.path.join(MODEL_DIR, 'submission_pytorch.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1. Extended Feature Engineering\n",
    "###############################################################################\n",
    "class ExtendedFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    _orientation_map = {\n",
    "        \"Norte\": 0, \"Nordeste\": 45, \"Este\": 90, \"Sudeste\": 135,\n",
    "        \"Sur\": 180, \"Sudoeste\": 225, \"Oeste\": 270, \"Noroeste\": 315,\n",
    "    }\n",
    "\n",
    "    def __init__(self, current_year: int = 2025, geo_clusters: int = 10):\n",
    "        self.current_year = current_year\n",
    "        self.geo_clusters = geo_clusters\n",
    "        self.km_model_ = None\n",
    "        self.agg_stats_ = {}\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        # Fit KMeans on latitude & longitude\n",
    "        if {\"latitud\", \"longitud\"}.issubset(X.columns):\n",
    "            coords = X[[\"latitud\", \"longitud\"]].fillna(0)\n",
    "            self.km_model_ = KMeans(n_clusters=self.geo_clusters, random_state=42)\n",
    "            self.km_model_.fit(coords)\n",
    "        # Compute aggregate stats by building type if target y provided\n",
    "        if y is not None and 'tipo_edificacion' in X.columns:\n",
    "            grouped = pd.DataFrame({'precio': y, 'type': X['tipo_edificacion']})\n",
    "            agg = grouped.groupby('type').precio.agg(['mean', 'std'])\n",
    "            self.agg_stats_ = agg.to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        df = X.copy()\n",
    "        # Age features\n",
    "        df['antiguedad'] = self.current_year - df['ano_construccion']\n",
    "        df['antiguedad2'] = df['antiguedad'] ** 2\n",
    "        df['decada'] = (df['ano_construccion'] // 10) * 10\n",
    "\n",
    "        # Surface features\n",
    "        df['superficie_total'] = df['superficie_interior_m2'].fillna(0) + df['superficie_exterior_m2'].fillna(0)\n",
    "        df['log_superficie_total'] = np.log1p(df['superficie_total'])\n",
    "        df['habitacion_area'] = df['superficie_interior_m2'] / df['numero_habitacions'].replace(0, np.nan)\n",
    "        df['banos_area'] = df['superficie_interior_m2'] / df['numero_banos'].replace(0, np.nan)\n",
    "\n",
    "        # Distance transformations\n",
    "        for col in ['distancia_centro_km', 'distancia_escola_km']:\n",
    "            if col in df.columns:\n",
    "                df[f'log_{col}'] = np.log1p(df[col])\n",
    "                df[f'inv_{col}'] = 1 / (df[col] + 0.1)\n",
    "\n",
    "        # Temperature features\n",
    "        if 'temperatura_media_mes_construccion' in df.columns:\n",
    "            temp = df['temperatura_media_mes_construccion']\n",
    "            df['temp_norm'] = (temp - temp.mean()) / temp.std()\n",
    "            df['temp_sq'] = temp ** 2\n",
    "\n",
    "        # Crime index buckets\n",
    "        if 'indice_criminalidade' in df.columns:\n",
    "            df['crime_q'] = pd.qcut(df['indice_criminalidade'], 5, labels=False, duplicates='drop')\n",
    "\n",
    "        # Orientation encoding\n",
    "        deg = df.get('orientacion', pd.Series()).map(self._orientation_map).fillna(0)\n",
    "        rad = np.deg2rad(deg)\n",
    "        df['orient_sin'] = np.sin(rad)\n",
    "        df['orient_cos'] = np.cos(rad)\n",
    "\n",
    "        # Geo clusters\n",
    "        if self.km_model_ is not None:\n",
    "            coords = df[['latitud', 'longitud']].fillna(0)\n",
    "            df['geo_cluster'] = self.km_model_.predict(coords)\n",
    "        else:\n",
    "            df['geo_cluster'] = 0\n",
    "\n",
    "        # Aggregated stats by building type\n",
    "        if 'tipo_edificacion' in df.columns and self.agg_stats_:\n",
    "            df['type_price_mean'] = df['tipo_edificacion'].map(self.agg_stats_['mean'])\n",
    "            df['type_price_std'] = df['tipo_edificacion'].map(self.agg_stats_['std'])\n",
    "        else:\n",
    "            df['type_price_mean'] = 0\n",
    "            df['type_price_std'] = 0\n",
    "\n",
    "        # One-hot favorite color if exists\n",
    "        if 'cor_favorita_propietario' in df.columns:\n",
    "            colors = pd.get_dummies(df['cor_favorita_propietario'], prefix='color')\n",
    "            df = pd.concat([df, colors], axis=1)\n",
    "\n",
    "        # Date features\n",
    "        if 'fecha' in df.columns:\n",
    "            dt = pd.to_datetime(df['fecha'], errors='coerce')\n",
    "            df['mes'] = dt.dt.month\n",
    "            df['dia'] = dt.dt.day\n",
    "            df['dia_semana'] = dt.dt.weekday\n",
    "            df['is_fin_de_semana'] = dt.dt.weekday.isin([5, 6]).astype(int)\n",
    "\n",
    "        # Drop original columns\n",
    "        drops = [\n",
    "            'ano_construccion', 'superficie_interior_m2', 'superficie_exterior_m2',\n",
    "            'numero_habitacions', 'numero_banos', 'temperatura_media_mes_construccion',\n",
    "            'distancia_centro_km', 'distancia_escola_km', 'indice_criminalidade',\n",
    "            'orientacion', 'tipo_edificacion', 'cor_favorita_propietario', 'fecha'\n",
    "        ]\n",
    "        df.drop(columns=[c for c in drops if c in df.columns], inplace=True)\n",
    "        return df\n",
    "\n",
    "###############################################################################\n",
    "# 2. Winsorizer Selectivo\n",
    "###############################################################################\n",
    "class WinsorizerSelective(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lower=0.005, upper=0.995, active=True):\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "        self.active = active\n",
    "        self.bounds_ = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not self.active:\n",
    "            return self\n",
    "        df = pd.DataFrame(X)\n",
    "        for col in df.columns:\n",
    "            lo = df[col].quantile(self.lower)\n",
    "            hi = df[col].quantile(self.upper)\n",
    "            self.bounds_[col] = (lo, hi)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not self.active:\n",
    "            return X\n",
    "        df = pd.DataFrame(X).copy()\n",
    "        for col, (lo, hi) in self.bounds_.items():\n",
    "            df[col] = df[col].clip(lo, hi)\n",
    "        return df.values\n",
    "\n",
    "###############################################################################\n",
    "# 3. Build Preprocessor\n",
    "###############################################################################\n",
    "def build_preprocessor(df_sample: pd.DataFrame, is_train=True):\n",
    "    target = 'prezo_euros'\n",
    "\n",
    "    # Identify numeric and categorical cols\n",
    "    numeric_cols = df_sample.select_dtypes(include='number').columns.tolist()\n",
    "    if target in numeric_cols:\n",
    "        numeric_cols.remove(target)\n",
    "\n",
    "    # Engineered features placeholders\n",
    "    engineered = [\n",
    "        'antiguedad', 'antiguedad2', 'decada',\n",
    "        'superficie_total', 'log_superficie_total', 'habitacion_area', 'banos_area',\n",
    "        'log_distancia_centro_km', 'inv_distancia_centro_km',\n",
    "        'log_distancia_escola_km', 'inv_distancia_escola_km',\n",
    "        'temp_norm', 'temp_sq', 'crime_q',\n",
    "        'orient_sin', 'orient_cos', 'geo_cluster',\n",
    "        'type_price_mean', 'type_price_std',\n",
    "        'mes', 'dia', 'dia_semana', 'is_fin_de_semana',\n",
    "        # plus any one-hot color_* columns\n",
    "    ]\n",
    "    numeric_cols += [f for f in engineered if f in df_sample.columns]\n",
    "\n",
    "    categorical_cols = [c for c in df_sample.select_dtypes(include='object').columns]\n",
    "\n",
    "    # Ordinal mappings\n",
    "    ordinal_maps = {\n",
    "        'calidade_materiais': ['Baixa', 'Media', 'Alta'],\n",
    "        'acceso_transporte_publico': ['Malo', 'Regular', 'Bo', 'Moi bo'],\n",
    "        'eficiencia_enerxetica': ['G', 'F', 'E', 'D', 'C', 'B', 'A'],\n",
    "    }\n",
    "    ord_feats = [c for c in ordinal_maps if c in categorical_cols]\n",
    "    ord_cats = [ordinal_maps[c] for c in ord_feats]\n",
    "    onehot_feats = [c for c in categorical_cols if c not in ord_feats]\n",
    "\n",
    "    # Pipelines\n",
    "    num_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='median')),\n",
    "        ('winsor', WinsorizerSelective(active=is_train)),\n",
    "        ('scale', RobustScaler())\n",
    "    ])\n",
    "    ord_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encode', OrdinalEncoder(categories=ord_cats))\n",
    "    ])\n",
    "    ohe_pipe = Pipeline([\n",
    "        ('impute', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_pipe, numeric_cols),\n",
    "        ('ord', ord_pipe, ord_feats),\n",
    "        ('ohe', ohe_pipe, onehot_feats)\n",
    "    ], remainder='drop', n_jobs=-1)\n",
    "\n",
    "    # Full pipeline\n",
    "    full_pipeline = Pipeline([\n",
    "        ('features', ExtendedFeatureEngineer()),\n",
    "        ('preproc', preprocessor)\n",
    "    ])\n",
    "\n",
    "    return full_pipeline, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/ipykernel_launcher.py:59: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'superficie_interior_m2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mcol_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'superficie_interior_m2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/mnt/lustre/scratch/nlsas/home/usc/ci/avs/desktop.5FZAnOkU/ipykernel_881224/1729211579.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Build and apply preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_preprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mX_all\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0my_all\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_transformers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_column_callables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_remainder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/compose/_column_transformer.py\u001b[0m in \u001b[0;36m_validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mall_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0mtransformer_to_input_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_column_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A given column is not a column of the dataframe\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcolumn_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# 4. PyTorch Training Script\n",
    "###############################################################################\n",
    "\n",
    "# Load raw data\n",
    "df_train = pd.read_csv(DATA_PATH)\n",
    "df_test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Build and apply preprocessing\n",
    "pipeline, target = build_preprocessor(df_train, is_train=True)\n",
    "X_all  = pipeline.fit_transform(df_train, df_train[target])\n",
    "y_all  = df_train[target].values\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_all, y_all, test_size=0.1, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Dataset & DataLoader\n",
    "class HousePriceDataset(Dataset):\n",
    "    def __init__(self, features, targets=None):\n",
    "        self.X = torch.from_numpy(features).float()\n",
    "        self.y = torch.from_numpy(targets).float() if targets is not None else None\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is None:\n",
    "            return self.X[idx]\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds    = HousePriceDataset(X_train, y_train)\n",
    "val_ds      = HousePriceDataset(X_val,   y_val)\n",
    "train_loader= DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_loader  = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Model definition (very large)\n",
    "class RegressionNNVeryBig(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4096), nn.BatchNorm1d(4096), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 2048), nn.BatchNorm1d(2048), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 1024), nn.BatchNorm1d(1024), nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(1024, 512),  nn.BatchNorm1d(512),  nn.ReLU(), nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),   nn.BatchNorm1d(256),  nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),   nn.BatchNorm1d(128),  nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),    nn.BatchNorm1d(64),   nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),     nn.BatchNorm1d(32),   nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze(1)\n",
    "\n",
    "model = RegressionNNVeryBig(X_train.shape[1]).to(DEVICE)\n",
    "\n",
    "# Optimizer, loss, early stopping\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.MSELoss()\n",
    "best_val = np.inf\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(1, MAX_EPOCHS + 1):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        preds  = model(xb)\n",
    "        loss   = criterion(preds, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            preds  = model(xb)\n",
    "            val_losses.append(((preds - yb)**2).mean().item())\n",
    "    val_rmse = np.sqrt(np.mean(val_losses))\n",
    "    print(f\"Epoch {epoch:03d} \u0014 Val RMSE: {val_rmse:.2f}\")\n",
    "\n",
    "    if val_rmse + 1e-4 < best_val:\n",
    "        best_val = val_rmse\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), os.path.join(MODEL_DIR, 'best_preproc.pt'))\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait >= PATIENCE:\n",
    "            print(f\"Stopping after {epoch} epochs without improvement.\")\n",
    "            break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, 'best_preproc.pt')))\n",
    "print(f\"Best Val RMSE: {best_val:.2f} euros\")\n",
    "\n",
    "# Generate submission\n",
    "pipeline.set_params(preproc__num__winsor__active=False)\n",
    "X_test = pipeline.transform(df_test)\n",
    "test_ds     = HousePriceDataset(X_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        preds.append(model(xb).cpu().numpy())\n",
    "preds = np.concatenate(preds, axis=0)\n",
    "submission = pd.DataFrame({'id': df_test['id'], 'prezo_euros': preds})\n",
    "submission.to_csv(SUBMIT_FILE, index=False)\n",
    "print(f\"Submission saved to {SUBMIT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
