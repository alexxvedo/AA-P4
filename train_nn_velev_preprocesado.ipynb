{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 34938836107.53905487\n",
      "Validation score: 0.478656\n",
      "Iteration 2, loss = 3960924759.34912872\n",
      "Validation score: 0.774619\n",
      "Iteration 3, loss = 2651605649.88038826\n",
      "Validation score: 0.801740\n",
      "Iteration 4, loss = 2458288540.36548090\n",
      "Validation score: 0.811688\n",
      "Iteration 5, loss = 2372195227.22597933\n",
      "Validation score: 0.820406\n",
      "Iteration 6, loss = 2312913372.10492182\n",
      "Validation score: 0.824044\n",
      "Iteration 7, loss = 2270682123.72034883\n",
      "Validation score: 0.827731\n",
      "Iteration 8, loss = 2223485673.31484509\n",
      "Validation score: 0.828408\n",
      "Iteration 9, loss = 2195353403.45056915\n",
      "Validation score: 0.829938\n",
      "Iteration 10, loss = 2165544193.58049822\n",
      "Validation score: 0.833200\n",
      "Iteration 11, loss = 2142116242.56525445\n",
      "Validation score: 0.837120\n",
      "Iteration 12, loss = 2111629543.21717739\n",
      "Validation score: 0.838476\n",
      "Iteration 13, loss = 2091940614.18797517\n",
      "Validation score: 0.839347\n",
      "Iteration 14, loss = 2078437562.79536057\n",
      "Validation score: 0.841795\n",
      "Iteration 15, loss = 2068923005.42436886\n",
      "Validation score: 0.840159\n",
      "Iteration 16, loss = 2045377482.39145780\n",
      "Validation score: 0.838838\n",
      "Iteration 17, loss = 2028741825.87326121\n",
      "Validation score: 0.843237\n",
      "Iteration 18, loss = 2010872784.61749673\n",
      "Validation score: 0.843617\n",
      "Iteration 19, loss = 2016795801.81899476\n",
      "Validation score: 0.844679\n",
      "Iteration 20, loss = 1990570340.51866150\n",
      "Validation score: 0.845301\n",
      "Iteration 21, loss = 1981809039.36114860\n",
      "Validation score: 0.845989\n",
      "Iteration 22, loss = 1983599260.22151446\n",
      "Validation score: 0.844641\n",
      "Iteration 23, loss = 1958422981.54910016\n",
      "Validation score: 0.847373\n",
      "Iteration 24, loss = 1945590419.62697315\n",
      "Validation score: 0.847511\n",
      "Iteration 25, loss = 1938921413.09987760\n",
      "Validation score: 0.848279\n",
      "Iteration 26, loss = 1926951055.23651910\n",
      "Validation score: 0.849093\n",
      "Iteration 27, loss = 1928415038.49644399\n",
      "Validation score: 0.847186\n",
      "Iteration 28, loss = 1921302515.91699886\n",
      "Validation score: 0.849544\n",
      "Iteration 29, loss = 1914825074.05698299\n",
      "Validation score: 0.847143\n",
      "Iteration 30, loss = 1903141741.03655624\n",
      "Validation score: 0.851513\n",
      "Iteration 31, loss = 1892482171.12522507\n",
      "Validation score: 0.851299\n",
      "Iteration 32, loss = 1885540392.09895134\n",
      "Validation score: 0.850853\n",
      "Iteration 33, loss = 1845607658.52289271\n",
      "Validation score: 0.851771\n",
      "Iteration 34, loss = 1828335318.51633859\n",
      "Validation score: 0.854361\n",
      "Iteration 35, loss = 1839711833.92819571\n",
      "Validation score: 0.855177\n",
      "Iteration 36, loss = 1807405857.01485062\n",
      "Validation score: 0.856038\n",
      "Iteration 37, loss = 1782223950.22597623\n",
      "Validation score: 0.857404\n",
      "Iteration 38, loss = 1769563183.58304095\n",
      "Validation score: 0.857997\n",
      "Iteration 39, loss = 1766317419.61626983\n",
      "Validation score: 0.851865\n",
      "Iteration 40, loss = 1754456585.02372265\n",
      "Validation score: 0.850173\n",
      "Iteration 41, loss = 1747503519.22086215\n",
      "Validation score: 0.859966\n",
      "Iteration 42, loss = 1732199652.05700564\n",
      "Validation score: 0.859309\n",
      "Iteration 43, loss = 1726303047.29110408\n",
      "Validation score: 0.860713\n",
      "Iteration 44, loss = 1708000760.26334953\n",
      "Validation score: 0.860677\n",
      "Iteration 45, loss = 1690334853.95499992\n",
      "Validation score: 0.859953\n",
      "Iteration 46, loss = 1691830585.82631230\n",
      "Validation score: 0.861386\n",
      "Iteration 47, loss = 1667356287.32118726\n",
      "Validation score: 0.861758\n",
      "Iteration 48, loss = 1656559782.83498693\n",
      "Validation score: 0.860857\n",
      "Iteration 49, loss = 1656704543.94290328\n",
      "Validation score: 0.862932\n",
      "Iteration 50, loss = 1652041271.50783801\n",
      "Validation score: 0.862467\n",
      "Iteration 51, loss = 1639446036.74116945\n",
      "Validation score: 0.863362\n",
      "Iteration 52, loss = 1621913971.01150370\n",
      "Validation score: 0.863490\n",
      "Iteration 53, loss = 1616356862.43587732\n",
      "Validation score: 0.860176\n",
      "Iteration 54, loss = 1611698906.23922634\n",
      "Validation score: 0.863177\n",
      "Iteration 55, loss = 1606514922.64693403\n",
      "Validation score: 0.864218\n",
      "Iteration 56, loss = 1570156621.32916451\n",
      "Validation score: 0.863681\n",
      "Iteration 57, loss = 1563644240.75738859\n",
      "Validation score: 0.863933\n",
      "Iteration 58, loss = 1548888246.24070215\n",
      "Validation score: 0.863957\n",
      "Iteration 59, loss = 1543724061.43124819\n",
      "Validation score: 0.858207\n",
      "Iteration 60, loss = 1544682633.57162213\n",
      "Validation score: 0.863155\n",
      "Iteration 61, loss = 1517163279.97616076\n",
      "Validation score: 0.861206\n",
      "Iteration 62, loss = 1506275776.70224714\n",
      "Validation score: 0.864974\n",
      "Iteration 63, loss = 1486709287.23858285\n",
      "Validation score: 0.863612\n",
      "Iteration 64, loss = 1503249044.63749313\n",
      "Validation score: 0.864878\n",
      "Iteration 65, loss = 1456171494.11943388\n",
      "Validation score: 0.866003\n",
      "Iteration 66, loss = 1452177926.55573368\n",
      "Validation score: 0.866071\n",
      "Iteration 67, loss = 1421005683.67584872\n",
      "Validation score: 0.864133\n",
      "Iteration 68, loss = 1398594743.02369070\n",
      "Validation score: 0.859388\n",
      "Iteration 69, loss = 1395486884.64640903\n",
      "Validation score: 0.869330\n",
      "Iteration 70, loss = 1358771278.68568015\n",
      "Validation score: 0.867627\n",
      "Iteration 71, loss = 1365018733.85863471\n",
      "Validation score: 0.867792\n",
      "Iteration 72, loss = 1310178908.97369146\n",
      "Validation score: 0.867525\n",
      "Iteration 73, loss = 1317696342.73875642\n",
      "Validation score: 0.867995\n",
      "Iteration 74, loss = 1280499683.94660568\n",
      "Validation score: 0.869312\n",
      "Iteration 75, loss = 1263138568.54510689\n",
      "Validation score: 0.871955\n",
      "Iteration 76, loss = 1230779883.36835909\n",
      "Validation score: 0.869430\n",
      "Iteration 77, loss = 1230387271.87662697\n",
      "Validation score: 0.869609\n",
      "Iteration 78, loss = 1203530653.28846622\n",
      "Validation score: 0.868597\n",
      "Iteration 79, loss = 1182544964.11923051\n",
      "Validation score: 0.869820\n",
      "Iteration 80, loss = 1171099628.84973025\n",
      "Validation score: 0.859932\n",
      "Iteration 81, loss = 1176108132.82010555\n",
      "Validation score: 0.870557\n",
      "Iteration 82, loss = 1180100307.81046176\n",
      "Validation score: 0.874557\n",
      "Iteration 83, loss = 1102145300.47184968\n",
      "Validation score: 0.872055\n",
      "Iteration 84, loss = 1096936989.23044515\n",
      "Validation score: 0.873088\n",
      "Iteration 85, loss = 1113715700.29047537\n",
      "Validation score: 0.871251\n",
      "Iteration 86, loss = 1059332042.74139607\n",
      "Validation score: 0.874664\n",
      "Iteration 87, loss = 1041464278.72950029\n",
      "Validation score: 0.873645\n",
      "Iteration 88, loss = 1013464799.18794751\n",
      "Validation score: 0.875002\n",
      "Iteration 89, loss = 1007288662.02245188\n",
      "Validation score: 0.861127\n",
      "Iteration 90, loss = 1011018731.05022645\n",
      "Validation score: 0.875966\n",
      "Iteration 91, loss = 981823276.33914351\n",
      "Validation score: 0.872417\n",
      "Iteration 92, loss = 964711665.19757581\n",
      "Validation score: 0.874284\n",
      "Iteration 93, loss = 948007407.79738355\n",
      "Validation score: 0.873820\n",
      "Iteration 94, loss = 950444197.74308920\n",
      "Validation score: 0.873041\n",
      "Iteration 95, loss = 928085887.10975730\n",
      "Validation score: 0.867718\n",
      "Iteration 96, loss = 906011694.18623400\n",
      "Validation score: 0.865691\n",
      "Iteration 97, loss = 882399663.12921035\n",
      "Validation score: 0.868434\n",
      "Iteration 98, loss = 927715813.04401314\n",
      "Validation score: 0.873022\n",
      "Iteration 99, loss = 883175040.81126034\n",
      "Validation score: 0.867342\n",
      "Iteration 100, loss = 855123197.89196444\n",
      "Validation score: 0.869337\n",
      "Iteration 101, loss = 914177424.43857265\n",
      "Validation score: 0.871141\n",
      "Iteration 102, loss = 814340885.51237178\n",
      "Validation score: 0.866176\n",
      "Iteration 103, loss = 845269974.44682193\n",
      "Validation score: 0.870452\n",
      "Iteration 104, loss = 809105943.65296853\n",
      "Validation score: 0.871415\n",
      "Iteration 105, loss = 869556231.10191691\n",
      "Validation score: 0.867292\n",
      "Iteration 106, loss = 790814301.05426657\n",
      "Validation score: 0.860244\n",
      "Iteration 107, loss = 789247485.70284927\n",
      "Validation score: 0.869614\n",
      "Iteration 108, loss = 769325151.90682852\n",
      "Validation score: 0.869537\n",
      "Iteration 109, loss = 758232364.82558107\n",
      "Validation score: 0.867431\n",
      "Iteration 110, loss = 729930331.17577636\n",
      "Validation score: 0.872849\n",
      "Iteration 111, loss = 714214711.51511431\n",
      "Validation score: 0.856807\n",
      "Iteration 112, loss = 774891054.82949495\n",
      "Validation score: 0.867569\n",
      "Iteration 113, loss = 732565631.69033885\n",
      "Validation score: 0.871114\n",
      "Iteration 114, loss = 698253919.96711898\n",
      "Validation score: 0.857784\n",
      "Iteration 115, loss = 710035355.26706409\n",
      "Validation score: 0.867630\n",
      "Iteration 116, loss = 680238769.83679223\n",
      "Validation score: 0.872194\n",
      "Iteration 117, loss = 685076654.53456795\n",
      "Validation score: 0.866432\n",
      "Iteration 118, loss = 669013215.18044960\n",
      "Validation score: 0.858905\n",
      "Iteration 119, loss = 636771788.09779274\n",
      "Validation score: 0.863124\n",
      "Iteration 120, loss = 659399508.71687531\n",
      "Validation score: 0.862261\n",
      "Iteration 121, loss = 663168476.89368224\n",
      "Validation score: 0.863181\n",
      "Iteration 122, loss = 624700072.04252839\n",
      "Validation score: 0.863856\n",
      "Iteration 123, loss = 650822146.96416461\n",
      "Validation score: 0.861767\n",
      "Iteration 124, loss = 605656793.73384845\n",
      "Validation score: 0.867938\n",
      "Iteration 125, loss = 597289931.58562434\n",
      "Validation score: 0.844195\n",
      "Iteration 126, loss = 638624866.29545486\n",
      "Validation score: 0.864549\n",
      "Iteration 127, loss = 584182302.06245565\n",
      "Validation score: 0.856999\n",
      "Iteration 128, loss = 606186364.54218256\n",
      "Validation score: 0.857089\n",
      "Iteration 129, loss = 609160233.99620759\n",
      "Validation score: 0.859756\n",
      "Iteration 130, loss = 581727589.99271488\n",
      "Validation score: 0.861477\n",
      "Iteration 131, loss = 563472913.38741899\n",
      "Validation score: 0.861804\n",
      "Iteration 132, loss = 572344610.12240303\n",
      "Validation score: 0.850864\n",
      "Iteration 133, loss = 535958692.60799968\n",
      "Validation score: 0.861478\n",
      "Iteration 134, loss = 519045087.68995553\n",
      "Validation score: 0.857230\n",
      "Iteration 135, loss = 553883816.51035738\n",
      "Validation score: 0.856159\n",
      "Iteration 136, loss = 515125598.45372695\n",
      "Validation score: 0.862665\n",
      "Iteration 137, loss = 509363001.69514525\n",
      "Validation score: 0.861011\n",
      "Iteration 138, loss = 515726332.83254272\n",
      "Validation score: 0.860230\n",
      "Iteration 139, loss = 518052796.31492364\n",
      "Validation score: 0.855875\n",
      "Iteration 140, loss = 503951348.00419945\n",
      "Validation score: 0.833294\n",
      "Iteration 141, loss = 511802001.67845839\n",
      "Validation score: 0.858225\n",
      "Validation score did not improve more than tol=0.000100 for 50 consecutive epochs. Stopping.\n",
      "Validation RMSE: 57270.22 euros\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Configuración y rutas\n",
    "# ----------------------------\n",
    "TRAIN_PATH   = 'train_preprocesado.csv'\n",
    "VAL_PATH     = 'val_preprocesado.csv'\n",
    "TEST_PATH    = 'test_preprocesado.csv'\n",
    "MODEL_DIR    = 'models_nn'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "BATCH_SIZE   = 256\n",
    "MAX_ITER     = 200\n",
    "PATIENCE     = 50  # early stopping\n",
    "LEARNING_RATE= 1e-3\n",
    "ALPHA        = 1e-4  # L2 regularization\n",
    "SUBMIT_FILE  = os.path.join(MODEL_DIR, 'submission_mlp.csv')\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Carga de datos\n",
    "# ----------------------------\n",
    "df_train = pd.read_csv(TRAIN_PATH)\n",
    "df_val   = pd.read_csv(VAL_PATH)\n",
    "df_test  = pd.read_csv(TEST_PATH)\n",
    "\n",
    "# Separar IDs\n",
    "train_ids = df_train['id'].values\n",
    "val_ids   = df_val['id'].values\n",
    "\n",
    "# Características y targets\n",
    "y_train = df_train['prezo_euros'].values\n",
    "X_train = df_train.drop(columns=['id','prezo_euros'])\n",
    "y_val   = df_val['prezo_euros'].values\n",
    "X_val   = df_val.drop(columns=['id','prezo_euros'])\n",
    "\n",
    "# Para la submission\n",
    "test_ids = df_test['id'].values\n",
    "X_test   = df_test.drop(columns=['id'])\n",
    "\n",
    "FEATURES = X_train.columns.tolist()\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Escalado de características\n",
    "# ----------------------------\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled   = scaler.transform(X_val)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Definición y entrenamiento del MLP\n",
    "# ----------------------------\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(1024, 512, 256, 128, 64, 32),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=ALPHA,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate_init=LEARNING_RATE,\n",
    "    max_iter=MAX_ITER,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=PATIENCE,\n",
    "    validation_fraction=0.1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ajuste del modelo con early stopping automático\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluar en validación externa\n",
    "val_preds = mlp.predict(X_val_scaled)\n",
    "val_rmse  = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "print(f\"Validation RMSE: {val_rmse:.2f} euros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/netapp2/Store_uni/home/usc/ci/avs/personal/aprendizaje/p4/venvP4/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=256, hidden_layer_sizes=(1024, 512, 256, 128, 64, 32),\n",
       "             random_state=42)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 5. Retrain en train+val para submission\n",
    "# ----------------------------\n",
    "X_full  = np.vstack((X_train_scaled, X_val_scaled))\n",
    "y_full  = np.concatenate((y_train, y_val))\n",
    "\n",
    "mlp_full = MLPRegressor(\n",
    "    hidden_layer_sizes=mlp.hidden_layer_sizes,\n",
    "    activation=mlp.activation,\n",
    "    solver=mlp.solver,\n",
    "    alpha=mlp.alpha,\n",
    "    batch_size=mlp.batch_size,\n",
    "    learning_rate_init=mlp.learning_rate_init,\n",
    "    max_iter=MAX_ITER,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=False\n",
    ")\n",
    "mlp_full.fit(X_full, y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 - Val RMSE: 54619.51\n",
      "Epoch 002 - Val RMSE: 55197.31\n",
      "Epoch 003 - Val RMSE: 55594.94\n",
      "Epoch 004 - Val RMSE: 55329.61\n",
      "Epoch 005 - Val RMSE: 54505.30\n",
      "Epoch 006 - Val RMSE: 56881.05\n",
      "Epoch 007 - Val RMSE: 55397.27\n",
      "Epoch 008 - Val RMSE: 56504.47\n",
      "Epoch 009 - Val RMSE: 54769.78\n",
      "Epoch 010 - Val RMSE: 54590.26\n",
      "Epoch 011 - Val RMSE: 59259.42\n",
      "Epoch 012 - Val RMSE: 55069.93\n",
      "Epoch 013 - Val RMSE: 56248.40\n",
      "Epoch 014 - Val RMSE: 54399.22\n",
      "Epoch 015 - Val RMSE: 56260.50\n",
      "Epoch 016 - Val RMSE: 54956.83\n",
      "Epoch 017 - Val RMSE: 57410.40\n",
      "Epoch 018 - Val RMSE: 55765.74\n",
      "Epoch 019 - Val RMSE: 54329.05\n",
      "Epoch 020 - Val RMSE: 55389.84\n",
      "Epoch 021 - Val RMSE: 54777.33\n",
      "Epoch 022 - Val RMSE: 54487.06\n",
      "Epoch 023 - Val RMSE: 55709.44\n",
      "Epoch 024 - Val RMSE: 54596.14\n",
      "Epoch 025 - Val RMSE: 56462.93\n",
      "Epoch 026 - Val RMSE: 55470.80\n",
      "Epoch 027 - Val RMSE: 54476.43\n",
      "Epoch 028 - Val RMSE: 55092.89\n",
      "Epoch 029 - Val RMSE: 58373.31\n",
      "Epoch 030 - Val RMSE: 54480.88\n",
      "Epoch 031 - Val RMSE: 55843.06\n",
      "Epoch 032 - Val RMSE: 54518.32\n",
      "Epoch 033 - Val RMSE: 55847.23\n",
      "Epoch 034 - Val RMSE: 54658.36\n",
      "Epoch 035 - Val RMSE: 56225.08\n",
      "Epoch 036 - Val RMSE: 55523.86\n",
      "Epoch 037 - Val RMSE: 54896.62\n",
      "Epoch 038 - Val RMSE: 57801.77\n",
      "Epoch 039 - Val RMSE: 54955.52\n",
      "Epoch 040 - Val RMSE: 54644.57\n",
      "Epoch 041 - Val RMSE: 55920.25\n",
      "Epoch 042 - Val RMSE: 54176.71\n",
      "Epoch 043 - Val RMSE: 54869.97\n",
      "Epoch 044 - Val RMSE: 54913.81\n",
      "Epoch 045 - Val RMSE: 56964.59\n",
      "Epoch 046 - Val RMSE: 55311.29\n",
      "Epoch 047 - Val RMSE: 55520.36\n",
      "Epoch 048 - Val RMSE: 56624.74\n",
      "Epoch 049 - Val RMSE: 54352.10\n",
      "Epoch 050 - Val RMSE: 56561.32\n",
      "Epoch 051 - Val RMSE: 54786.89\n",
      "Epoch 052 - Val RMSE: 57029.01\n",
      "Epoch 053 - Val RMSE: 56400.01\n",
      "Epoch 054 - Val RMSE: 61725.80\n",
      "Epoch 055 - Val RMSE: 54932.30\n",
      "Epoch 056 - Val RMSE: 56370.80\n",
      "Epoch 057 - Val RMSE: 54263.53\n",
      "Epoch 058 - Val RMSE: 55921.92\n",
      "Epoch 059 - Val RMSE: 57687.48\n",
      "Epoch 060 - Val RMSE: 58533.15\n",
      "Epoch 061 - Val RMSE: 54581.13\n",
      "Epoch 062 - Val RMSE: 54008.21\n",
      "Epoch 063 - Val RMSE: 54754.87\n",
      "Epoch 064 - Val RMSE: 54436.13\n",
      "Epoch 065 - Val RMSE: 54313.12\n",
      "Epoch 066 - Val RMSE: 55008.28\n",
      "Epoch 067 - Val RMSE: 56190.43\n",
      "Epoch 068 - Val RMSE: 57194.87\n",
      "Epoch 069 - Val RMSE: 56759.82\n",
      "Epoch 070 - Val RMSE: 55370.82\n",
      "Epoch 071 - Val RMSE: 55447.18\n",
      "Epoch 072 - Val RMSE: 54391.36\n",
      "Epoch 073 - Val RMSE: 54097.11\n",
      "Epoch 074 - Val RMSE: 54738.90\n",
      "Epoch 075 - Val RMSE: 55482.14\n",
      "Epoch 076 - Val RMSE: 55338.82\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 6. Generar submission\n",
    "# ----------------------------\n",
    "test_preds = mlp_full.predict(X_test_scaled)\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'prezo_euros': test_preds\n",
    "})\n",
    "submission.to_csv(SUBMIT_FILE, index=False)\n",
    "print(f\"Submission guardada en {SUBMIT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0523ecfdfd03da9535a2cd394fa2b2a2368df119d71b1e2a5e4a2b8711053260"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('venvP4': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
